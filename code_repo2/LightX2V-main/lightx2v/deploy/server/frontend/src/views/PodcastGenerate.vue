<script setup>
import { ref, computed, onMounted, onUnmounted, onBeforeUnmount, nextTick, watch } from 'vue'
import { useRouter, useRoute } from 'vue-router'
import {
    handleAudioUpload,
    showAlert,
    apiCall,
    loadPodcastAudioFromCache,
    getPodcastAudioFromCache,
    setPodcastAudioToCache,
    getPodcastAudioUrlFromApi,
    switchToCreateView,
    getCurrentForm,
    selectedTaskId,
    isCreationAreaExpanded,
    setCurrentAudioPreview,
    isLoading,
} from '../utils/other'

import { useI18n } from 'vue-i18n'
import topMenu from '../components/TopBar.vue'
import Loading from '../components/Loading.vue'
import SiteFooter from '../components/SiteFooter.vue'
import Alert from '../components/Alert.vue'
import Confirm from '../components/Confirm.vue'

const router = useRouter()
const route = useRoute()
const { t, locale, tm } = useI18n()

// å½“å‰ session_idï¼ˆä»è·¯ç”±å‚æ•°è·å–ï¼‰
const currentSessionId = ref(null)
const isDetailMode = ref(false) // æ˜¯å¦ä¸ºè¯¦æƒ…æ¨¡å¼

// æ¨¡æ¿å¼•ç”¨
const inputField = ref(null)
const playerSection = ref(null)
const statusText = ref(null)
const statusMessage = ref(null)
const stopBtn = ref(null)
const downloadBtn = ref(null)
const applyBtn = ref(null)
const subtitleSection = ref(null)
const playBtn = ref(null)
const progressBar = ref(null)
const currentTimeEl = ref(null)
const durationEl = ref(null)
const waveform = ref(null)
const progressContainer = ref(null)
const sidebar = ref(null)
const sidebarToggle = ref(null)
const toggleSubtitlesBtn = ref(null)
const audioUserInputEl = ref(null)
const audioElement = ref(null)  // template ä¸­çš„ audio å…ƒç´ å¼•ç”¨

// å“åº”å¼çŠ¶æ€
const input = ref('')
const showPlayer = ref(false)
const showStatus = ref(false)
const statusMsg = ref('')
const statusClass = ref('')
const showStopBtn = ref(false)
const showDownloadBtn = ref(false)
const showSubtitles = ref(false)
const isPlaying = ref(false)
const currentTime = ref(0)
const duration = ref(0)
const progress = ref(0)
const audioUserInput = ref('')
const sidebarCollapsed = ref(false)
const historyItems = ref([])
const loadingHistory = ref(false)
const loadingSessionDetail = ref(false)
// éŸ³é¢‘ URLï¼ˆå“åº”å¼ï¼Œç”¨äº template ä¸­çš„ audio å…ƒç´ ï¼‰
const audioUrl = ref('')
// æ³¢å½¢å›¾æ•°æ®ï¼ˆå“åº”å¼æ•°ç»„ï¼Œç”¨äº template æ¸²æŸ“ï¼‰
const waveformBars = ref([])

// ç¤ºä¾‹è¾“å…¥åˆ—è¡¨ï¼ˆä½¿ç”¨è®¡ç®—å±æ€§æ”¯æŒè¯­è¨€åˆ‡æ¢ï¼‰
const exampleInputs = computed(() => {
    try {
        // ä½¿ç”¨ tm å‡½æ•°ç›´æ¥è·å–ç¿»è¯‘å¯¹è±¡ï¼ˆæ•°ç»„ï¼‰
        const messages = tm('podcast.exampleInputs')
        if (Array.isArray(messages)) {
            return messages
        }
        // å¦‚æœ tm è¿”å›çš„ä¸æ˜¯æ•°ç»„ï¼Œå°è¯•ä½¿ç”¨ t å‡½æ•°
        const result = t('podcast.exampleInputs', { returnObjects: true })
        if (Array.isArray(result)) {
            return result
        }
        // å¦‚æœéƒ½ä¸è¡Œï¼Œè¿”å›é»˜è®¤å€¼
        console.warn('exampleInputs not found in translations, using defaults')
        return locale.value === 'zh' ? [
            'https://github.com/ModelTC/LightX2V',
            'LLMå¤§æ¨¡å‹çš„åŸç†',
            'ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ',
            'å¦‚ä½•å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ï¼Ÿ',
            'å¦‚ä½•ç§‘å­¦å‡è‚¥'
        ] : [
            'https://github.com/ModelTC/LightX2V',
            'Principles of LLM Large Models',
            'What is Deep Learning?',
            'How to Balance Work and Life?',
            'How to Lose Weight Scientifically'
        ]
    } catch (error) {
        console.warn('Failed to load exampleInputs:', error)
        // è¿”å›é»˜è®¤å€¼
        return locale.value === 'zh' ? [
            'https://github.com/ModelTC/LightX2V',
            'LLMå¤§æ¨¡å‹çš„åŸç†',
            'ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ',
            'å¦‚ä½•å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ï¼Ÿ',
            'å¦‚ä½•ç§‘å­¦å‡è‚¥'
        ] : [
            'https://github.com/ModelTC/LightX2V',
            'Principles of LLM Large Models',
            'What is Deep Learning?',
            'How to Balance Work and Life?',
            'How to Lose Weight Scientifically'
        ]
    }
})

// éŸ³é¢‘ç›¸å…³çŠ¶æ€ï¼ˆéå“åº”å¼ï¼Œç”¨äºå†…éƒ¨é€»è¾‘ï¼‰
let audio = null
let isDragging = false
let audioContext = null
let analyser = null  // ç”¨äº audio å…ƒç´ çš„åˆ†æå™¨
let webAudioAnalyser = null  // ç”¨äº WebAudio çš„åˆ†æå™¨ï¼ˆç‹¬ç«‹ï¼‰
let animationFrameId = null
// å­—å¹•æ•°æ®æ”¹ä¸ºå“åº”å¼ï¼Œç”¨äº template æ¸²æŸ“
const subtitles = ref([])
const subtitleTimestamps = ref([])
let wsConnection = null
let mergedAudioUrl = null
let currentAudioUrl = null
let sessionAudioUrl = null  // å½“å‰ä¼šè¯çš„éŸ³é¢‘ URLï¼ˆç”¨äº applyToDigitalHumanï¼‰
let lastAudioDuration = 0
let audioUpdateChecker = null
let isSwitching = false
let autoFollowSubtitles = true
let userScrollTimeout = null
let mediaSource = null
let sourceBuffer = null
let audioQueue = []
let lastBytePosition = 0
let totalAudioSize = 0
let shouldResumePlayback = false
let isGenerating = false  // æ˜¯å¦æ­£åœ¨ç”Ÿæˆæ’­å®¢
let isInitialAudioLoadComplete = false  // åˆå§‹éŸ³é¢‘åŠ è½½æ˜¯å¦å®Œæˆ
let pendingAppendSize = 0  // æ­£åœ¨è¿½åŠ çš„æ•°æ®å¤§å°ï¼ˆç”¨äºæ›´æ–° lastBytePositionï¼‰

// WebAudio æµå¼æ’­æ”¾ç›¸å…³
let webAudioContext = null
let webAudioQueue = []
let webAudioPlaying = false
let webAudioCurrentTime = 0
let webAudioStartTime = 0
let webAudioTotalDuration = 0
let webAudioSourceNodes = []
let webAudioTimeUpdateFrame = null

// è®¾å¤‡æ£€æµ‹
function isIOSSafari() {
    const ua = window.navigator.userAgent
    const isIOS = /iPad|iPhone|iPod/.test(ua) || (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1)
    const isSafari = /^((?!chrome|android).)*safari/i.test(ua)
    return isIOS && isSafari
}

// ä¸º URL æ·»åŠ ç¼“å­˜ç ´åå‚æ•°ï¼ˆä»…å¯¹ API URLï¼Œä¸å¯¹ CDN é¢„ç­¾å URLï¼‰
function addCacheBustingParam(url) {
    if (!url) return url
    // å¦‚æœæ˜¯ CDN URLï¼ˆhttp/httpsï¼‰ï¼Œä¸æ·»åŠ å‚æ•°ï¼Œé¿å…ç ´åé¢„ç­¾å URL
    if (url.startsWith('http://') || url.startsWith('https://')) {
        return url
    }
    // å¯¹äº API URLï¼Œæ·»åŠ ç¼“å­˜ç ´åå‚æ•°
    const separator = url.includes('?') ? '&' : '?'
    let newUrl = `${url}${separator}t=${Date.now()}`;
    const token = localStorage.getItem('accessToken')
    if (token) {
        newUrl = `${newUrl}&token=${token}`
    }
    return newUrl;
}

// æ£€æµ‹æ˜¯å¦ä¸ºç§»åŠ¨ç«¯
function isMobileDevice() {
    return window.matchMedia && window.matchMedia('(max-width: 768px)').matches
}

// åˆå§‹åŒ–æ³¢å½¢å›¾ï¼ˆä½¿ç”¨å“åº”å¼æ•°æ®ï¼‰
function initWaveform() {
    try {
        // æ ¹æ®è®¾å¤‡ç±»å‹åˆå§‹åŒ–æ³¢å½¢æ¡æ•°ç»„ï¼šç§»åŠ¨ç«¯50ä¸ªï¼Œæ¡Œé¢ç«¯100ä¸ª
        const barCount = isMobileDevice() ? 50 : 100
        const bars = []
        for (let i = 0; i < barCount; i++) {
            bars.push({
                id: i,
                height: 30, // å½“å‰é«˜åº¦ï¼ˆç”¨äºå¹³æ»‘è¿‡æ¸¡ï¼‰
                targetHeight: 30, // ç›®æ ‡é«˜åº¦
                intensity: 50 // åˆå§‹å¼ºåº¦ï¼ˆ0-100ï¼‰
            })
        }

        waveformBars.value = bars
        // ç«‹å³æ¸²æŸ“ä¸€æ¬¡æ³¢å½¢ï¼ˆå³ä½¿æ²¡æœ‰æ’­æ”¾ï¼‰
        nextTick(() => {
            renderSimulatedWaveform()
        })
    } catch (error) {
        console.error('Error initializing waveform:', error)
    }
}

// åˆå§‹åŒ– WebAudio Contextï¼ˆç”¨äºæµå¼æ’­æ”¾ï¼‰
function initWebAudioContext() {
    if (!webAudioContext || webAudioContext.state === 'closed') {
        webAudioContext = new (window.AudioContext || window.webkitAudioContext)()
    }
    return webAudioContext
}

// å¤„ç†æ¥æ”¶åˆ°çš„ WAV chunk
async function handleWebAudioChunk(arrayBuffer) {
    try {
        const context = initWebAudioContext()

        // è§£ç  WAV chunk
        const audioBuffer = await context.decodeAudioData(arrayBuffer.slice(0))

        // æ·»åŠ åˆ°é˜Ÿåˆ—
        webAudioQueue.push(audioBuffer)
        webAudioTotalDuration += audioBuffer.duration

        // æ›´æ–°æ€»æ—¶é•¿æ˜¾ç¤º
        duration.value = webAudioTotalDuration

        // æ˜¾ç¤ºæ’­æ”¾å™¨ï¼ˆå¦‚æœè¿˜æ²¡æ˜¾ç¤ºï¼‰
        if (!showPlayer.value) {
            showPlayer.value = true
            await nextTick()
            // ç¡®ä¿æ³¢å½¢å›¾å®¹å™¨å­˜åœ¨åå†åˆå§‹åŒ–
            if (waveform.value) {
                initWaveform()
            }
            statusMsg.value = t('podcast.ready')
        }

        // ç¡®ä¿æ³¢å½¢å›¾å·²åˆå§‹åŒ–ï¼ˆå¦‚æœæ’­æ”¾å™¨å·²æ˜¾ç¤ºä½†æ³¢å½¢å›¾æœªåˆå§‹åŒ–ï¼‰
        if (showPlayer.value && waveformBars.value.length === 0) {
            initWaveform()
        }

        console.log(`âœ… Received WAV chunk: ${audioBuffer.duration.toFixed(2)}s, queue: ${webAudioQueue.length}, total duration: ${webAudioTotalDuration.toFixed(2)}s`)
    } catch (error) {
        console.error('Error handling WebAudio chunk:', error)
        statusMsg.value = t('podcast.audioDecodeFailed', { error: error.message })
    }
}

// æ’­æ”¾ä¸‹ä¸€ä¸ª WebAudio chunk
async function playNextWebAudioChunk() {
    if (webAudioQueue.length === 0) {
        webAudioPlaying = false
        if (isPlaying.value) {
            // æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ
            isPlaying.value = false
            webAudioCurrentTime = 0
        }
        return
    }

    if (!webAudioPlaying && !isPlaying.value) {
        // ç”¨æˆ·æ²¡æœ‰ç‚¹å‡»æ’­æ”¾ï¼Œä¸è‡ªåŠ¨æ’­æ”¾
        return
    }

    webAudioPlaying = true
    const context = initWebAudioContext()

    // ç¡®ä¿ AudioContext å·²æ¢å¤ï¼ˆç§»åŠ¨ç«¯éœ€è¦ç”¨æˆ·äº¤äº’ï¼‰
    if (context.state === 'suspended') {
        await context.resume()
    }

    const audioBuffer = webAudioQueue.shift()

    // åˆ›å»º AudioBufferSourceNode
    const source = context.createBufferSource()
    source.buffer = audioBuffer

    // åˆ›å»ºåˆ†æå™¨ç”¨äºæ³¢å½¢æ˜¾ç¤ºï¼ˆWebAudio æ¨¡å¼ï¼Œä½¿ç”¨ç‹¬ç«‹çš„ analyserï¼‰
    if (!webAudioAnalyser || webAudioAnalyser.context !== context) {
        webAudioAnalyser = context.createAnalyser()
        webAudioAnalyser.fftSize = 256
        // é™ä½å¹³æ»‘ç³»æ•°ï¼Œè®©æ³¢å½¢å˜åŒ–æ›´æ•æ„Ÿã€æ›´æ˜æ˜¾ï¼ˆ0.3 æ¯” 0.8 æ›´æ•æ„Ÿï¼‰
        webAudioAnalyser.smoothingTimeConstant = 0.3
        webAudioAnalyser.connect(context.destination)
    }
    // ç¡®ä¿ source è¿æ¥åˆ° webAudioAnalyserï¼ŒwebAudioAnalyser è¿æ¥åˆ° destination
    source.connect(webAudioAnalyser)

    // è®°å½•å¼€å§‹æ—¶é—´ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡æ’­æ”¾æ—¶è®¾ç½®ï¼‰
    if (webAudioStartTime === 0) {
        webAudioStartTime = context.currentTime
    }

    // è®¡ç®—å½“å‰éŸ³é¢‘å—çš„å¼€å§‹æ—¶é—´ï¼ˆæŒ‰é¡ºåºæ’­æ”¾ï¼‰
    const chunkStartTime = webAudioStartTime + webAudioCurrentTime

    // æ’­æ”¾ï¼ˆä½¿ç”¨è®¡ç®—å¥½çš„å¼€å§‹æ—¶é—´ï¼Œç¡®ä¿æŒ‰é¡ºåºæ’­æ”¾ï¼‰
    source.start(chunkStartTime)

    console.log(`ğŸµ Playing chunk: start=${chunkStartTime.toFixed(3)}, duration=${audioBuffer.duration.toFixed(3)}, currentTime=${webAudioCurrentTime.toFixed(3)}`)

    // ä¿å­˜ source nodeï¼ˆç”¨äºåœæ­¢ï¼‰
    webAudioSourceNodes.push(source)

    // ç›‘å¬æ’­æ”¾ç»“æŸ
    source.onended = () => {
        webAudioCurrentTime += audioBuffer.duration
        currentTime.value = webAudioCurrentTime
        // æ›´æ–°è¿›åº¦æ¡
        if (webAudioTotalDuration > 0) {
            progress.value = (webAudioCurrentTime / webAudioTotalDuration) * 100
        }
        // æ›´æ–°å­—å¹•é«˜äº®
        updateActiveSubtitleForStreaming(webAudioCurrentTime)
        // ç»§ç»­æ’­æ”¾ä¸‹ä¸€ä¸ª
        playNextWebAudioChunk()
    }

    // å¯åŠ¨æ—¶é—´æ›´æ–°ï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰
    if (!webAudioTimeUpdateFrame) {
        startWebAudioTimeUpdate()
    }
}

// æ›´æ–° WebAudio å½“å‰æ—¶é—´ï¼ˆä¸å‚è€ƒ HTML ä¸€è‡´ï¼Œè‡ªåŠ¨è·Ÿéšå­—å¹•ï¼‰
function startWebAudioTimeUpdate() {
    function updateWebAudioTime() {
        if (webAudioPlaying && isPlaying.value && webAudioContext) {
            const elapsed = webAudioContext.currentTime - webAudioStartTime
            webAudioCurrentTime = Math.min(elapsed, webAudioTotalDuration)
            currentTime.value = webAudioCurrentTime
            if (webAudioTotalDuration > 0) {
                progress.value = (webAudioCurrentTime / webAudioTotalDuration) * 100
            }
            // è‡ªåŠ¨æ›´æ–°å­—å¹•é«˜äº®å¹¶è·Ÿéšï¼ˆä¸å‚è€ƒ HTML ä¸€è‡´ï¼‰
            updateActiveSubtitleForStreaming(webAudioCurrentTime)
            webAudioTimeUpdateFrame = requestAnimationFrame(updateWebAudioTime)
        } else {
            webAudioTimeUpdateFrame = null
        }
    }
    webAudioTimeUpdateFrame = requestAnimationFrame(updateWebAudioTime)
}

// å¼€å§‹/æš‚åœ WebAudio æ’­æ”¾
function toggleWebAudioPlayback() {
    if (!webAudioContext) {
        initWebAudioContext()
    }

    // ç¡®ä¿ AudioContext å·²æ¢å¤ï¼ˆç§»åŠ¨ç«¯éœ€è¦ç”¨æˆ·äº¤äº’ï¼‰
    if (webAudioContext.state === 'suspended') {
        webAudioContext.resume().catch(err => {
            console.error('Failed to resume AudioContext:', err)
        })
    }

    if (webAudioPlaying || isPlaying.value) {
        // åœæ­¢æ‰€æœ‰æ­£åœ¨æ’­æ”¾çš„ source nodes
        webAudioSourceNodes.forEach(node => {
            try {
                node.stop()
            } catch (e) {
                // å¯èƒ½å·²ç»åœæ­¢
            }
        })
        webAudioSourceNodes = []
        webAudioPlaying = false
        isPlaying.value = false
        if (webAudioTimeUpdateFrame) {
            cancelAnimationFrame(webAudioTimeUpdateFrame)
            webAudioTimeUpdateFrame = null
        }
        if (animationFrameId) {
            cancelAnimationFrame(animationFrameId)
            animationFrameId = null
        }
    } else {
        // å¼€å§‹æ’­æ”¾
        if (webAudioQueue.length === 0) {
            statusMsg.value = t('podcast.noAudioAvailable')
            return
        }

        isPlaying.value = true
        const context = initWebAudioContext()
        if (webAudioStartTime === 0) {
            webAudioStartTime = context.currentTime
        }
        playNextWebAudioChunk()
        startWebAudioTimeUpdate()
        // å¯åŠ¨æ³¢å½¢å¯è§†åŒ–
        if (!animationFrameId) {
            visualize()
        }
    }
}

// å­˜å‚¨ MediaElementSourceï¼Œé¿å…é‡å¤åˆ›å»º
let mediaElementSource = null
// è·¨åŸŸéŸ³é¢‘çš„é¢„åˆ†ææ³¢å½¢æ•°æ®ï¼ˆç”¨äºæ³¢å½¢æ˜¾ç¤ºï¼‰
let crossOriginWaveformData = null
let crossOriginWaveformDataLoaded = false
let crossOriginWaveformMin = 0 // æ³¢å½¢æ•°æ®çš„æœ€å°å€¼ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
let crossOriginWaveformMax = 0 // æ³¢å½¢æ•°æ®çš„æœ€å¤§å€¼ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰

// æ£€æŸ¥éŸ³é¢‘ URL æ˜¯å¦è·¨åŸŸï¼ˆå¯èƒ½å¯¼è‡´ CORS é—®é¢˜ï¼‰
function isCrossOriginAudio(audioElement) {
    if (!audioElement || !audioElement.src) return false

    try {
        const audioUrl = new URL(audioElement.src, window.location.href)
        const currentOrigin = window.location.origin
        return audioUrl.origin !== currentOrigin
    } catch (e) {
        // å¦‚æœ URL è§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯ blob: æˆ– data: URLï¼Œä¸ç®—è·¨åŸŸ
        return false
    }
}

// ä¸ºè·¨åŸŸéŸ³é¢‘é¢„åˆ†ææ³¢å½¢æ•°æ®ï¼ˆç”¨äºæ³¢å½¢æ˜¾ç¤ºï¼‰
let lastAnalyzedAudioUrl = null

async function initCrossOriginAudioAnalyzer() {
    if (!audio || !audio.src || !isCrossOriginAudio(audio)) return

    // æ£€æŸ¥éŸ³é¢‘ URL æ˜¯å¦å˜åŒ–ï¼Œå¦‚æœå˜åŒ–äº†éœ€è¦é‡æ–°åˆ†æ
    const currentAudioUrl = audio.src.split('?')[0] // ç§»é™¤æŸ¥è¯¢å‚æ•°
    if (crossOriginWaveformDataLoaded && crossOriginWaveformData && lastAnalyzedAudioUrl === currentAudioUrl) {
        return // å·²ç»åˆ†æè¿‡ä¸” URL æ²¡å˜åŒ–
    }

    // å¦‚æœ URL å˜åŒ–äº†ï¼Œæ¸…ç†æ—§æ•°æ®
    if (lastAnalyzedAudioUrl !== currentAudioUrl) {
        crossOriginWaveformData = null
        crossOriginWaveformDataLoaded = false
        crossOriginWaveformMin = 0
        crossOriginWaveformMax = 0
    }

    try {
        console.log('ğŸµ Pre-analyzing cross-origin audio for waveform visualization...')

        // åˆ›å»ºä¸´æ—¶çš„ AudioContextï¼ˆä»…ç”¨äºè§£ç ï¼‰
        const tempContext = new (window.AudioContext || window.webkitAudioContext)()

        // ä½¿ç”¨ fetch è·å–éŸ³é¢‘æ•°æ®ï¼ˆæ”¯æŒ CORSï¼‰
        // æ³¨æ„ï¼šå¯¹äº CDN é¢„ç­¾å URLï¼ŒæŸ¥è¯¢å‚æ•°å¯èƒ½åŒ…å«è®¤è¯ä¿¡æ¯ï¼Œåº”è¯¥ä¿ç•™
        const fullAudioUrl = audio.src // ä¿ç•™å®Œæ•´ URLï¼ˆåŒ…æ‹¬æŸ¥è¯¢å‚æ•°ï¼‰
        const audioUrlWithoutParams = audio.src.split('?')[0] // ç§»é™¤æŸ¥è¯¢å‚æ•°çš„ç‰ˆæœ¬ï¼ˆå¤‡ç”¨ï¼‰

        let response
        let lastError = null

        // å…ˆå°è¯•å®Œæ•´ URLï¼ˆä¿ç•™æŸ¥è¯¢å‚æ•°ï¼Œå¯èƒ½åŒ…å«è®¤è¯ä¿¡æ¯ï¼‰
        try {
            response = await fetch(fullAudioUrl, {
                mode: 'cors',
                credentials: 'omit'
            })

            // å¦‚æœ fetch è¿”å›é”™è¯¯çŠ¶æ€ç ï¼ˆå¦‚ 403ï¼‰ï¼Œå°è¯•ä½¿ç”¨ apiCallï¼ˆæ”¯æŒè®¤è¯ï¼‰
            if (!response.ok) {
                console.warn(`Direct fetch returned ${response.status}, trying apiCall with authentication...`)
                lastError = new Error(`Direct fetch failed: ${response.status} ${response.statusText}`)
                try {
                    // ä½¿ç”¨å®Œæ•´ URL å°è¯• apiCall
                    response = await apiCall(fullAudioUrl)
                    if (!response || !response.ok) {
                        throw new Error(`apiCall failed: ${response ? response.status : 'no response'}`)
                    }
                } catch (apiError) {
                    // å¦‚æœå®Œæ•´ URL å¤±è´¥ï¼Œå°è¯•ç§»é™¤æŸ¥è¯¢å‚æ•°çš„ç‰ˆæœ¬
                    console.warn('apiCall with full URL failed, trying without query params...')
                    try {
                        response = await apiCall(audioUrlWithoutParams)
                        if (!response || !response.ok) {
                            throw new Error(`apiCall without params failed: ${response ? response.status : 'no response'}`)
                        }
                    } catch (apiError2) {
                        throw new Error(`Both fetch and apiCall failed. Fetch: ${lastError.message}, apiCall (full): ${apiError.message || 'unknown'}, apiCall (no params): ${apiError2.message || 'unknown'}`)
                    }
                }
            }
        } catch (fetchError) {
            // å¦‚æœ fetch å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ CORS é™åˆ¶æˆ–ç½‘ç»œé”™è¯¯ï¼‰ï¼Œå°è¯•ä½¿ç”¨ apiCallï¼ˆæ”¯æŒè®¤è¯ï¼‰
            console.warn('Direct fetch failed, trying apiCall:', fetchError)
            lastError = fetchError
            try {
                // å…ˆå°è¯•å®Œæ•´ URL
                response = await apiCall(fullAudioUrl)
                if (!response) {
                    throw new Error('apiCall returned no response')
                }
                if (!response.ok) {
                    throw new Error(`apiCall failed: ${response.status} ${response.statusText}`)
                }
            } catch (apiError) {
                // å¦‚æœå®Œæ•´ URL å¤±è´¥ï¼Œå°è¯•ç§»é™¤æŸ¥è¯¢å‚æ•°çš„ç‰ˆæœ¬
                console.warn('apiCall with full URL failed, trying without query params...')
                try {
                    response = await apiCall(audioUrlWithoutParams)
                    if (!response) {
                        throw new Error('apiCall (no params) returned no response')
                    }
                    if (!response.ok) {
                        throw new Error(`apiCall (no params) failed: ${response.status} ${response.statusText}`)
                    }
                } catch (apiError2) {
                    const errorMsg = `Failed to fetch audio. Fetch error: ${fetchError.message || 'unknown'}, apiCall (full) error: ${apiError.message || 'unknown'}, apiCall (no params) error: ${apiError2.message || 'unknown'}`
                    console.error('âŒ', errorMsg)
                    throw new Error(errorMsg)
                }
            }
        }

        if (!response || !response.ok) {
            const errorMsg = `Failed to fetch audio: ${response ? response.status : 'no response'}`
            console.error('âŒ', errorMsg)
            throw new Error(errorMsg)
        }

        const arrayBuffer = await response.arrayBuffer()

        // è§£ç éŸ³é¢‘æ•°æ®
        const audioBuffer = await tempContext.decodeAudioData(arrayBuffer)

        // å…³é—­ä¸´æ—¶ context
        await tempContext.close()

        // é¢„åˆ†æéŸ³é¢‘æ•°æ®ï¼Œç”Ÿæˆä¸€ä¸ªéå¸¸é•¿çš„æ³¢å½¢æ•°æ®æ•°ç»„
        // æ ¹æ®éŸ³é¢‘æ—¶é•¿ç”Ÿæˆæ•°æ®ç‚¹ï¼šæ¯ 0.01 ç§’ä¸€ä¸ªæ•°æ®ç‚¹ï¼ˆ100Hz é‡‡æ ·ç‡ï¼‰
        const audioDuration = audioBuffer.duration // éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        const sampleRate = audioBuffer.sampleRate // é‡‡æ ·ç‡
        const channelData = audioBuffer.getChannelData(0) // ä½¿ç”¨ç¬¬ä¸€ä¸ªå£°é“

        // è®¡ç®—æ•°æ®ç‚¹æ•°é‡ï¼šæ¯ 0.01 ç§’ä¸€ä¸ªæ•°æ®ç‚¹
        const dataPointInterval = 0.05 // ç§’
        const totalDataPoints = Math.ceil(audioDuration / dataPointInterval)
        const samplesPerDataPoint = Math.floor(sampleRate * dataPointInterval) // æ¯ä¸ªæ•°æ®ç‚¹å¯¹åº”çš„æ ·æœ¬æ•°

        console.log(`ğŸ“Š Generating long waveform: ${totalDataPoints} data points for ${audioDuration.toFixed(2)}s audio (${dataPointInterval}s per point)`)

        crossOriginWaveformData = []
        let minAmplitude = Infinity
        let maxAmplitude = -Infinity

        for (let i = 0; i < totalDataPoints; i++) {
            // è®¡ç®—è¯¥æ•°æ®ç‚¹å¯¹åº”çš„æ ·æœ¬èŒƒå›´
            const startSample = Math.floor(i * samplesPerDataPoint)
            const endSample = Math.min(startSample + samplesPerDataPoint, channelData.length)

            // å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡
            if (startSample >= channelData.length) {
                crossOriginWaveformData.push(0)
                continue
            }

            // è®¡ç®—è¯¥æ®µçš„ RMSï¼ˆå‡æ–¹æ ¹å€¼ï¼‰å’Œå³°å€¼
            let sumSquares = 0
            let count = 0
            let maxSampleAmplitude = 0

            for (let j = startSample; j < endSample; j++) {
                const sample = channelData[j]
                sumSquares += sample * sample
                count++
                if (Math.abs(sample) > maxSampleAmplitude) {
                    maxSampleAmplitude = Math.abs(sample)
                }
            }

            const rms = count > 0 ? Math.sqrt(sumSquares / count) : 0
            // æ··åˆ RMS å’Œå³°å€¼ï¼ˆ50% RMS + 50% å³°å€¼ï¼‰
            const amplitude = rms * 0.5 + maxSampleAmplitude * 0.5

            crossOriginWaveformData.push(amplitude)

            // æ›´æ–°æœ€å°å€¼å’Œæœ€å¤§å€¼
            if (amplitude < minAmplitude) {
                minAmplitude = amplitude
            }
            if (amplitude > maxAmplitude) {
                maxAmplitude = amplitude
            }
        }

        // ä¿å­˜æœ€å°å€¼å’Œæœ€å¤§å€¼ï¼Œç”¨äºå½’ä¸€åŒ–
        crossOriginWaveformMin = minAmplitude
        crossOriginWaveformMax = maxAmplitude

        console.log(`âœ… Generated ${crossOriginWaveformData.length} data points for waveform visualization`)
        console.log(`ğŸ“Š Amplitude range: ${minAmplitude.toFixed(6)} to ${maxAmplitude.toFixed(6)}`)

        crossOriginWaveformDataLoaded = true
        lastAnalyzedAudioUrl = currentAudioUrl // ä¿å­˜å·²åˆ†æçš„ URL
        console.log('âœ… Cross-origin audio waveform data pre-analyzed successfully')
    } catch (error) {
        console.warn('âš ï¸ Failed to pre-analyze cross-origin audio:', error)
        console.warn('Will fall back to simulated waveform')
        // æ¸…ç†å¤±è´¥çš„çŠ¶æ€
        crossOriginWaveformData = null
        crossOriginWaveformDataLoaded = false
        crossOriginWaveformMin = 0
        crossOriginWaveformMax = 0
        lastAnalyzedAudioUrl = null
    }
}

// åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨
async function initAudioAnalyzer() {
    if (!audio) return

    // æ£€æŸ¥éŸ³é¢‘æ˜¯å¦è·¨åŸŸï¼ˆè·¨åŸŸéŸ³é¢‘ä½¿ç”¨ MediaElementSource ä¼šå¯¼è‡´ CORS é™åˆ¶ï¼ŒéŸ³é¢‘ä¼šæ— å£°ï¼‰
    if (isCrossOriginAudio(audio)) {
        console.warn('âš ï¸ Audio is cross-origin, skipping MediaElementSource creation to avoid CORS restrictions')
        console.warn('Will try to use pre-analyzed waveform data instead')
        analyser = null
        mediaElementSource = null
        // å°è¯•é¢„åˆ†æéŸ³é¢‘æ•°æ®ç”¨äºæ³¢å½¢æ˜¾ç¤º
        await initCrossOriginAudioAnalyzer()
        return
    }

    // å¦‚æœå·²ç»æœ‰æœ‰æ•ˆçš„ analyser å’Œ mediaElementSourceï¼Œç›´æ¥è¿”å›
    if (analyser && audioContext && audioContext.state !== 'closed' && mediaElementSource) {
        return
    }

    // å¦‚æœ audioContext å·²å…³é—­ï¼Œéœ€è¦é‡æ–°åˆ›å»º
    if (audioContext && audioContext.state === 'closed') {
        audioContext = null
        analyser = null
        mediaElementSource = null
    }

    // å¦‚æœ audioContext å­˜åœ¨ä½† analyser ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°åˆ›å»º
    if (audioContext && audioContext.state !== 'closed' && !analyser) {
        // å…³é—­æ—§çš„ context å¹¶é‡æ–°åˆ›å»º
        try {
            await audioContext.close()
        } catch (e) {
            console.log('Error closing old context:', e)
        }
        audioContext = null
        analyser = null
        mediaElementSource = null
    }

    // åˆ›å»ºæ–°çš„ AudioContext
    if (!audioContext || audioContext.state === 'closed') {
        audioContext = new (window.AudioContext || window.webkitAudioContext)()
    }

    // ç¡®ä¿ AudioContext æ˜¯ running çŠ¶æ€ï¼ˆé‡è¦ï¼šå¦‚æœä½¿ç”¨ MediaElementSourceï¼ŒéŸ³é¢‘å¿…é¡»é€šè¿‡ Web Audio API æ’­æ”¾ï¼‰
    // å¿…é¡»åœ¨åˆ›å»º MediaElementSource ä¹‹å‰æ¢å¤ï¼Œå¦åˆ™éŸ³é¢‘ä¼šæ— å£°
    if (audioContext.state === 'suspended') {
        try {
            await audioContext.resume()
            console.log('AudioContext resumed in initAudioAnalyzer, state:', audioContext.state)
        } catch (e) {
            console.warn('Error resuming AudioContext in initAudioAnalyzer:', e)
            // å¦‚æœæ¢å¤å¤±è´¥ï¼Œä¸è¦åˆ›å»º MediaElementSourceï¼Œè®©éŸ³é¢‘ç›´æ¥æ’­æ”¾
            console.warn('âš ï¸ AudioContext resume failed, skipping MediaElementSource creation to allow direct audio playback')
            return
        }
    }

    // å†æ¬¡ç¡®è®¤ AudioContext æ˜¯ running çŠ¶æ€ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
    if (audioContext.state !== 'running') {
        console.warn('âš ï¸ AudioContext is not running before creating MediaElementSource:', audioContext.state)
        console.warn('Skipping MediaElementSource creation to allow direct audio playback')
        return
    }

    try {
        analyser = audioContext.createAnalyser()
        analyser.fftSize = 256
        // é™ä½å¹³æ»‘ç³»æ•°ï¼Œè®©æ³¢å½¢å˜åŒ–æ›´æ•æ„Ÿã€æ›´æ˜æ˜¾ï¼ˆ0.3 æ¯” 0.8 æ›´æ•æ„Ÿï¼‰
        analyser.smoothingTimeConstant = 0.3

        // åˆ›å»º MediaElementSourceï¼ˆåªèƒ½è°ƒç”¨ä¸€æ¬¡ï¼‰
        // å¦‚æœå·²ç»åˆ›å»ºè¿‡ï¼Œä¼šæŠ›å‡º InvalidStateError
        try {
            mediaElementSource = audioContext.createMediaElementSource(audio)
            // è¿æ¥ï¼šsource -> analyser -> destination
            mediaElementSource.connect(analyser)
            analyser.connect(audioContext.destination)
            console.log('Audio analyzer initialized successfully, AudioContext state:', audioContext.state)

            // å†æ¬¡ç¡®ä¿ AudioContext æ˜¯ running çŠ¶æ€ï¼ˆåˆ›å»º MediaElementSource åï¼‰
            if (audioContext.state === 'suspended') {
                try {
                    await audioContext.resume()
                    console.log('AudioContext resumed after creating MediaElementSource, state:', audioContext.state)
                } catch (e) {
                    console.warn('Error resuming AudioContext after creating MediaElementSource:', e)
                    console.error('âš ï¸ AudioContext is suspended after creating MediaElementSource - audio may be silent!')
                }
            }

            // æœ€ç»ˆéªŒè¯ AudioContext çŠ¶æ€
            if (audioContext.state !== 'running') {
                console.error('âš ï¸ AudioContext is not running after creating MediaElementSource:', audioContext.state)
                console.error('Audio may be silent!')
            }
        } catch (error) {
            // å¦‚æœå·²ç»åˆ›å»ºè¿‡ MediaElementSourceï¼Œè¯´æ˜éŸ³é¢‘å…ƒç´ å·²ç»è¿æ¥åˆ°å¦ä¸€ä¸ª context
            if (error.name === 'InvalidStateError' || error.message.includes('already been created') || error.message.includes('InvalidStateError')) {
                console.warn('MediaElementSource already exists for this audio element, cannot create analyzer')
                // æ— æ³•åˆ›å»ºåˆ†æå™¨ï¼Œä½†ä¸å½±å“éŸ³é¢‘æ’­æ”¾
                // éŸ³é¢‘ä»ç„¶å¯ä»¥é€šè¿‡ audio å…ƒç´ ç›´æ¥æ’­æ”¾ï¼ˆå¦‚æœå®ƒè¿˜æ²¡æœ‰è¢«è¿æ¥åˆ° Web Audio APIï¼‰
                // æˆ–è€…å¦‚æœå·²ç»è¢«è¿æ¥ï¼Œå®ƒä¼šé€šè¿‡ç°æœ‰çš„è¿æ¥æ’­æ”¾
                analyser = null
                mediaElementSource = null
                // ä¸æŠ›å‡ºé”™è¯¯ï¼Œè®©éŸ³é¢‘ç»§ç»­æ’­æ”¾
                return
            } else {
                throw error
            }
        }
    } catch (error) {
        console.error('Error creating audio analyzer:', error)
        analyser = null
        mediaElementSource = null
        // å³ä½¿åˆ†æå™¨åˆ›å»ºå¤±è´¥ï¼Œä¹Ÿä¸åº”è¯¥é˜»æ­¢éŸ³é¢‘æ’­æ”¾
        // éŸ³é¢‘ä»ç„¶å¯ä»¥é€šè¿‡ audio å…ƒç´ ç›´æ¥æ’­æ”¾
    }
}

// æ³¢å½¢å¯è§†åŒ–ï¼ˆä½¿ç”¨çœŸå®éŸ³é¢‘æ•°æ®ï¼‰
function visualize() {
    // æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æºï¼ˆaudio å…ƒç´ æˆ– WebAudioï¼‰
    const hasAudio = audio || (webAudioPlaying && webAudioContext)

    if (!hasAudio || waveformBars.value.length === 0) {
        if (waveformBars.value.length === 0) {
        initWaveform()
        }
        // å¦‚æœæ­£åœ¨ç”Ÿæˆæˆ–æ­£åœ¨æ’­æ”¾ï¼Œç»§ç»­åŠ¨ç”»
        if (isGenerating || (audio && !audio.paused) || (webAudioPlaying && isPlaying.value)) {
            // ç”Ÿæˆæ—¶æˆ–æ’­æ”¾æ—¶ï¼Œæ¸²æŸ“æ¨¡æ‹Ÿæ³¢å½¢å›¾
            if (waveformBars.value.length > 0) {
                renderSimulatedWaveform()
            }
            animationFrameId = requestAnimationFrame(visualize)
        } else {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId)
                animationFrameId = null
            }
        }
        return
    }

    // ä¼˜å…ˆä½¿ç”¨çœŸå®éŸ³é¢‘æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•ä½¿ç”¨é¢„åˆ†æçš„æ³¢å½¢æ•°æ®ï¼ˆè·¨åŸŸéŸ³é¢‘ï¼‰ï¼Œæœ€åå›é€€åˆ°æ¨¡æ‹Ÿæ³¢å½¢
    if (analyser && audioContext && audioContext.state !== 'closed') {
        renderRealWaveform(analyser)
    } else if (webAudioAnalyser && webAudioContext && webAudioContext.state !== 'closed') {
        renderRealWaveform(webAudioAnalyser)
    } else if (crossOriginWaveformData && crossOriginWaveformDataLoaded && isCrossOriginAudio(audio)) {
        // è·¨åŸŸéŸ³é¢‘ï¼šä½¿ç”¨é¢„åˆ†æçš„æ³¢å½¢æ•°æ®
        renderPreAnalyzedWaveform()
    } else {
        // å›é€€åˆ°æ¨¡æ‹Ÿæ³¢å½¢
        renderSimulatedWaveform()
    }

    // æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾æˆ–æ­£åœ¨ç”Ÿæˆ
    const isCurrentlyPlaying = (audio && !audio.paused) || (webAudioPlaying && isPlaying.value)

    if ((isCurrentlyPlaying || isGenerating) && !isDragging) {
        animationFrameId = requestAnimationFrame(visualize)
    } else {
        if (animationFrameId) {
            cancelAnimationFrame(animationFrameId)
            animationFrameId = null
        }
    }
}

// ä½¿ç”¨çœŸå®éŸ³é¢‘æ•°æ®æ¸²æŸ“æ³¢å½¢ï¼ˆå¿ƒç”µå›¾æ ·å¼ï¼Œåæ˜ å®æ—¶éŸ³é‡å˜åŒ–ï¼‰
function renderRealWaveform(analyserNode) {
    if (!analyserNode || waveformBars.value.length === 0) return

    // ä½¿ç”¨æ—¶åŸŸæ•°æ®ï¼ˆå¿ƒç”µå›¾æ ·å¼ï¼‰ï¼Œæ›´å¥½åœ°åæ˜ éŸ³é‡å˜åŒ–
    const bufferLength = analyserNode.frequencyBinCount
    const timeDataArray = new Uint8Array(bufferLength)
    analyserNode.getByteTimeDomainData(timeDataArray)

    // è®¡ç®—æ•´ä½“éŸ³é‡ï¼ˆRMS - å‡æ–¹æ ¹å€¼ï¼‰
    let sumSquares = 0
    for (let i = 0; i < timeDataArray.length; i++) {
        // å°† 0-255 è½¬æ¢ä¸º -128 åˆ° 127
        const sample = (timeDataArray[i] - 128) / 128
        sumSquares += sample * sample
    }
    const rms = Math.sqrt(sumSquares / timeDataArray.length) // RMS å€¼ (0-1)

    // è®¡ç®—æ¯ä¸ª bar å¯¹åº”çš„æ—¶åŸŸæ•°æ®èŒƒå›´
    const barsCount = waveformBars.value.length
    const samplesPerBar = Math.floor(bufferLength / barsCount)

    // æ ¹æ®ä¸»é¢˜åˆ‡æ¢æ³¢å½¢é¢œè‰²
    const isDark = document.documentElement.classList.contains('dark')

    // å¹³æ»‘è¿‡æ¸¡å‚æ•°ï¼šæ§åˆ¶è¿‡æ¸¡é€Ÿåº¦ï¼ˆå€¼è¶Šå°ï¼Œè¿‡æ¸¡è¶Šæ…¢ï¼‰
    const smoothingFactor = 0.05 // æ¯æ¬¡æ›´æ–°ç§»åŠ¨ 5% çš„è·ç¦»ï¼ˆçº¦ 20 å¸§å®Œæˆè¿‡æ¸¡ï¼Œæ›´å¹³æ»‘ï¼‰

    waveformBars.value.forEach((bar, i) => {
        // è®¡ç®—è¯¥ bar å¯¹åº”çš„æ—¶åŸŸæ•°æ®èŒƒå›´
        let sumAmplitude = 0
        let maxAmplitudeInBar = 0
        let count = 0
        const start = i * samplesPerBar
        const end = Math.min(start + samplesPerBar, bufferLength)

        for (let j = start; j < end; j++) {
            // å°† 0-255 è½¬æ¢ä¸º -1 åˆ° 1
            const sample = (timeDataArray[j] - 128) / 128
            const amplitude = Math.abs(sample) // æŒ¯å¹…ï¼ˆç»å¯¹å€¼ï¼‰
            sumAmplitude += amplitude
            count++
            if (amplitude > maxAmplitudeInBar) {
                maxAmplitudeInBar = amplitude
            }
        }

        // è®¡ç®—å¹³å‡æŒ¯å¹…
        const avgAmplitude = count > 0 ? sumAmplitude / count : 0

        // æ··åˆå¹³å‡æŒ¯å¹…å’Œå³°å€¼æŒ¯å¹…ï¼ˆ50% å¹³å‡ + 50% å³°å€¼ï¼‰ï¼Œè®©å³°å€¼æ›´æ˜æ˜¾
        let normalizedAmplitude = avgAmplitude * 0.5 + maxAmplitudeInBar * 0.5

        // ç»“åˆæ•´ä½“éŸ³é‡ï¼ˆRMSï¼‰è¿›è¡ŒåŠ¨æ€è°ƒæ•´ï¼ˆè®©æ³¢å½¢æ›´æ•æ„Ÿåœ°åæ˜ éŸ³é‡å˜åŒ–ï¼‰
        normalizedAmplitude = normalizedAmplitude * 0.6 + rms * 0.4

        // åŠ¨æ€èŒƒå›´å‹ç¼©ï¼šå¢å¼ºå°ä¿¡å·ï¼Œè®©ä½éŸ³é‡ä¹Ÿèƒ½çœ‹åˆ°æ˜æ˜¾å˜åŒ–
        // ä½¿ç”¨æ›´æ¿€è¿›çš„å‹ç¼©ï¼ˆ0.4 æ¬¡æ–¹ï¼‰ï¼Œè®©æ³¢å½¢å˜åŒ–æ›´æ˜æ˜¾
        const compressed = Math.pow(normalizedAmplitude, 0.4)

        // é«˜åº¦èŒƒå›´ï¼š4px åˆ° 76pxï¼ˆå®¹å™¨é«˜åº¦ 80pxï¼Œä»åº•éƒ¨å‘ä¸Šå»¶ä¼¸ï¼Œåƒå¿ƒç”µå›¾ä¸€æ ·ï¼‰
        // éŸ³é‡è¶Šå¤§ï¼Œé«˜åº¦è¶Šé«˜
        const minHeight = 4
        const maxHeight = 76
        const heightRange = maxHeight - minHeight
        const targetHeight = minHeight + compressed * heightRange

        // å¹³æ»‘è¿‡æ¸¡ï¼šä»å½“å‰é«˜åº¦å‘ç›®æ ‡é«˜åº¦ç§»åŠ¨
        // ä½¿ç”¨çº¿æ€§æ’å€¼ï¼ˆLerpï¼‰å®ç°å¹³æ»‘è¿‡æ¸¡
        const currentHeight = bar.height || bar.targetHeight || minHeight
        const heightDiff = targetHeight - currentHeight
        const newHeight = currentHeight + heightDiff * smoothingFactor

        // æ›´æ–°ç›®æ ‡é«˜åº¦ï¼ˆç”¨äºä¸‹æ¬¡è®¡ç®—ï¼‰
        bar.targetHeight = targetHeight

        // æ›´æ–°å½“å‰é«˜åº¦ï¼ˆå¹³æ»‘è¿‡æ¸¡åçš„å€¼ï¼‰
        bar.height = newHeight

        // å¼ºåº¦ç”¨äºæ¸å˜æ•ˆæœï¼ˆåŸºäºæŒ¯å¹…ï¼ŒéŸ³é‡è¶Šå¤§å¼ºåº¦è¶Šé«˜ï¼‰
        const intensity = Math.min(100, normalizedAmplitude * 180) // å¢å¼ºå¼ºåº¦æ˜¾ç¤ºï¼Œè®©å˜åŒ–æ›´æ˜æ˜¾

        // æ›´æ–°å“åº”å¼æ•°æ®
        try {
            bar.intensity = intensity
            bar.isDark = isDark
        } catch (e) {
            console.warn('Error updating waveform bar:', e)
        }
    })
}

// ä½¿ç”¨é¢„åˆ†æçš„æ³¢å½¢æ•°æ®æ¸²æŸ“æ³¢å½¢ï¼ˆè·¨åŸŸéŸ³é¢‘ï¼‰
// æ ¹æ®æ’­æ”¾è¿›åº¦éå†é•¿æ³¢å½¢æ•°æ®ï¼Œæ˜¾ç¤ºå¯¹åº”ä½ç½®çš„æ³¢å½¢æ®µ
// ä½¿ç”¨å¹³æ»‘è¿‡æ¸¡ï¼Œè®©æ³¢å½¢åƒå¿ƒç”µå›¾ä¸€æ ·æµåŠ¨
function renderPreAnalyzedWaveform() {
    if (!crossOriginWaveformData || waveformBars.value.length === 0 || !audio) return

    // è·å–å½“å‰æ’­æ”¾è¿›åº¦
    const currentTime = audio.currentTime || 0
    const duration = audio.duration || 1

    // æ³¢å½¢æ•°æ®æ˜¯æŒ‰ 0.01 ç§’é—´éš”ç”Ÿæˆçš„ï¼Œè®¡ç®—å½“å‰æ—¶é—´å¯¹åº”çš„æ•°æ®ç‚¹ç´¢å¼•
    const dataPointInterval = 0.07 // ç§’ï¼ˆä¸ç”Ÿæˆæ—¶ä¸€è‡´ï¼‰
    const currentDataIndex = Math.floor(currentTime / dataPointInterval)

    const barsCount = waveformBars.value.length
    const dataLength = crossOriginWaveformData.length

    // è®¡ç®—å½“å‰æ˜¾ç¤ºçš„æ³¢å½¢æ•°æ®èŒƒå›´
    // ä»å½“å‰æ’­æ”¾ä½ç½®å¼€å§‹ï¼Œæ˜¾ç¤ºåç»­çš„æ³¢å½¢æ¡ï¼ˆç¬¦åˆè¿›åº¦æ¡çš„é€»è¾‘ï¼‰
    // å¦‚æœæ¥è¿‘ç»“å°¾ï¼Œåˆ™æ˜¾ç¤ºå½“å‰ä½ç½®ä¹‹å‰çš„æ³¢å½¢æ¡ï¼Œç¡®ä¿å§‹ç»ˆæ˜¾ç¤ºæ»¡ 100 ä¸ªæ³¢å½¢æ¡
    let startDataIndex = currentDataIndex
    if (startDataIndex + barsCount > dataLength) {
        // å¦‚æœä»å½“å‰ä½ç½®å¼€å§‹ä¼šè¶…å‡ºèŒƒå›´ï¼Œåˆ™ä»æœ«å°¾å¾€å‰æ¨
        startDataIndex = Math.max(0, dataLength - barsCount)
    }
    const endDataIndex = Math.min(startDataIndex + barsCount, dataLength)

    // æ ¹æ®ä¸»é¢˜åˆ‡æ¢æ³¢å½¢é¢œè‰²
    const isDark = document.documentElement.classList.contains('dark')

    // å¹³æ»‘è¿‡æ¸¡å‚æ•°ï¼šæ§åˆ¶è¿‡æ¸¡é€Ÿåº¦ï¼ˆå€¼è¶Šå°ï¼Œè¿‡æ¸¡è¶Šæ…¢ï¼‰
    const smoothingFactor = 0.2 // æ¯æ¬¡æ›´æ–°ç§»åŠ¨ 15% çš„è·ç¦»ï¼ˆçº¦ 6-7 å¸§å®Œæˆè¿‡æ¸¡ï¼‰

    waveformBars.value.forEach((bar, i) => {
        // è®¡ç®—å¯¹åº”çš„æ•°æ®ç´¢å¼•
        const dataIndex = startDataIndex + i

        // å¦‚æœè¶…å‡ºæ•°æ®èŒƒå›´ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªæ•°æ®æˆ–æœ€å°å€¼
        let amplitude = 0
        if (dataIndex >= 0 && dataIndex < dataLength) {
            amplitude = crossOriginWaveformData[dataIndex]
        } else if (dataLength > 0 && dataIndex >= dataLength) {
            // è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªæ•°æ®
            amplitude = crossOriginWaveformData[dataLength - 1]
        } else if (dataIndex < 0) {
            // åœ¨å¼€å§‹ä¹‹å‰ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°æ®
            amplitude = dataLength > 0 ? crossOriginWaveformData[0] : 0
        }

        // å½’ä¸€åŒ–æŒ¯å¹…ï¼šå°† [min, max] æ˜ å°„åˆ° [0, 1]
        // è¿™æ ·å³ä½¿æŒ¯å¹…å·®å¼‚å¾ˆå°ï¼Œä¹Ÿèƒ½å……åˆ†åˆ©ç”¨æ•´ä¸ªé«˜åº¦èŒƒå›´
        let normalized = 0
        const amplitudeRange = crossOriginWaveformMax - crossOriginWaveformMin
        if (amplitudeRange > 0) {
            // çº¿æ€§æ˜ å°„ï¼šå°† [min, max] æ˜ å°„åˆ° [0, 1]
            normalized = (amplitude - crossOriginWaveformMin) / amplitudeRange
            normalized = Math.max(0, Math.min(1, normalized)) // ç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…
        } else {
            // å¦‚æœæ‰€æœ‰å€¼éƒ½ç›¸åŒï¼Œä½¿ç”¨ 0.5ï¼ˆä¸­é—´å€¼ï¼‰
            normalized = 0.5
        }

        // åŠ¨æ€èŒƒå›´å‹ç¼©ï¼šå¢å¼ºå°ä¿¡å·ï¼ˆå¯é€‰ï¼Œå¦‚æœå¸Œæœ›æ›´å¹³æ»‘çš„è¿‡æ¸¡ï¼‰
        // const compressed = Math.pow(normalized, 0.4)
        const compressed = normalized

        // é«˜åº¦èŒƒå›´ï¼š4px åˆ° 76pxï¼ˆä»åº•éƒ¨å‘ä¸Šå»¶ä¼¸ï¼Œåƒå¿ƒç”µå›¾ä¸€æ ·ï¼‰
        const minHeight = 1
        const maxHeight = 150
        const heightRange = maxHeight - minHeight
        const targetHeight = minHeight + compressed * heightRange

        // å¹³æ»‘è¿‡æ¸¡ï¼šä»å½“å‰é«˜åº¦å‘ç›®æ ‡é«˜åº¦ç§»åŠ¨
        // ä½¿ç”¨çº¿æ€§æ’å€¼ï¼ˆLerpï¼‰å®ç°å¹³æ»‘è¿‡æ¸¡
        const currentHeight = bar.height || bar.targetHeight || minHeight
        const heightDiff = targetHeight - currentHeight
        const newHeight = currentHeight + heightDiff * smoothingFactor

        // æ›´æ–°ç›®æ ‡é«˜åº¦ï¼ˆç”¨äºä¸‹æ¬¡è®¡ç®—ï¼‰
        bar.targetHeight = targetHeight

        // æ›´æ–°å½“å‰é«˜åº¦ï¼ˆå¹³æ»‘è¿‡æ¸¡åçš„å€¼ï¼‰
        bar.height = newHeight

        // å¼ºåº¦ç”¨äºæ¸å˜æ•ˆæœï¼ˆä½¿ç”¨å½’ä¸€åŒ–åçš„å€¼ï¼‰
        const intensity = Math.min(100, normalized * 50 + 50)
        bar.intensity = bar.height * 0.8
        bar.isDark = isDark
    })
}

// æ¨¡æ‹Ÿæ³¢å½¢æ¸²æŸ“ï¼ˆå›é€€æ–¹æ¡ˆï¼‰
let simulatedWaveformStartTime = null  // æ¨¡æ‹Ÿæ³¢å½¢åŠ¨ç”»å¼€å§‹æ—¶é—´

function renderSimulatedWaveform() {
    if (waveformBars.value.length === 0) return

    // è·å–å½“å‰æ—¶é—´ï¼šä¼˜å…ˆä½¿ç”¨ WebAudio æ—¶é—´ï¼Œå¦åˆ™ä½¿ç”¨ audio å…ƒç´ æ—¶é—´ï¼Œæœ€åä½¿ç”¨ç”Ÿæˆæ—¶çš„æ¨¡æ‹Ÿæ—¶é—´
    let currentTime = 0
    let duration = 1

    if (webAudioPlaying && webAudioContext) {
        // WebAudio æµå¼æ’­æ”¾æ¨¡å¼
        currentTime = webAudioCurrentTime
        duration = webAudioTotalDuration || 1
    } else if (audio) {
        // ä¼ ç»Ÿ audio å…ƒç´ æ’­æ”¾æ¨¡å¼
        currentTime = audio.currentTime || 0
        duration = audio.buffered && audio.buffered.length > 0
            ? audio.buffered.end(audio.buffered.length - 1)
            : (audio.duration || 1)
    } else if (isGenerating) {
        // ç”Ÿæˆæ—¶ï¼šä½¿ç”¨åŸºäºæ—¶é—´çš„åŠ¨ç”»
        if (!simulatedWaveformStartTime) {
            simulatedWaveformStartTime = Date.now()
        }
        // ä½¿ç”¨ç»è¿‡çš„æ—¶é—´ä½œä¸ºè¿›åº¦ï¼ˆå¾ªç¯åŠ¨ç”»ï¼‰
        const elapsed = (Date.now() - simulatedWaveformStartTime) / 1000  // ç§’
        currentTime = elapsed % 10  // 10ç§’å¾ªç¯
        duration = 10
    }

    const progress = duration > 0 ? currentTime / duration : 0

    // æ ¹æ®ä¸»é¢˜åˆ‡æ¢æ³¢å½¢é¢œè‰²
    const isDark = document.documentElement.classList.contains('dark')

    waveformBars.value.forEach((bar, i) => {
        const position = i / waveformBars.value.length
        const wave1 = Math.sin(position * Math.PI * 4 + progress * Math.PI * 2) * 0.5
        const wave2 = Math.sin(position * Math.PI * 8 + progress * Math.PI * 4) * 0.3
        const wave3 = Math.sin(position * Math.PI * 2 + progress * Math.PI * 1.5) * 0.2
        const wave4 = Math.sin(position * Math.PI * 5 + progress * Math.PI * 2.3) * 0.12
        const wave5 = Math.sin(position * Math.PI * 7 + progress * Math.PI * 0.9) * 0.09
        const wave6 = Math.sin(position * Math.PI * 3.3 + progress * Math.PI * 2.7) * 0.13
        const wave7 = Math.sin(position * Math.PI * 1.5 + progress * Math.PI * 6.2) * 0.08
        const wave8 = Math.cos(position * Math.PI * 6 + progress * Math.PI * 1.5) * 0.11
        const wave9 = Math.sin(position * Math.PI * 9 + progress * Math.PI * 3.5) * 0.07
        const wave10 = Math.cos(position * Math.PI * 4 + progress * Math.PI * 2.8) * 0.15
        const wave11 = Math.sin(position * Math.PI * 8.5 + progress * Math.PI * 1.1) * 0.06
        const wave12 = Math.cos(position * Math.PI * 2.7 + progress * Math.PI * 4.2) * 0.1
        const combined = (wave1 + wave2 + wave3 + wave4 + wave5 + wave6 + wave7 + wave8 + wave9 + wave10 + wave11 + wave12 + 1) / 2
        // é«˜åº¦èŒƒå›´ï¼š10px åˆ° 50pxï¼ˆå®¹å™¨é«˜åº¦60pxï¼Œpadding 10pxï¼Œå®é™…å¯ç”¨40pxï¼‰
        const height = 1 + combined * 49
        const intensity = combined * 100

        // æ›´æ–°å“åº”å¼æ•°æ®
        try {
            bar.height = height
            bar.intensity = intensity
            bar.isDark = isDark
        } catch (e) {
            console.warn('Error updating waveform bar:', e)
        }
    })
}

// è®¾ç½®éŸ³é¢‘äº‹ä»¶ç›‘å¬å™¨
function setupAudioEventListeners() {
    if (!audio || !audioElement.value) return

    // ç§»é™¤æ—§çš„äº‹ä»¶ç›‘å¬å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    audio.removeEventListener('loadedmetadata', onAudioLoadedMetadata)
    audio.removeEventListener('canplay', onAudioCanPlay)
    audio.removeEventListener('timeupdate', onAudioTimeUpdate)
    audio.removeEventListener('ended', onAudioEnded)
    audio.removeEventListener('play', onAudioPlay)
    audio.removeEventListener('pause', onAudioPause)
    audio.removeEventListener('error', onAudioError)

    // æ·»åŠ æ–°çš„äº‹ä»¶ç›‘å¬å™¨
    audio.addEventListener('loadedmetadata', onAudioLoadedMetadata)
    audio.addEventListener('canplay', onAudioCanPlay)
    audio.addEventListener('timeupdate', onAudioTimeUpdate)
    audio.addEventListener('ended', onAudioEnded)
    audio.addEventListener('play', onAudioPlay)
    audio.addEventListener('pause', onAudioPause)
    audio.addEventListener('error', onAudioError)
}

let hasLoadedMetadata = false
let analyzerInitialized = false

function onAudioLoadedMetadata() {
    if (hasLoadedMetadata || !audio) return
    hasLoadedMetadata = true

    try {
        console.log('Audio loadedmetadata:', {
            duration: audio.duration,
            readyState: audio.readyState,
            src: audio.src.substring(0, 100)
        })

        // åœ¨è¯¦æƒ…æ¨¡å¼ä¸‹æ˜¾ç¤ºæ’­æ”¾å™¨
        if (isDetailMode.value) {
            showPlayer.value = true
        }

        const total = getDisplayedDuration()
        if (total > 0) {
            duration.value = total
            // åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨ï¼ˆç”¨äºæ³¢å½¢å›¾ï¼‰
            if (!analyzerInitialized) {
                initAudioAnalyzer().then(() => {
                    analyzerInitialized = true
                    console.log('Audio analyzer initialized successfully')
                }).catch(error => {
                    console.error('Error initializing audio analyzer:', error)
                })
            }
        }
    } catch (e) {
        console.warn('Error in onAudioLoadedMetadata:', e)
    }
}

function onAudioCanPlay() {
    if (!audio) return

    try {
        console.log('Audio canplay event:', {
            readyState: audio.readyState,
            paused: audio.paused,
            volume: audio.volume
        })
        // éŸ³é¢‘å¯ä»¥æ’­æ”¾æ—¶ï¼Œç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        if (!analyzerInitialized && audio.readyState >= HTMLMediaElement.HAVE_METADATA) {
            initAudioAnalyzer().then(() => {
                analyzerInitialized = true
                console.log('Audio analyzer initialized in canplay event')
            }).catch(error => {
                console.error('Error initializing audio analyzer:', error)
            })
        }
    } catch (e) {
        console.warn('Error in onAudioCanPlay:', e)
    }
}

function onAudioTimeUpdate() {
    if (!isDragging && audio) {
        try {
            currentTime.value = audio.currentTime
            const total = getDisplayedDuration()
            if (total > 0) {
                progress.value = (audio.currentTime / total) * 100
                duration.value = total
            }
            updateActiveSubtitleForStreaming(audio.currentTime)
        } catch (e) {
            console.warn('Error in onAudioTimeUpdate:', e)
        }
    }
}

function onAudioEnded() {
    try {
        isPlaying.value = false
    } catch (e) {
        console.warn('Error in onAudioEnded:', e)
    }
}

function onAudioPlay() {
    try {
        isPlaying.value = true
        // å¯åŠ¨æ³¢å½¢å›¾å¯è§†åŒ–
        if (!animationFrameId) {
            visualize()
        }
    } catch (e) {
        console.warn('Error in onAudioPlay:', e)
    }
}

function onAudioPause() {
    try {
        isPlaying.value = false
    } catch (e) {
        console.warn('Error in onAudioPause:', e)
    }
}

function onAudioError(e) {
    try {
        console.error('Audio error:', e, audio?.error)

        // æ£€æŸ¥éŸ³é¢‘çŠ¶æ€ï¼Œå¦‚æœè¿˜åœ¨åŠ è½½ä¸­ï¼Œä¸ç«‹å³æ˜¾ç¤ºé”™è¯¯
        if (audio && audio.readyState === HTMLMediaElement.HAVE_NOTHING) {
            // éŸ³é¢‘è¿˜åœ¨åŠ è½½ä¸­ï¼Œå¯èƒ½æ˜¯ç½‘ç»œå»¶è¿Ÿï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†åˆ¤æ–­
            console.log('Audio still loading, waiting before showing error...')
            setTimeout(() => {
                // å†æ¬¡æ£€æŸ¥ï¼Œå¦‚æœä»ç„¶å‡ºé”™ä¸”æ²¡æœ‰åŠ è½½ä»»ä½•æ•°æ®ï¼Œæ‰æ˜¾ç¤ºé”™è¯¯
                if (audio && audio.readyState === HTMLMediaElement.HAVE_NOTHING && audio.error) {
                    const errorCode = audio.error.code
                    // MEDIA_ERR_ABORTED (1) é€šå¸¸æ˜¯ç”¨æˆ·æ“ä½œå¯¼è‡´çš„ï¼Œä¸æ˜¾ç¤ºé”™è¯¯
                    if (errorCode !== 1) {
                        showAlert(t('podcast.audioLoadFailedNetwork'), 'error')
                    }
                }
            }, 3000) // ç­‰å¾… 3 ç§’
            return
        }

        // å¦‚æœå·²ç»æœ‰å…ƒæ•°æ®æˆ–å¯ä»¥æ’­æ”¾ï¼Œè¯´æ˜ä¸æ˜¯åŠ è½½é—®é¢˜
        if (audio && audio.readyState >= HTMLMediaElement.HAVE_METADATA) {
            console.log('Audio has metadata, error might be non-critical')
            return
        }

        // æ£€æŸ¥é”™è¯¯ä»£ç 
        if (audio?.error) {
            const errorCode = audio.error.code
            // MEDIA_ERR_ABORTED (1) é€šå¸¸æ˜¯ç”¨æˆ·æ“ä½œå¯¼è‡´çš„ï¼Œä¸æ˜¾ç¤ºé”™è¯¯
            if (errorCode === 1) {
                console.log('Audio error is ABORTED, likely user action, not showing error')
                return
            }
        }
    } catch (err) {
        console.warn('Error in onAudioError:', err)
    }
}

// æ’­æ”¾/æš‚åœ
async function togglePlayback() {
    // ä½¿ç”¨ template ä¸­çš„ audio å…ƒç´ 
    if (!audio || !audioElement.value) {
        // å¦‚æœ audio å˜é‡æœªåˆå§‹åŒ–ï¼Œå°è¯•åˆå§‹åŒ–
        if (audioElement.value) {
            audio = audioElement.value
            setupAudioEventListeners()
        } else {
            return
        }
    }

    if (audio.readyState === HTMLMediaElement.HAVE_NOTHING) {
        statusMsg.value = t('podcast.audioLoading')
        return
    }

    if (audio.paused) {
        try {
            // ç¡®ä¿éŸ³é‡è®¾ç½®ä¸º 1.0ï¼ˆé‡è¦ï¼šé¿å…æ— å£°ï¼‰
            audio.volume = 1.0
            // ç¡®ä¿éŸ³é¢‘å…ƒç´ æœªè¢«é™éŸ³ï¼ˆé‡è¦ï¼šé¿å…æ— å£°ï¼‰
            audio.muted = false

            // åˆå§‹åŒ–æ³¢å½¢å›¾ï¼ˆåœ¨æ’­æ”¾å‰åˆå§‹åŒ–ï¼Œé¿å…å»¶è¿Ÿï¼‰
            if (waveformBars.value.length === 0) {
                initWaveform()
            }

            // æ£€æŸ¥éŸ³é¢‘æ˜¯å¦è·¨åŸŸï¼Œå¦‚æœæ˜¯è·¨åŸŸä¸”å·²æœ‰ MediaElementSourceï¼Œéœ€è¦æ¸…ç†ï¼ˆé¿å… CORS é™åˆ¶å¯¼è‡´æ— å£°ï¼‰
            if (isCrossOriginAudio(audio) && mediaElementSource) {
                console.warn('âš ï¸ Audio is cross-origin but MediaElementSource exists, cleaning up to avoid CORS restrictions')
                // æ–­å¼€è¿æ¥
                try {
                    if (mediaElementSource) {
                        mediaElementSource.disconnect()
                    }
                    if (analyser) {
                        analyser.disconnect()
                    }
                } catch (e) {
                    console.warn('Error disconnecting MediaElementSource:', e)
                }
                mediaElementSource = null
                analyser = null
            }

            // ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–ï¼ˆåœ¨ç”¨æˆ·äº¤äº’æ—¶åˆå§‹åŒ–ï¼Œç¡®ä¿ AudioContext å¯ä»¥æ¢å¤ï¼‰
            // æ³¨æ„ï¼šå¦‚æœ MediaElementSource å·²å­˜åœ¨ä¸”éŸ³é¢‘ä¸æ˜¯è·¨åŸŸï¼Œä¸éœ€è¦é‡æ–°åˆ›å»º
            if (!mediaElementSource) {
                try {
                    await initAudioAnalyzer()
                    console.log('Audio analyzer initialized in togglePlayback')
                } catch (e) {
                    console.log('Analyzer init on play failed (non-critical):', e)
                    // åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥ä¸å½±å“éŸ³é¢‘æ’­æ”¾
                }
            }

            // ç¡®ä¿ AudioContext å·²æ¢å¤ï¼ˆå¦‚æœè¢«æš‚åœï¼‰
            // æ³¨æ„ï¼šå¦‚æœä½¿ç”¨äº† MediaElementSourceï¼ŒéŸ³é¢‘å¿…é¡»é€šè¿‡ Web Audio API æ’­æ”¾ï¼Œæ‰€ä»¥ AudioContext å¿…é¡»æ˜¯ running çŠ¶æ€
            // ä½†è·¨åŸŸéŸ³é¢‘ä¸ä½¿ç”¨ MediaElementSourceï¼Œæ‰€ä»¥ä¸éœ€è¦ AudioContext
            if (audioContext && !isCrossOriginAudio(audio)) {
                if (audioContext.state === 'suspended') {
                    try {
                        await audioContext.resume()
                        console.log('AudioContext resumed before play, state:', audioContext.state)
                    } catch (e) {
                        console.warn('Error resuming AudioContext:', e)
                        // AudioContext æ¢å¤å¤±è´¥å¯èƒ½å½±å“æ’­æ”¾ï¼ˆå¦‚æœä½¿ç”¨äº† MediaElementSourceï¼‰
                        if (mediaElementSource) {
                            console.error('âš ï¸ AudioContext resume failed but MediaElementSource exists - audio may be silent!')
                            showAlert(t('podcast.audioMayBeSilent'), 'warning')
                        }
                    }
                }
                // å¦‚æœ AudioContext å·²å…³é—­ï¼Œéœ€è¦é‡æ–°åˆ›å»ºï¼ˆå¦‚æœä½¿ç”¨äº† MediaElementSourceï¼‰
                if (audioContext.state === 'closed' && mediaElementSource) {
                    console.warn('AudioContext closed but MediaElementSource exists, reinitializing analyzer')
                    try {
                        // æ¸…ç†æ—§çš„è¿æ¥
                        mediaElementSource = null
                        analyser = null
                        await initAudioAnalyzer()
                    } catch (e) {
                        console.warn('Error reinitializing analyzer:', e)
                    }
                }
            }

            // æ’­æ”¾éŸ³é¢‘
            console.log('Attempting to play audio:', {
                readyState: audio.readyState,
                src: audio.src ? audio.src.substring(0, 100) : 'no src',
                currentSrc: audio.currentSrc ? audio.currentSrc.substring(0, 100) : 'no currentSrc',
                volume: audio.volume,
                muted: audio.muted,
                paused: audio.paused,
                audioContextState: audioContext ? audioContext.state : 'no context',
                hasMediaElementSource: !!mediaElementSource,
                hasAnalyser: !!analyser
            })

            await audio.play()
            isPlaying.value = true
            console.log('Audio playing successfully, AudioContext state:', audioContext ? audioContext.state : 'no context')

            // å¦‚æœä½¿ç”¨äº† MediaElementSourceï¼Œå†æ¬¡ç¡®ä¿ AudioContext æ˜¯ running çŠ¶æ€
            // æ³¨æ„ï¼šè·¨åŸŸéŸ³é¢‘ä¸åº”è¯¥ä½¿ç”¨ MediaElementSourceï¼ˆå·²åœ¨å‰é¢æ¸…ç†ï¼‰
            if (mediaElementSource && audioContext && !isCrossOriginAudio(audio)) {
                if (audioContext.state === 'suspended') {
                    try {
                        await audioContext.resume()
                        console.log('AudioContext resumed after play, state:', audioContext.state)
                    } catch (e) {
                        console.warn('Error resuming AudioContext after play:', e)
                        console.error('âš ï¸ AudioContext is suspended after play - audio may be silent!')
                    }
                }
                // éªŒè¯è¿æ¥æ˜¯å¦æ­£å¸¸
                if (audioContext.state !== 'running') {
                    console.error('âš ï¸ AudioContext is not running after play:', audioContext.state)
                    console.error('This may cause audio to be silent when using MediaElementSource')
                }
            } else if (isCrossOriginAudio(audio)) {
                // è·¨åŸŸéŸ³é¢‘ç›´æ¥æ’­æ”¾ï¼Œä¸ä½¿ç”¨ MediaElementSource
                console.log('âœ… Cross-origin audio playing directly (no MediaElementSource)')
            }

            // å¯åŠ¨å¯è§†åŒ–
            if (!animationFrameId) {
                visualize()
            }
        } catch (error) {
            console.error('Error playing audio:', error)
            isPlaying.value = false
            statusMsg.value = t('podcast.playbackFailed')
            showAlert(t('podcast.playbackFailedWithError', { error: error.message }), 'error')
        }
    } else {
        audio.pause()
        isPlaying.value = false
        if (animationFrameId) {
            cancelAnimationFrame(animationFrameId)
            animationFrameId = null
        }
    }
}

// è·å–éŸ³é¢‘æ—¶é•¿
function getAudioDuration() {
    if (!audio) return 0
    if (audio.buffered && audio.buffered.length > 0) {
        return audio.buffered.end(audio.buffered.length - 1)
    }
    if (audio.seekable && audio.seekable.length > 0) {
        return audio.seekable.end(audio.seekable.length - 1)
    }
    if (Number.isFinite(audio.duration)) {
        return audio.duration || 0
    }
    return 0
}

function getDisplayedDuration() {
    const d = getAudioDuration()
    if (!Number.isFinite(d) || d <= 0) return 0
    return d
}

// æ ¼å¼åŒ–æ—¶é—´
function formatTime(seconds) {
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    return `${String(mins).padStart(2, '0')}:${String(secs).padStart(2, '0')}`
}

// è¿›åº¦æ¡æ›´æ–°ï¼ˆä¸åŸå§‹ HTML å®Œå…¨ä¸€è‡´ï¼‰
function updateProgress(e) {
    if (!audio || !progressContainer.value) return

    const duration = getAudioDuration()
    if (duration === 0) return

    const rect = progressContainer.value.getBoundingClientRect()
    const clientX = (e && e.touches && e.touches[0]) ? e.touches[0].clientX : e.clientX
    const percent = Math.max(0, Math.min(1, (clientX - rect.left) / rect.width))
    const newTime = percent * duration

    // è®¾ç½®æ’­æ”¾ä½ç½®
    audio.currentTime = newTime

    // æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
    progress.value = percent * 100
    currentTime.value = newTime

    // ç‚¹å‡»è¿›åº¦æ¡æ—¶ï¼Œç¡®ä¿è‡ªåŠ¨è·Ÿéšå­—å¹•
    autoFollowSubtitles = true

    // æ¸…é™¤ä¹‹å‰çš„æ»šåŠ¨å®šæ—¶å™¨ï¼ˆé¿å…ä¸ç«‹å³æ»šåŠ¨å†²çªï¼‰
    if (scrollThrottleTimer) {
        clearTimeout(scrollThrottleTimer)
        scrollThrottleTimer = null
    }

    // æ›´æ–°å­—å¹•é«˜äº®
    updateActiveSubtitleForStreaming(newTime)

    // å¦‚æœå­—å¹•åŒºåŸŸå·²æ˜¾ç¤ºï¼Œç«‹å³æ»šåŠ¨åˆ°å¯¹åº”å­—å¹•ï¼ˆä¸ç­‰å¾…èŠ‚æµï¼‰
    if (showSubtitles.value && subtitleSection.value && subtitleTimestamps.value.length > 0) {
        // æ‰¾åˆ°å¯¹åº”æ—¶é—´ç‚¹çš„å­—å¹•ç´¢å¼•
        let targetIndex = -1
        for (let i = 0; i < subtitleTimestamps.value.length; i++) {
            if (newTime >= subtitleTimestamps.value[i].start && newTime <= subtitleTimestamps.value[i].end) {
                targetIndex = i
                break
            }
        }

        // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œæ‰¾åˆ°æœ€è¿‘çš„
        if (targetIndex === -1 && subtitleTimestamps.value.length > 0) {
            if (newTime >= subtitleTimestamps.value[subtitleTimestamps.value.length - 1].end) {
                targetIndex = subtitleTimestamps.value.length - 1
            } else {
                for (let i = 0; i < subtitleTimestamps.value.length; i++) {
                    if (newTime < subtitleTimestamps.value[i].start) {
                        targetIndex = Math.max(0, i - 1)
                        break
                    }
                }
            }
        }

        // ç«‹å³æ»šåŠ¨åˆ°å¯¹åº”å­—å¹•
        if (targetIndex >= 0) {
            nextTick().then(() => {
                const targetSubtitleEl = subtitleSection.value?.querySelector(`#subtitle-${targetIndex}`)
                if (targetSubtitleEl && subtitleSection.value) {
                    const container = subtitleSection.value
                    const containerRect = container.getBoundingClientRect()
                    const elementRect = targetSubtitleEl.getBoundingClientRect()

                    // è®¡ç®—å…ƒç´ ç›¸å¯¹äºå®¹å™¨çš„ä½ç½®
                    const elementTop = elementRect.top - containerRect.top + container.scrollTop
                    const elementHeight = elementRect.height
                    const containerHeight = container.clientHeight

                    // è®¡ç®—æ»šåŠ¨ä½ç½®ï¼Œä½¿å…ƒç´ åœ¨å®¹å™¨ä¸­é—´
                    const scrollTop = elementTop - (containerHeight / 2) + (elementHeight / 2)

                    // å¹³æ»‘æ»šåŠ¨åˆ°ç›®æ ‡ä½ç½®
                    container.scrollTo({
                        top: Math.max(0, scrollTop),
                        behavior: 'smooth'
                    })
                }
            })
        }
    }
}

// è¿›åº¦æ¡ç‚¹å‡»
function onProgressClick(e) {
    updateProgress(e)
}

// è¿›åº¦æ¡æ‹–æ‹½ï¼ˆé¼ æ ‡ï¼‰
function onProgressMouseDown(e) {
    if (!audio) return
    const duration = getAudioDuration()
    if (duration === 0) return
    isDragging = true
    updateProgress(e)
}

function onProgressMouseMove(e) {
    if (isDragging) {
        updateProgress(e)
    }
}

function onProgressMouseUp() {
    if (isDragging) {
        isDragging = false
    }
    // æ‹–æ‹½ç»“æŸåï¼Œå¦‚æœæ­£åœ¨æ’­æ”¾ä¸”æ²¡æœ‰åŠ¨ç”»å¸§ï¼Œæ¢å¤å¯è§†åŒ–
    if (audio && !audio.paused && !animationFrameId) {
        visualize()
    }
}

// è¿›åº¦æ¡æ‹–æ‹½ï¼ˆè§¦æ‘¸ï¼‰
function onProgressTouchStart(e) {
    if (!audio) return
    const duration = getAudioDuration()
    if (duration === 0) return
    isDragging = true
    updateProgress(e)
}

function onProgressTouchMove(e) {
    if (isDragging) {
        updateProgress(e)
    }
}

function onProgressTouchEnd() {
    if (isDragging) {
        isDragging = false
    }
    if (audio && !audio.paused && !animationFrameId) {
        visualize()
    }
}

// å½“å‰æ¿€æ´»çš„å­—å¹•ç´¢å¼•ï¼ˆå“åº”å¼ï¼‰
const activeSubtitleIndex = ref(-1)
// ä¸Šæ¬¡æ›´æ–°çš„ç´¢å¼•ï¼Œç”¨äºé¿å…ä¸å¿…è¦çš„æ›´æ–°
let lastActiveSubtitleIndex = -1
// æ»šåŠ¨èŠ‚æµå®šæ—¶å™¨
let scrollThrottleTimer = null

// æ›´æ–°å­—å¹•é«˜äº®ï¼ˆä¸å‚è€ƒ HTML å®Œå…¨ä¸€è‡´ï¼Œæ”¯æŒ WebAudio å’Œä¼ ç»Ÿ audio æ¨¡å¼ï¼‰
async function updateActiveSubtitleForStreaming(currentTime) {
    // æ£€æŸ¥æ˜¯å¦æœ‰å­—å¹•æ•°æ®
    if (subtitles.value.length === 0 || subtitleTimestamps.value.length === 0) {
        if (activeSubtitleIndex.value !== -1) {
            activeSubtitleIndex.value = -1
            lastActiveSubtitleIndex = -1
        }
        return
    }

    // æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æºï¼ˆaudio å…ƒç´ æˆ– WebAudioï¼‰
    const hasAudio = audio || (webAudioPlaying && webAudioContext)
    if (!hasAudio) return

    // å¯¹äºä¼ ç»Ÿ audio å…ƒç´ ï¼Œæ£€æŸ¥ duration
    if (audio && audio.duration === 0) return

    // æ ¹æ®æ—¶é—´æˆ³æ‰¾åˆ°å½“å‰æ’­æ”¾çš„å­—å¹•
    let currentIndex = -1
    for (let i = 0; i < subtitleTimestamps.value.length; i++) {
        if (currentTime >= subtitleTimestamps.value[i].start && currentTime <= subtitleTimestamps.value[i].end) {
            currentIndex = i
            break
        }
    }

    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•æ‰¾åˆ°æœ€è¿‘çš„
    if (currentIndex === -1 && subtitleTimestamps.value.length > 0) {
        // å¦‚æœæ—¶é—´è¶…è¿‡äº†æœ€åä¸€ä¸ªå­—å¹•ï¼Œæ˜¾ç¤ºæœ€åä¸€ä¸ª
        if (currentTime >= subtitleTimestamps.value[subtitleTimestamps.value.length - 1].end) {
            currentIndex = subtitleTimestamps.value.length - 1
        } else {
            // æ‰¾åˆ°æœ€è¿‘çš„å­—å¹•
            for (let i = 0; i < subtitleTimestamps.value.length; i++) {
                if (currentTime < subtitleTimestamps.value[i].start) {
                    currentIndex = Math.max(0, i - 1)
                    break
                }
            }
        }
    }

    // åªåœ¨ç´¢å¼•çœŸæ­£å˜åŒ–æ—¶æ‰æ›´æ–°ï¼Œé¿å…ä¸å¿…è¦çš„ DOM æ“ä½œ
    if (currentIndex !== lastActiveSubtitleIndex) {
        activeSubtitleIndex.value = currentIndex
        lastActiveSubtitleIndex = currentIndex

        // è‡ªåŠ¨æ»šåŠ¨åˆ°å½“å‰å­—å¹•ï¼ˆä»…å½“å¼€å¯è‡ªåŠ¨è·Ÿéšæ—¶ï¼Œä½¿ç”¨èŠ‚æµé¿å…é¢‘ç¹æ»šåŠ¨ï¼‰
        if (autoFollowSubtitles && currentIndex >= 0 && subtitleSection.value && subtitleSection.value.parentElement) {
            // æ¸…é™¤ä¹‹å‰çš„æ»šåŠ¨å®šæ—¶å™¨
            if (scrollThrottleTimer) {
                clearTimeout(scrollThrottleTimer)
            }

            // ä½¿ç”¨èŠ‚æµï¼Œé¿å…é¢‘ç¹æ»šåŠ¨å¯¼è‡´å¡é¡¿
            scrollThrottleTimer = setTimeout(async () => {
                try {
                    await nextTick()
                    if (!subtitleSection.value || !subtitleSection.value.parentElement) {
                        return
                    }
                    const currentSubtitleEl = subtitleSection.value.querySelector(`#subtitle-${currentIndex}`)
                    if (currentSubtitleEl && currentSubtitleEl.parentElement) {
                        // åªåœ¨å­—å¹•å®¹å™¨å†…æ»šåŠ¨ï¼Œä¸å½±å“å¤–éƒ¨ç»„ä»¶
                        const container = subtitleSection.value
                        const containerRect = container.getBoundingClientRect()
                        const elementRect = currentSubtitleEl.getBoundingClientRect()

                        // è®¡ç®—å…ƒç´ ç›¸å¯¹äºå®¹å™¨çš„ä½ç½®
                        const elementTop = elementRect.top - containerRect.top + container.scrollTop
                        const elementHeight = elementRect.height
                        const containerHeight = container.clientHeight

                        // è®¡ç®—æ»šåŠ¨ä½ç½®ï¼Œä½¿å…ƒç´ åœ¨å®¹å™¨ä¸­é—´
                        const scrollTop = elementTop - (containerHeight / 2) + (elementHeight / 2)

                        // å¹³æ»‘æ»šåŠ¨åˆ°ç›®æ ‡ä½ç½®
                        container.scrollTo({
                            top: Math.max(0, scrollTop),
                            behavior: 'smooth'
                        })
                    }
                } catch (e) {
                    // å¿½ç•¥ DOM æ“ä½œé”™è¯¯ï¼ˆå¯èƒ½ç»„ä»¶å·²å¸è½½ï¼‰
                    console.warn('Error scrolling to subtitle:', e)
                }
                scrollThrottleTimer = null
            }, 100) // 100ms èŠ‚æµï¼Œå‡å°‘æ»šåŠ¨é¢‘ç‡
        }
    }
}

// å­—å¹•ç‚¹å‡»è·³è½¬
function onSubtitleClick(index) {
    if (!audio || !subtitleTimestamps.value[index]) return

    const jumpTime = subtitleTimestamps.value[index].start ?? 0
    const duration = getAudioDuration() || audio.duration || 0
    const targetTime = Math.max(0, Math.min(duration, jumpTime))

    try {
        audio.currentTime = targetTime
        // ç‚¹å‡»è§†ä¸º"è·Ÿéšå½“å‰å­—å¹•"çš„æ„å›¾
        autoFollowSubtitles = true
        // ç«‹å³æ›´æ–°é«˜äº®
        updateActiveSubtitleForStreaming(targetTime)
    } catch (error) {
        console.error('Error jumping to subtitle:', error)
    }
}

// åˆ‡æ¢å­—å¹•æ˜¾ç¤º
function toggleSubtitles() {
    showSubtitles.value = !showSubtitles.value
}

// MediaSource æ–¹å¼åˆå§‹åŒ–éŸ³é¢‘ï¼ˆæ¨èï¼Œæ”¯æŒæ— ç¼æµå¼æ›´æ–°ï¼‰
async function initMediaSourceAudio(autoPlay = false) {
    if (isIOSSafari()) {
        // iOS Safari å¯¹ MSE æ”¯æŒæœ‰é™ï¼Œç›´æ¥å›é€€
        return loadAudio(autoPlay)
    }
    if (!mergedAudioUrl) return

    console.log('ğŸµ Initializing MediaSource audio...')

    try {
        // ä¼˜å…ˆä½¿ç”¨ template ä¸­çš„ audioElement
        if (!audioElement.value) {
            console.warn('audioElement not available, waiting...')
            await nextTick()
            if (!audioElement.value) {
                console.error('audioElement still not available, falling back to loadAudio')
                return loadAudio(autoPlay)
            }
        }

        // ä½¿ç”¨ template ä¸­çš„ audio å…ƒç´ 
        audio = audioElement.value
        setupAudioEventListeners()

        // åˆ›å»º MediaSource
        mediaSource = new MediaSource()
        const url = URL.createObjectURL(mediaSource)

        // è®¾ç½® MediaSource blob URL åˆ° audio å…ƒç´ 
        audio.src = url
        audio.volume = 1.0

        // ç­‰å¾… sourceopen
        mediaSource.addEventListener('sourceopen', async () => {
            console.log('ğŸ“‚ MediaSource sourceopen')

            try {
                // æ·»åŠ  SourceBufferï¼ˆä½¿ç”¨ MP3 MIME typeï¼‰
                sourceBuffer = mediaSource.addSourceBuffer('audio/mpeg')

                // ç›‘å¬æ›´æ–°ç»“æŸäº‹ä»¶ï¼ˆå¤„ç†é˜Ÿåˆ—ï¼‰
                sourceBuffer.addEventListener('updateend', () => {
                    console.log('ğŸ“¦ SourceBuffer updateend')

                    // æ›´æ–° lastBytePositionï¼ˆå…³é”®ï¼šç¡®ä¿ä¸‹æ¬¡ Range Request ä»æ­£ç¡®ä½ç½®å¼€å§‹ï¼‰
                    if (pendingAppendSize > 0) {
                        lastBytePosition += pendingAppendSize
                        console.log(`ğŸ“Š Updated lastBytePosition to ${lastBytePosition} bytes (added ${pendingAppendSize} bytes)`)
                        pendingAppendSize = 0
                    }

                    // æ›´æ–° MediaSource durationï¼ˆå…³é”®ï¼šé¿å…é‡å¤æ’­æ”¾ï¼‰
                    if (audio.buffered.length > 0) {
                        const bufferedEnd = audio.buffered.end(audio.buffered.length - 1)
                        // ç¡®ä¿ MediaSource duration å¤§äºç­‰äº buffered çš„ç»“æŸä½ç½®
                        // å¦‚æœ duration å°äº buffered é•¿åº¦ï¼Œä¼šå¯¼è‡´é‡å¤æ’­æ”¾
                        if (mediaSource.duration === Infinity || mediaSource.duration < bufferedEnd) {
                            try {
                                mediaSource.duration = bufferedEnd
                                console.log(`ğŸ“Š Updated MediaSource duration to ${bufferedEnd.toFixed(2)}s`)
                            } catch (e) {
                                // duration å¯èƒ½å·²ç»è®¾ç½®ï¼Œå¿½ç•¥é”™è¯¯
                                console.warn('Could not update MediaSource duration:', e)
                            }
                        }
                        // æ›´æ–°æ˜¾ç¤º
                        duration.value = bufferedEnd
                    }

                    // è‡ªåŠ¨åˆ·æ–°é˜Ÿåˆ—
                    flushQueue()
                })

                sourceBuffer.addEventListener('error', (e) => {
                    console.error('SourceBuffer error:', e)
                })

                // åŠ è½½åˆå§‹éŸ³é¢‘ï¼ˆå®Œæ•´æ–‡ä»¶ï¼Œå› ä¸ºæ˜¯é¦–æ¬¡åŠ è½½ï¼‰
                console.log('ğŸ“¥ Fetching initial audio...')
                const audioUrlWithCache = addCacheBustingParam(mergedAudioUrl)
                const response = await apiCall(audioUrlWithCache)
                const blob = await response.blob()
                const arrayBuffer = await blob.arrayBuffer()

                console.log(`âœ… Received ${arrayBuffer.byteLength} bytes`)

                // è®°å½•æ€»å¤§å°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
                totalAudioSize = arrayBuffer.byteLength

                // ä½¿ç”¨é˜Ÿåˆ—å®‰å…¨çš„è¿½åŠ æ–¹æ³•
                // æ³¨æ„ï¼šlastBytePosition ä¼šåœ¨ updateend äº‹ä»¶ä¸­æ›´æ–°
                appendToBuffer(arrayBuffer)

                // åˆå§‹åŒ–æ³¢å½¢å›¾ï¼ˆç­‰å¾…éŸ³é¢‘å¯ä»¥æ’­æ”¾ï¼‰
                audio.addEventListener('canplay', async () => {
                    console.log('ğŸµ Audio can play, initializing waveform...')

                    // ç¡®ä¿æ³¢å½¢å›¾å·²åˆå§‹åŒ–
                    if (waveformBars.value.length === 0) {
                        initWaveform()
                    }

                    // æ›´æ–° lastAudioDuration ä¸ºå®é™…åŠ è½½çš„éŸ³é¢‘æ—¶é•¿ï¼Œé¿å…é‡å¤è¿½åŠ 
                    if (audio.buffered.length > 0) {
                        const bufferedEnd = audio.buffered.end(audio.buffered.length - 1)
                        lastAudioDuration = bufferedEnd
                        console.log(`ğŸ“Š Updated lastAudioDuration to ${bufferedEnd.toFixed(2)}s after initial load`)
                        // æ ‡è®°åˆå§‹åŠ è½½å·²å®Œæˆ
                        isInitialAudioLoadComplete = true
                    }

                    // å°è¯•åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨
                    try {
                        await initAudioAnalyzer()
                    } catch (e) {
                        console.log('Analyzer init failed, fallback to simulated waveform')
                    }
                })

                // ç¦ç”¨éŸ³é¢‘æ›´æ–°æ£€æŸ¥å™¨ï¼šç›´æ¥ä½¿ç”¨ WebSocket çš„ WAV chunkï¼Œä¸éœ€è¦è½®è¯¢ API
                // startAudioUpdateChecker()  // ç¦ç”¨ï¼šWebSocket å·²ç»åœ¨æ¨é€ WAV chunk

            } catch (err) {
                console.error('Error initializing source buffer:', err)
            }
        })

        mediaSource.addEventListener('error', (e) => {
            console.error('MediaSource error:', e)
        })

        // ç»‘å®šäº‹ä»¶
        audio.addEventListener('timeupdate', () => {
            if (!isDragging && audio) {
                currentTime.value = audio.currentTime

                // ä½¿ç”¨ buffered è®¡ç®—è¿›åº¦ï¼ˆMediaSource çš„ duration æ˜¯åŠ¨æ€çš„ï¼‰
                if (audio.buffered.length > 0) {
                    const bufferedEnd = audio.buffered.end(audio.buffered.length - 1)
                    progress.value = (audio.currentTime / bufferedEnd) * 100
                    duration.value = bufferedEnd
                }

                updateActiveSubtitleForStreaming(audio.currentTime)
            }
        })

        // ç›‘å¬ buffered æ›´æ–°ï¼ˆMediaSource çš„ duration æ˜¯åŠ¨æ€çš„ï¼‰
        audio.addEventListener('progress', () => {
            if (audio.buffered.length > 0) {
                const bufferedEnd = audio.buffered.end(audio.buffered.length - 1)
                duration.value = bufferedEnd
            }
        })

        audio.addEventListener('ended', () => {
            isPlaying.value = false
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId)
                animationFrameId = null
            }
            stopAudioUpdateChecker()
        })

        audio.addEventListener('error', (e) => {
            console.error('MediaSource audio error:', e, audio?.error)
            if (audio?.error) {
                const errorCode = audio.error.code
                const errorMessages = {
                    1: 'MEDIA_ERR_ABORTED - ç”¨æˆ·ä¸­æ­¢',
                    2: 'MEDIA_ERR_NETWORK - ç½‘ç»œé”™è¯¯',
                    3: 'MEDIA_ERR_DECODE - è§£ç é”™è¯¯',
                    4: 'MEDIA_ERR_SRC_NOT_SUPPORTED - æ ¼å¼ä¸æ”¯æŒ'
                }
                console.error('MediaSource audio error code:', errorCode, errorMessages[errorCode] || t('podcast.unknownError'))

                // æ£€æŸ¥éŸ³é¢‘çŠ¶æ€ï¼Œå¦‚æœè¿˜åœ¨åŠ è½½ä¸­ï¼Œå»¶è¿Ÿæ˜¾ç¤ºé”™è¯¯
                if (audio.readyState === HTMLMediaElement.HAVE_NOTHING) {
                    console.log('MediaSource audio still loading, waiting before showing error...')
                    setTimeout(() => {
                        // å†æ¬¡æ£€æŸ¥ï¼Œå¦‚æœä»ç„¶å‡ºé”™ä¸”æ²¡æœ‰åŠ è½½ä»»ä½•æ•°æ®ï¼Œæ‰æ˜¾ç¤ºé”™è¯¯å¹¶å›é€€
                        if (audio && audio.readyState === HTMLMediaElement.HAVE_NOTHING && audio.error) {
                            const currentErrorCode = audio.error.code
                            // MEDIA_ERR_ABORTED (1) é€šå¸¸æ˜¯ç”¨æˆ·æ“ä½œå¯¼è‡´çš„ï¼Œä¸æ˜¾ç¤ºé”™è¯¯
                            if (currentErrorCode !== 1) {
                                showAlert(t('podcast.audioLoadFailedWithError', { error: errorMessages[currentErrorCode] || t('podcast.unknownError') }), 'error')
                                // MediaSource å¤±è´¥æ—¶å›é€€åˆ°æ™®é€šæ–¹å¼
                                loadAudio(autoPlay)
                            }
                        }
                    }, 3000) // ç­‰å¾… 3 ç§’
                    return
                }

                // MEDIA_ERR_ABORTED (1) é€šå¸¸æ˜¯ç”¨æˆ·æ“ä½œå¯¼è‡´çš„ï¼Œä¸æ˜¾ç¤ºé”™è¯¯
                if (errorCode === 1) {
                    console.log('MediaSource audio error is ABORTED, likely user action, not showing error')
                    return
                }

                // å…¶ä»–æƒ…å†µæ‰æ˜¾ç¤ºé”™è¯¯å¹¶å›é€€
                showAlert(t('podcast.audioLoadFailedWithError', { error: errorMessages[errorCode] || t('podcast.unknownError') }), 'error')
                // MediaSource å¤±è´¥æ—¶å›é€€åˆ°æ™®é€šæ–¹å¼
                loadAudio(autoPlay)
            }
        })

        // å¦‚æœæ˜¯è‡ªåŠ¨æ’­æ”¾ï¼Œç­‰å¾… canplay äº‹ä»¶
        if (autoPlay) {
            audio.addEventListener('canplay', async () => {
                try {
                    await audio.play()
                    isPlaying.value = true
                    visualize()
                } catch (error) {
                    console.error('Error auto playing:', error)
                }
            })
        }

    } catch (err) {
        console.error('Error initializing MediaSource audio:', err)
        // å¦‚æœ MediaSource å¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šæ–¹å¼
        loadAudio(autoPlay)
    }
}

// åŠ è½½éŸ³é¢‘ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼Œä½œä¸ºåå¤‡ï¼‰
async function loadAudio(autoPlay = false, retryCount = 0) {
    if (!mergedAudioUrl) return

    const maxRetries = 3
    if (animationFrameId) {
        cancelAnimationFrame(animationFrameId)
        animationFrameId = null
    }

    // ä¼˜å…ˆä½¿ç”¨ template ä¸­çš„ audioElement
    if (audioElement.value) {
        audio = audioElement.value
        // ç¡®ä¿éŸ³é‡è®¾ç½®ä¸º 1.0ï¼ˆé‡è¦ï¼šé¿å…æ— å£°ï¼‰
        audio.volume = 1.0
        // è®¾ç½® audioUrlï¼Œè®© template ä¸­çš„ audio å…ƒç´ è‡ªåŠ¨åŠ è½½
        if (mergedAudioUrl.startsWith('http://') || mergedAudioUrl.startsWith('https://')) {
            audioUrl.value = mergedAudioUrl
        } else {
            audioUrl.value = addCacheBustingParam(mergedAudioUrl)
        }
        // ç¡®ä¿éŸ³é¢‘å…ƒç´ å·²åŠ è½½
        await nextTick()
        if (audio.readyState === HTMLMediaElement.HAVE_NOTHING) {
            audio.load()
        }
    } else {
        // å¦‚æœ audioElement ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„ Audio å¯¹è±¡ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
        if (audio) {
            audio.pause()
            // æ¸…ç†ä¹‹å‰çš„ blob URL
            if (audio.src && audio.src.startsWith('blob:')) {
                URL.revokeObjectURL(audio.src)
            }
        }

        // ä½¿ç”¨ fetch è·å–éŸ³é¢‘ï¼ˆæ”¯æŒè®¤è¯ï¼‰
        try {
            const audioUrlWithCache = addCacheBustingParam(mergedAudioUrl)
            const response = await apiCall(audioUrlWithCache)
            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`)
            }
            const blob = await response.blob()
            const blobUrl = URL.createObjectURL(blob)

            audio = new Audio(blobUrl)
            audio.volume = 1.0
            audio.preload = 'auto'
        } catch (error) {
            console.error('Error loading audio:', error)
            setTimeout(() => {
                loadAudio(autoPlay, retryCount + 1)
            }, 1000)
            return
        }
    }

    let hasLoadedMetadata = false
    let analyzerInitialized = false

    audio.addEventListener('loadedmetadata', async () => {
        if (hasLoadedMetadata) return
        hasLoadedMetadata = true

        const total = getDisplayedDuration()
        if (total > 0) {
            duration.value = total
            // æ›´æ–° lastAudioDuration ä¸ºå®é™…åŠ è½½çš„éŸ³é¢‘æ—¶é•¿ï¼Œé¿å…é‡å¤è¿½åŠ 
            lastAudioDuration = total
            console.log(`ğŸ“Š Updated lastAudioDuration to ${total.toFixed(2)}s after initial load (loadAudio)`)
            // æ ‡è®°åˆå§‹åŠ è½½å·²å®Œæˆ
            isInitialAudioLoadComplete = true
            if (!analyzerInitialized) {
                await initAudioAnalyzer()
                analyzerInitialized = true
            }
            // ç¦ç”¨éŸ³é¢‘æ›´æ–°æ£€æŸ¥å™¨ï¼šç›´æ¥ä½¿ç”¨ WebSocket çš„ WAV chunkï¼Œä¸éœ€è¦è½®è¯¢ API
            // startAudioUpdateChecker()  // ç¦ç”¨ï¼šWebSocket å·²ç»åœ¨æ¨é€ WAV chunk
        }
    })

    audio.addEventListener('canplay', async () => {
        if (shouldResumePlayback) {
            shouldResumePlayback = false
            try {
                await audio.play()
                isPlaying.value = true
                if (!animationFrameId) {
                    visualize()
                }
            } catch (error) {
                console.error('Error resuming audio:', error)
                isPlaying.value = false
            }
                } else if (!autoPlay) {
            isPlaying.value = false
            statusMsg.value = t('podcast.readyWithCount', { count: subtitles.value.length })
        }
    })

    audio.addEventListener('timeupdate', () => {
        if (!isDragging && audio) {
            currentTime.value = audio.currentTime
            const total = getDisplayedDuration()
            if (total > 0) {
                progress.value = (audio.currentTime / total) * 100
                duration.value = total
            }
            updateActiveSubtitleForStreaming(audio.currentTime)
        }
    })

    audio.addEventListener('ended', () => {
        isPlaying.value = false
        if (animationFrameId) {
            cancelAnimationFrame(animationFrameId)
            animationFrameId = null
        }
        stopAudioUpdateChecker()
    })

    audio.addEventListener('error', (e) => {
        console.error('Audio error:', e, audio?.error)
        // è¾“å‡ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        if (audio?.error) {
            const errorCode = audio.error.code
            const errorMessages = {
                1: 'MEDIA_ERR_ABORTED - ç”¨æˆ·ä¸­æ­¢',
                2: 'MEDIA_ERR_NETWORK - ç½‘ç»œé”™è¯¯',
                3: 'MEDIA_ERR_DECODE - è§£ç é”™è¯¯',
                4: 'MEDIA_ERR_SRC_NOT_SUPPORTED - æ ¼å¼ä¸æ”¯æŒ'
            }
            console.error('Audio error code:', errorCode, errorMessages[errorCode] || t('podcast.unknownError'))
            console.error('Audio src:', audio.src?.substring(0, 100))

            // MEDIA_ERR_ABORTED (1) é€šå¸¸æ˜¯ç”¨æˆ·æ“ä½œå¯¼è‡´çš„ï¼Œä¸æ˜¾ç¤ºé”™è¯¯ï¼Œä¹Ÿä¸é‡è¯•
            if (errorCode === 1) {
                console.log('Audio error is ABORTED, likely user action, not retrying')
                return
            }
        }

        // æ£€æŸ¥éŸ³é¢‘çŠ¶æ€ï¼Œå¦‚æœè¿˜åœ¨åŠ è½½ä¸­ï¼Œå»¶è¿Ÿåˆ¤æ–­
        if (audio && audio.readyState === HTMLMediaElement.HAVE_NOTHING) {
            console.log('Audio still loading, waiting before retrying...')
            setTimeout(() => {
                // å†æ¬¡æ£€æŸ¥ï¼Œå¦‚æœä»ç„¶å‡ºé”™ä¸”æ²¡æœ‰åŠ è½½ä»»ä½•æ•°æ®ï¼Œæ‰é‡è¯•æˆ–æ˜¾ç¤ºé”™è¯¯
                if (audio && audio.readyState === HTMLMediaElement.HAVE_NOTHING && audio.error) {
                    const currentErrorCode = audio.error.code
                    // MEDIA_ERR_ABORTED (1) é€šå¸¸æ˜¯ç”¨æˆ·æ“ä½œå¯¼è‡´çš„ï¼Œä¸æ˜¾ç¤ºé”™è¯¯
                    if (currentErrorCode !== 1) {
                        if (!hasLoadedMetadata && retryCount < maxRetries) {
                            setTimeout(() => {
                                loadAudio(autoPlay, retryCount + 1)
                            }, 1000)
                        } else if (retryCount >= maxRetries) {
                            statusMsg.value = t('podcast.audioLoadFailedNetwork')
                            showAlert(t('podcast.audioLoadFailedFormat'), 'error')
                        }
                    }
                }
            }, 3000) // ç­‰å¾… 3 ç§’
            return
        }

        // å¦‚æœå·²ç»æœ‰å…ƒæ•°æ®ï¼Œè¯´æ˜ä¸æ˜¯åŠ è½½é—®é¢˜ï¼Œå¯èƒ½æ˜¯å…¶ä»–é”™è¯¯
        if (audio && audio.readyState >= HTMLMediaElement.HAVE_METADATA) {
            console.log('Audio has metadata, error might be non-critical')
            return
        }

        // å…¶ä»–æƒ…å†µæ‰é‡è¯•æˆ–æ˜¾ç¤ºé”™è¯¯
        if (!hasLoadedMetadata && retryCount < maxRetries) {
            setTimeout(() => {
                loadAudio(autoPlay, retryCount + 1)
            }, 1000)
        } else if (retryCount >= maxRetries) {
            statusMsg.value = t('podcast.audioLoadFailedNetwork')
            showAlert(t('podcast.audioLoadFailedFormat'), 'error')
        }
    })
}

// å¯åŠ¨éŸ³é¢‘æ›´æ–°æ£€æŸ¥å™¨
function startAudioUpdateChecker() {
    if (audioUpdateChecker) {
        clearInterval(audioUpdateChecker)
    }
    audioUpdateChecker = setInterval(() => {
        checkAndUpdateAudio()
    }, 5000)
}

// åœæ­¢éŸ³é¢‘æ›´æ–°æ£€æŸ¥å™¨
function stopAudioUpdateChecker() {
    if (audioUpdateChecker) {
        clearInterval(audioUpdateChecker)
        audioUpdateChecker = null
    }
}

// æ— ç¼åˆ‡æ¢éŸ³é¢‘ï¼ˆä½¿ç”¨ Range Request åªæ‹‰æ–°å¢éƒ¨åˆ†ï¼‰
async function switchAudioSeamlessly() {
    if (isSwitching || !mergedAudioUrl || !audio || !sourceBuffer || !mediaSource) return

    isSwitching = true

    const currentTime = audio.currentTime
    const wasPlaying = !audio.paused

    console.log(`ğŸ“¥ Fetching audio update from: ${mergedAudioUrl}, starting at byte ${lastBytePosition}`)

    try {
        // âœ… Range Request: åªæ‹‰æ–°å¢éƒ¨åˆ†
        // æ³¨æ„ï¼šRange Request ä½¿ç”¨ fetch è€Œä¸æ˜¯ apiCallï¼Œå› ä¸º Range Request éœ€è¦ç›´æ¥æ§åˆ¶ headers
        const audioUrlWithCache = addCacheBustingParam(mergedAudioUrl)

        // å¯¹äº API URLï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ è®¤è¯å¤´
        let headers = {
            'Range': `bytes=${lastBytePosition}-`
        }

        // å¦‚æœæ˜¯ API URLï¼ˆä¸æ˜¯ CDN URLï¼‰ï¼Œæ·»åŠ è®¤è¯å¤´
        if (!audioUrlWithCache.startsWith('http://') && !audioUrlWithCache.startsWith('https://')) {
            const token = localStorage.getItem('accessToken')
            if (token) {
                headers['Authorization'] = `Bearer ${token}`
            }
        }

        const response = await fetch(audioUrlWithCache, {
            headers: headers
        })

        if (response.status === 206) {
            // Range è¯·æ±‚æˆåŠŸï¼ˆ206 Partial Contentï¼‰
            const blob = await response.blob()
            const arrayBuffer = await blob.arrayBuffer()

            if (arrayBuffer.byteLength > 0) {
                console.log(`âœ… Received ${arrayBuffer.byteLength} bytes (total loaded: ${lastBytePosition + arrayBuffer.byteLength} bytes)`)

                // æ·»åŠ åˆ°é˜Ÿåˆ—ï¼Œç”± updateend äº‹ä»¶å¤„ç†
                audioQueue.push(arrayBuffer)

                // å°è¯•åˆ·æ–°é˜Ÿåˆ—
                flushQueue()

                // æ³¨æ„ï¼šlastBytePosition åœ¨ updateend äº‹ä»¶ä¸­æ›´æ–°ï¼Œé¿å…é‡å¤è¿½åŠ 
            } else {
                console.log('No new data available')
            }
        } else if (response.ok && response.status === 200) {
            // Range ä¸æ”¯æŒï¼Œä½†è¿”å›äº†å®Œæ•´æ–‡ä»¶
            // è¿™ç§æƒ…å†µä¸åº”è¯¥åœ¨è¿½åŠ æ—¶å‘ç”Ÿï¼Œå¦‚æœå‘ç”Ÿè¯´æ˜æœåŠ¡å™¨ä¸æ”¯æŒ Range Request
            console.warn('âš ï¸ Range request returned 200 (full file), this should not happen during append')
            // æ£€æŸ¥ Content-Range å¤´ï¼Œå¦‚æœæœ‰ï¼Œè¯´æ˜å®é™…è¿”å›çš„æ˜¯éƒ¨åˆ†å†…å®¹
            const contentRange = response.headers.get('Content-Range')
            if (contentRange) {
                // è§£æ Content-Range: bytes 0-999/2000
                const match = contentRange.match(/bytes (\d+)-(\d+)\/(\d+)/)
                if (match) {
                    const start = parseInt(match[1])
                    const end = parseInt(match[2])
                    const total = parseInt(match[3])
                    console.log(`ğŸ“Š Content-Range: ${start}-${end}/${total}`)
                    // å¦‚æœè¿”å›çš„æ˜¯ä» lastBytePosition å¼€å§‹çš„å†…å®¹ï¼Œå¯ä»¥è¿½åŠ 
                    if (start === lastBytePosition) {
                        const blob = await response.blob()
                        const arrayBuffer = await blob.arrayBuffer()
                        audioQueue.push(arrayBuffer)
                        flushQueue()
                    } else {
                        console.warn('âš ï¸ Content-Range start does not match lastBytePosition, skipping to avoid duplicate')
                    }
                }
            } else {
                // æ²¡æœ‰ Content-Rangeï¼Œè¯´æ˜è¿”å›çš„æ˜¯å®Œæ•´æ–‡ä»¶ï¼Œä¸åº”è¯¥è¿½åŠ 
                console.warn('âš ï¸ No Content-Range header, skipping to avoid duplicate')
            }
        } else {
            console.warn('Range request failed:', response.status, response.statusText)
            // å¦‚æœ Range è¯·æ±‚å¤±è´¥ï¼Œå°è¯•å®Œæ•´ fetch
            try {
                const fullResponse = await fetch(audioUrlWithCache, {
                    headers: headers
                })
                if (fullResponse.ok) {
                    const blob = await fullResponse.blob()
                    const arrayBuffer = await blob.arrayBuffer()
                    lastBytePosition = arrayBuffer.byteLength
                    totalAudioSize = arrayBuffer.byteLength
                    appendToBuffer(arrayBuffer)
                }
            } catch (e) {
                console.error('Fallback fetch also failed:', e)
            }
        }

    } catch (err) {
        console.error('âŒ Error fetching audio:', err)
    } finally {
        isSwitching = false
    }
}

// è¿½åŠ æ•°æ®åˆ° bufferï¼ˆé˜Ÿåˆ—å®‰å…¨ï¼‰
function appendToBuffer(arrayBuffer) {
    if (!sourceBuffer || sourceBuffer.updating || mediaSource.readyState !== 'open') {
        audioQueue.push(arrayBuffer)
        return
    }

    try {
        // è®°å½•æ­£åœ¨è¿½åŠ çš„æ•°æ®å¤§å°
        pendingAppendSize = arrayBuffer.byteLength
        sourceBuffer.appendBuffer(arrayBuffer)
        console.log(`âœ… Audio chunk appended to source buffer (${arrayBuffer.byteLength} bytes)`)
    } catch (e) {
        console.error('Error appending buffer:', e)
        pendingAppendSize = 0
        audioQueue.push(arrayBuffer)
    }
}

// å¤„ç†éŸ³é¢‘é˜Ÿåˆ—ï¼ˆåœ¨ updateend æ—¶è°ƒç”¨ï¼‰
function flushQueue() {
    if (!sourceBuffer || sourceBuffer.updating || mediaSource.readyState !== 'open') {
        return
    }

    if (audioQueue.length === 0) {
        return
    }

    const chunk = audioQueue.shift()
    try {
        // è®°å½•æ­£åœ¨è¿½åŠ çš„æ•°æ®å¤§å°
        pendingAppendSize = chunk.byteLength
        sourceBuffer.appendBuffer(chunk)
        console.log(`ğŸ“¦ Appended queued chunk (${chunk.byteLength} bytes)`)
    } catch (e) {
        console.error('Error appending queued buffer:', e)
        pendingAppendSize = 0
        audioQueue.unshift(chunk) // å¤±è´¥æ—¶æ”¾å›é˜Ÿåˆ—
    }
}

// æ£€æŸ¥éŸ³é¢‘æ˜¯å¦æœ‰æ›´æ–°å¹¶è‡ªåŠ¨åˆ‡æ¢
async function checkAndUpdateAudio() {
    if (!mergedAudioUrl || !audio || isSwitching) return

    try {
        // åˆ›å»ºä¸´æ—¶éŸ³é¢‘å¯¹è±¡æ£€æŸ¥æ–°é•¿åº¦
        const audioUrlWithCache = addCacheBustingParam(mergedAudioUrl)
        const response = await apiCall(audioUrlWithCache)
        if (!response.ok) return

        const blob = await response.blob()
        const blobUrl = URL.createObjectURL(blob)
        const checkAudio = new Audio(blobUrl)

        checkAudio.addEventListener('loadedmetadata', () => {
            const newDuration = checkAudio.duration
            URL.revokeObjectURL(blobUrl)
            checkAudio.remove()

            // æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹ï¼ˆæ–°çš„durationå¤§äºæ—§çš„duration+2ç§’å®¹å·®ï¼‰
            if (newDuration > audio.duration + 2) {
                console.log(`Detected audio update: ${audio.duration}s -> ${newDuration}s`)
                if (mediaSource && sourceBuffer) {
                    // æ¡Œé¢ç­‰æ”¯æŒ MSEï¼šæ— ç¼è¿½åŠ 
                    switchAudioSeamlessly()
                } else {
                    // iOS ç­‰ä¸æ”¯æŒ MSEï¼šé‡æ–°åŠ è½½éŸ³é¢‘å¹¶æ¢å¤ä½ç½®
                    reloadAudioForIOS()
                }
            }
        })

        checkAudio.addEventListener('error', () => {
            URL.revokeObjectURL(blobUrl)
            checkAudio.remove()
        })

        // åŠ è½½å…ƒæ•°æ®
        checkAudio.load()
    } catch (error) {
        console.error('Error checking audio update:', error)
    }
}

// iOS é‡æ–°åŠ è½½éŸ³é¢‘ï¼ˆæµå¼æ›´æ–°ï¼‰
async function reloadAudioForIOS() {
    if (!audio || !mergedAudioUrl) return

    const wasPlaying = !audio.paused
    const prevTime = audio.currentTime || 0
    const newSrc = addCacheBustingParam(mergedAudioUrl)

    try {
        // ä½¿ç”¨ fetch è·å–éŸ³é¢‘ï¼ˆæ”¯æŒè®¤è¯ï¼‰
        const response = await apiCall(newSrc)
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`)
        }
        const blob = await response.blob()
        const blobUrl = URL.createObjectURL(blob)

        // æ£€æŸ¥éŸ³é¢‘æ—¶é•¿æ˜¯å¦æœ‰æ˜¾è‘—å¢åŠ 
        const checkAudio = new Audio(blobUrl)
        checkAudio.addEventListener('loadedmetadata', () => {
            const newDuration = checkAudio.duration
            const currentDuration = audio.duration || 0

            // å¦‚æœæ–°æ—¶é•¿æ˜¾è‘—å¤§äºå½“å‰æ—¶é•¿ï¼ˆè‡³å°‘å¢åŠ  1 ç§’ï¼‰ï¼Œæ‰é‡æ–°åŠ è½½
            if (newDuration > currentDuration + 1) {
                console.log(`ğŸ“Š Audio duration updated: ${currentDuration.toFixed(2)}s -> ${newDuration.toFixed(2)}s`)

                // æ¸…ç†æ—§çš„ blob URL
                if (audio.src && audio.src.startsWith('blob:')) {
                    URL.revokeObjectURL(audio.src)
                }

                try { audio.pause() } catch (_) {}
                audio.src = blobUrl

                const onLoaded = async () => {
                    try {
                        const durationVal = getDisplayedDuration()
                        if (durationVal) {
                            duration.value = durationVal
                        }
                        // ä¿æŒæ’­æ”¾ä½ç½®
                        audio.currentTime = Math.min(prevTime, getDisplayedDuration() || prevTime)
                        if (wasPlaying) {
                            await audio.play()
                            isPlaying.value = true
                            if (!animationFrameId) visualize()
                        } else {
                            isPlaying.value = false
                        }
                    } catch (e) {
                        console.error('Error reloading audio:', e)
                        isPlaying.value = false
                    }
                }

                audio.addEventListener('loadedmetadata', onLoaded, { once: true })
                audio.addEventListener('error', () => {
                    console.error('Error reloading audio')
                    URL.revokeObjectURL(blobUrl)
                    isPlaying.value = false
                }, { once: true })
                audio.load()
            } else {
                // æ—¶é•¿æ²¡æœ‰æ˜¾è‘—å˜åŒ–ï¼Œåªæ›´æ–°æ˜¾ç¤º
                URL.revokeObjectURL(blobUrl)
                const durationVal = getDisplayedDuration()
                if (durationVal) {
                    duration.value = durationVal
                }
            }
            checkAudio.remove()
        })
        checkAudio.addEventListener('error', () => {
            console.warn('Error checking audio duration')
            URL.revokeObjectURL(blobUrl)
            checkAudio.remove()
        })
        checkAudio.load()
    } catch (error) {
        console.error('Error reloading audio:', error)
    }
}

// ç”Ÿæˆæ’­å®¢
async function generatePodcast() {
    if (!input.value.trim()) {
        showAlert(t('podcast.enterLinkOrTopic'), 'warning')
        return
    }

    showStatus.value = true
    statusMsg.value = t('podcast.generating')
    statusClass.value = 'generating'
    showStopBtn.value = true
    showDownloadBtn.value = false

    // è®¾ç½®ç”ŸæˆçŠ¶æ€
    isGenerating = true
    simulatedWaveformStartTime = null  // é‡ç½®æ¨¡æ‹Ÿæ³¢å½¢åŠ¨ç”»æ—¶é—´

    // ç­‰å¾… DOM æ›´æ–°
    await nextTick()

    // é‡ç½®çŠ¶æ€
    subtitles.value = []
    subtitleTimestamps.value = []
    activeSubtitleIndex.value = -1
    audioUrl.value = ''
    mergedAudioUrl = null
    lastAudioDuration = 0
    isPlaying.value = false
    isSwitching = false
    stopAudioUpdateChecker()

    lastBytePosition = 0
    totalAudioSize = 0
    audioQueue = []
    hasLoadedMetadata = false
    analyzerInitialized = false
    // æ¸…ç†è·¨åŸŸéŸ³é¢‘çš„é¢„åˆ†ææ•°æ®
    crossOriginWaveformData = null
    crossOriginWaveformDataLoaded = false
    crossOriginWaveformMin = 0
    crossOriginWaveformMax = 0
    lastAnalyzedAudioUrl = null
    if (audio) {
        audio.pause()
    }
    if (mediaSource) {
        mediaSource = null
    }
    if (sourceBuffer) {
        sourceBuffer = null
    }

    // é‡ç½® WebAudio çŠ¶æ€ï¼ˆä¸å†ä½¿ç”¨ï¼Œä½†ä¿ç•™æ¸…ç†ä»£ç ï¼‰
    webAudioQueue = []
    webAudioPlaying = false
    webAudioCurrentTime = 0
    webAudioStartTime = 0
    webAudioTotalDuration = 0
    webAudioSourceNodes.forEach(node => {
        try {
            node.stop()
        } catch (e) {
            // å¯èƒ½å·²ç»åœæ­¢
        }
    })
    webAudioSourceNodes = []
    if (webAudioTimeUpdateFrame) {
        cancelAnimationFrame(webAudioTimeUpdateFrame)
        webAudioTimeUpdateFrame = null
    }

    // é‡ç½® MediaSource ç›¸å…³çŠ¶æ€ï¼ˆä¸ index.html ä¸€è‡´ï¼‰
    lastBytePosition = 0
    totalAudioSize = 0
    audioQueue = []
    isInitialAudioLoadComplete = false  // é‡ç½®åˆå§‹åŠ è½½å®Œæˆæ ‡å¿—

    showSubtitles.value = false
    audioUserInput.value = input.value

    // æ¸…ç©ºå­—å¹•ï¼ˆä¸å†éœ€è¦ï¼Œå› ä¸ºä½¿ç”¨å“åº”å¼æ•°æ®ï¼‰

    // æ˜¾ç¤ºæ’­æ”¾å™¨å¹¶åˆå§‹åŒ–æ³¢å½¢å›¾ï¼ˆç”Ÿæˆæ—¶æ˜¾ç¤ºæ¨¡æ‹Ÿæ³¢å½¢å›¾ï¼‰
    showPlayer.value = true
    await nextTick()

    // åˆå§‹åŒ–æ³¢å½¢å›¾
    if (waveformBars.value.length === 0) {
        initWaveform()
    }

    // å¯åŠ¨æ³¢å½¢å›¾åŠ¨ç”»ï¼ˆç”Ÿæˆæ—¶æ˜¾ç¤ºæ¨¡æ‹Ÿæ³¢å½¢å›¾ï¼‰
    if (!animationFrameId) {
        visualize()
    }

    try {
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:'
        // è·å– token ç”¨äº WebSocket è®¤è¯
        const token = localStorage.getItem('accessToken')
        const wsUrl = token
            ? `${protocol}//${window.location.host}/api/v1/podcast/generate?token=${encodeURIComponent(token)}`
            : `${protocol}//${window.location.host}/api/v1/podcast/generate`
        wsConnection = new WebSocket(wsUrl)

        wsConnection.onopen = () => {
            wsConnection.send(JSON.stringify({ input: input.value }))
        }

        // è®¾ç½® WebSocket æ¥æ”¶äºŒè¿›åˆ¶æ•°æ®
        wsConnection.binaryType = 'arraybuffer'

        wsConnection.onmessage = async (event) => {
            // å¿½ç•¥äºŒè¿›åˆ¶æ•°æ®ï¼ˆWAV chunkï¼‰ï¼Œæ”¹ç”¨ Range Request æ–¹å¼
            // è¿™æ ·å¯ä»¥ä¿æŒéŸ³é¢‘è¿ç»­æ€§ï¼Œé¿å…åˆ†æ®µæ’­æ”¾

            // JSON æ¶ˆæ¯å¤„ç†
            let message
            try {
                // å¦‚æœæ˜¯äºŒè¿›åˆ¶æ•°æ®ï¼Œè·³è¿‡ï¼ˆä¸å†ä½¿ç”¨ WebAudio chunk æ–¹å¼ï¼‰
                if (event.data instanceof ArrayBuffer || event.data instanceof Blob) {
                    return
                }
                message = JSON.parse(event.data)
            } catch (e) {
                console.error('Failed to parse WebSocket message:', e, event.data)
                return
            }

            if (message.type === 'audio_update') {
                const audioData = message.data
                const currentDuration = audioData.duration || 0
                const durationChanged = currentDuration > lastAudioDuration
                lastAudioDuration = currentDuration

                if (isIOSSafari() && audioData.hls_url) {
                    window.__lastProgressiveUrl = audioData.url
                    mergedAudioUrl = audioData.hls_url
                } else {
                    mergedAudioUrl = audioData.url
                }

                if (audioData.text) {
                    const subtitleItem = {
                        text: audioData.text,
                        speaker: audioData.speaker
                    }
                    subtitles.value.push(subtitleItem)

                    if (audioData.duration !== undefined) {
                        const previousDuration = subtitleTimestamps.value.length > 0
                            ? subtitleTimestamps.value[subtitleTimestamps.value.length - 1].end
                            : 0
                        subtitleTimestamps.value.push({
                            start: previousDuration,
                            end: audioData.duration,
                            text: audioData.text,
                            speaker: audioData.speaker
                        })
                    }

                    // å¦‚æœå­—å¹•åŒºåŸŸæœªæ˜¾ç¤ºï¼Œè‡ªåŠ¨æ˜¾ç¤º
                    if (!showSubtitles.value && subtitles.value.length > 0) {
                        showSubtitles.value = true
                        await nextTick()
                    }
                }

                // ä½¿ç”¨ MediaSource æˆ–ä¼ ç»Ÿ Audio æ–¹å¼ï¼Œé€šè¿‡ Range Request è¿½åŠ æ–°å†…å®¹
                // è¿™æ ·å¯ä»¥ä¿æŒéŸ³é¢‘è¿ç»­æ€§ï¼Œä¸ index.html ä¸€è‡´
                if (subtitles.value.length === 1 && !audio) {
                    statusMsg.value = t('podcast.preparingFirstAudio')
                    // å»¶è¿Ÿ2ç§’ç¡®ä¿mergedéŸ³é¢‘æ–‡ä»¶å·²å®Œå…¨å†™å…¥ï¼ˆä¸ index.html ä¸€è‡´ï¼‰
                    setTimeout(async () => {
                        if (isIOSSafari()) {
                            await loadAudio(false)
                        } else {
                            await initMediaSourceAudio(false)
                        }
                        // æ˜¾ç¤ºæ’­æ”¾å™¨
                        showPlayer.value = true
                        await nextTick()

                        // ç¡®ä¿ audioElement å·²ç»‘å®š
                        if (audioElement.value && !audio) {
                            audio = audioElement.value
                            setupAudioEventListeners()
                        }

                        // åˆå§‹åŒ–æ³¢å½¢å›¾
                        if (waveformBars.value.length === 0) {
                            initWaveform()
                        }
                        statusMsg.value = t('podcast.readyWithCount', { count: subtitles.value.length })
                    }, 2000)
                } else if (subtitles.value.length > 1 && !audio) {
                    // å¦‚æœç¬¬ä¸€æ®µé”™è¿‡äº†ï¼Œç¬¬äºŒæ®µç«‹å³æ˜¾ç¤º
                    statusMsg.value = t('podcast.preparingAudio')
                    setTimeout(async () => {
                        if (isIOSSafari()) {
                            await loadAudio(false)
                        } else {
                            await initMediaSourceAudio(false)
                        }
                        showPlayer.value = true
                        await nextTick()

                        // ç¡®ä¿ audioElement å·²ç»‘å®š
                        if (audioElement.value && !audio) {
                            audio = audioElement.value
                            setupAudioEventListeners()
                        }

                        // åˆå§‹åŒ–æ³¢å½¢å›¾
                        if (waveformBars.value.length === 0) {
                            initWaveform()
                        }
                        statusMsg.value = t('podcast.readyWithCount', { count: subtitles.value.length })
                    }, 2000)
                } else if (audio && durationChanged) {
                    // éŸ³é¢‘æ—¶é•¿å·²æ›´æ–°ï¼Œç«‹å³è¿½åŠ æ–°å†…å®¹ï¼ˆæ— ç¼ï¼‰
                    // ç¡®ä¿åˆå§‹åŠ è½½å·²å®Œæˆï¼Œé¿å…åœ¨åˆå§‹åŠ è½½æ—¶é‡å¤è¿½åŠ ç¬¬ä¸€æ®µ
                    if (!isInitialAudioLoadComplete) {
                        console.log('â¸ï¸ Skipping audio update: initial load not complete yet')
                        return
                    }

                    // ç¡®ä¿éŸ³é¢‘å·²ç»åŠ è½½å®Œæˆ
                    const audioReady = audio.readyState >= HTMLMediaElement.HAVE_METADATA
                    const audioDuration = getDisplayedDuration() || audio.duration || 0
                    // åªæœ‰å½“éŸ³é¢‘å·²åŠ è½½ä¸”æ–°æ—¶é•¿ç¡®å®å¤§äºå½“å‰éŸ³é¢‘æ—¶é•¿æ—¶æ‰è¿½åŠ 
                    if (audioReady && currentDuration > audioDuration + 0.5) {
                        console.log(`ğŸ“Š Audio duration updated from ${audioDuration.toFixed(2)}s to ${currentDuration.toFixed(2)}s`)
                        if (mediaSource && sourceBuffer) {
                            // æ¡Œé¢ç­‰æ”¯æŒ MSEï¼šæ— ç¼è¿½åŠ 
                            // ç¡®ä¿ lastBytePosition å·²æ­£ç¡®è®¾ç½®ï¼Œé¿å…é‡å¤è¯·æ±‚
                            if (lastBytePosition > 0) {
                                switchAudioSeamlessly()
                            } else {
                                console.warn('âš ï¸ lastBytePosition is 0, skipping seamless switch to avoid duplicate')
                            }
                        } else {
                            // iOS ç­‰ä¸æ”¯æŒ MSEï¼šé‡æ–°åŠ è½½éŸ³é¢‘å¹¶æ¢å¤ä½ç½®
                            reloadAudioForIOS()
                        }
                        statusMsg.value = t('podcast.generatingStatusWithCount', { count: subtitles.value.length })
                        await nextTick()
                    } else {
                        console.log(`â¸ï¸ Skipping audio update: audioReady=${audioReady}, currentDuration=${currentDuration.toFixed(2)}s, audioDuration=${audioDuration.toFixed(2)}s`)
                    }
                } else {
                    // åªæ›´æ–°çŠ¶æ€
                    statusMsg.value = t('podcast.generatingStatusWithCount', { count: subtitles.value.length })
                    await nextTick()
                }
            } else if (message.type === 'complete') {
                statusClass.value = 'complete'
                statusMsg.value = t('podcast.completed', { count: subtitles.value.length })
                isGenerating = false  // ç”Ÿæˆå®Œæˆï¼Œåœæ­¢æ¨¡æ‹Ÿæ³¢å½¢å›¾åŠ¨ç”»
                simulatedWaveformStartTime = null
                await nextTick()
                wsConnection.close()
                stopAudioUpdateChecker()
                showStopBtn.value = false
                showDownloadBtn.value = true
                await nextTick()

                if (message.data && message.data.audio_url) {
                    currentAudioUrl = message.data.audio_url
                    if (message.data.timestamps_url) {
                        // ä½¿ç”¨ apiCall è‡ªåŠ¨æ·»åŠ è®¤è¯å¤´
                        // ç§»é™¤æŸ¥è¯¢å‚æ•°ï¼ˆå¦‚ ?t=timestampï¼‰ï¼Œå› ä¸º apiCall ä¼šå¤„ç† URL
                        const cleanTimestampsUrl = message.data.timestamps_url.split('?')[0]
                        apiCall(cleanTimestampsUrl)
                            .then(response => {
                                if (!response || !response.ok) {
                                    throw new Error(`HTTP error! status: ${response ? response.status : 'unknown'}`)
                                }
                                return response.json()
                            })
                            .then(timestamps => {
                                subtitleTimestamps.value = timestamps || []
                            })
                            .catch(err => {
                                console.warn('Failed to load subtitle timestamps:', err)
                            })
                    }
                    switchToFinalAudio(currentAudioUrl)
                }

                loadHistory()
            } else if (message.type === 'stopped') {
                statusMsg.value = t('podcast.stopped')
                isGenerating = false  // åœæ­¢ç”Ÿæˆï¼Œåœæ­¢æ¨¡æ‹Ÿæ³¢å½¢å›¾åŠ¨ç”»
                simulatedWaveformStartTime = null
                await nextTick()
                stopAudioUpdateChecker()
                showStopBtn.value = false
                showDownloadBtn.value = false
                statusClass.value = ''
                await nextTick()
                // æ”¶åˆ°åœæ­¢ç¡®è®¤åï¼Œå…³é—­ WebSocket è¿æ¥
                if (wsConnection && wsConnection.readyState !== WebSocket.CLOSED) {
                    wsConnection.close()
                }
            } else if (message.type === 'error' || message.error) {
                // å¤„ç†é”™è¯¯æ¶ˆæ¯
                const errorMessage = message.error || message.message || t('podcast.generationFailed')
                showAlert(errorMessage, 'error')
                statusMsg.value = t('podcast.generationFailed')
                statusClass.value = ''
                isGenerating = false  // ç”Ÿæˆå¤±è´¥ï¼Œåœæ­¢æ¨¡æ‹Ÿæ³¢å½¢å›¾åŠ¨ç”»
                simulatedWaveformStartTime = null
                stopAudioUpdateChecker()
                showStopBtn.value = false
                showDownloadBtn.value = false
                await nextTick()
                // å…³é—­ WebSocket è¿æ¥
                if (wsConnection && wsConnection.readyState !== WebSocket.CLOSED) {
                    wsConnection.close()
                }
                return  // æå‰è¿”å›ï¼Œä¸ç»§ç»­å¤„ç†
            }
        }

        wsConnection.onerror = (error) => {
            throw new Error('WebSocketè¿æ¥é”™è¯¯')
        }
    } catch (error) {
        showAlert(t('podcast.generationFailed') + ': ' + error.message, 'error')
        statusMsg.value = t('podcast.generationFailed')
        statusClass.value = ''
        isGenerating = false  // ç”Ÿæˆå¤±è´¥ï¼Œåœæ­¢æ¨¡æ‹Ÿæ³¢å½¢å›¾åŠ¨ç”»
        simulatedWaveformStartTime = null
        stopAudioUpdateChecker()
        showStopBtn.value = false
        showDownloadBtn.value = false
    }
}

// åˆ‡æ¢åˆ°æœ€ç»ˆéŸ³é¢‘
async function switchToFinalAudio(finalUrl) {
    try {
        const wasPlaying = audio && !audio.paused
        const prevTime = audio ? audio.currentTime : 0
        mergedAudioUrl = finalUrl
        if (mediaSource) { mediaSource = null }
        if (sourceBuffer) { sourceBuffer = null }
        shouldResumePlayback = !!wasPlaying
        // ä¼˜å…ˆä½¿ç”¨ MediaSource æ–¹å¼ï¼ˆæ”¯æŒæ— ç¼æµå¼æ›´æ–°ï¼‰
        await initMediaSourceAudio(false)
        if (!audio) return
        const onCanPlay = async () => {
            try {
                const total = getDisplayedDuration()
                if (total > 0) {
                    duration.value = total
                }
                if (prevTime > 0) {
                    audio.currentTime = Math.min(prevTime, total || prevTime)
                }
                if (wasPlaying) {
                    await audio.play()
                    isPlaying.value = true
                    if (!animationFrameId) visualize()
                } else {
                    isPlaying.value = false
                }
            } finally {
                audio.removeEventListener('canplay', onCanPlay)
            }
        }
        audio.addEventListener('canplay', onCanPlay)
    } catch (e) {
        console.error('Error switching to final audio:', e)
    }
}

// åœæ­¢ç”Ÿæˆ
function stopGeneration() {
    if (wsConnection) {
        if (wsConnection.readyState === WebSocket.OPEN) {
            // å‘é€åœæ­¢ä¿¡å·ï¼Œä½†ä¸ç«‹å³å…³é—­è¿æ¥ï¼Œç­‰å¾…åç«¯ç¡®è®¤
            try {
                wsConnection.send(JSON.stringify({ type: 'stop' }))
                // è®¾ç½®ä¸€ä¸ªè¶…æ—¶ï¼Œå¦‚æœ3ç§’å†…æ²¡æœ‰æ”¶åˆ°ç¡®è®¤ï¼Œåˆ™å¼ºåˆ¶å…³é—­
                const stopTimeout = setTimeout(() => {
                    if (wsConnection && wsConnection.readyState !== WebSocket.CLOSED) {
                        wsConnection.close()
                    }
                    clearTimeout(stopTimeout)
                }, 3000)
            } catch (error) {
                console.error('Error sending stop signal:', error)
                // å¦‚æœå‘é€å¤±è´¥ï¼Œç›´æ¥å…³é—­è¿æ¥
                wsConnection.close()
            }
        } else if (wsConnection.readyState === WebSocket.CONNECTING) {
            // å¦‚æœè¿˜åœ¨è¿æ¥ä¸­ï¼Œç›´æ¥å…³é—­
            wsConnection.close()
        }
    }
    // ç«‹å³æ›´æ–°UIçŠ¶æ€
    statusMsg.value = t('podcast.generating')
    stopAudioUpdateChecker()
    showStopBtn.value = false
    showDownloadBtn.value = false
    // æ³¨æ„ï¼šstatusClass ä¿æŒ 'generating' ç›´åˆ°æ”¶åˆ° 'stopped' æ¶ˆæ¯
}

// ä¸‹è½½éŸ³é¢‘
function downloadAudio() {
    // ä¼˜å…ˆä½¿ç”¨ sessionAudioUrlï¼ˆè¯¦æƒ…æ¨¡å¼ï¼‰ï¼Œç„¶åæ˜¯ currentAudioUrlï¼ˆç”Ÿæˆå®Œæˆï¼‰ï¼Œæœ€åæ˜¯ mergedAudioUrlï¼ˆç”Ÿæˆä¸­ï¼‰
    // å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°è¯•ä½¿ç”¨ audioUrl.valueï¼ˆå“åº”å¼éŸ³é¢‘ URLï¼‰
    const urlToDownload = sessionAudioUrl || currentAudioUrl || mergedAudioUrl || audioUrl.value
    if (urlToDownload) {
        const link = document.createElement('a')
        link.href = addCacheBustingParam(urlToDownload);
        link.download = 'podcast.mp3'
        document.body.appendChild(link)
        link.click()
        document.body.removeChild(link)
    } else {
        showAlert(t('podcast.noAudioToDownload'), 'warning')
    }
}

// åº”ç”¨åˆ°æ•°å­—äººï¼ˆå‚è€ƒ useTemplate çš„å®ç°æ–¹å¼ï¼‰
async function applyToDigitalHuman() {
    // ä¼˜å…ˆä½¿ç”¨å½“å‰ä¼šè¯çš„éŸ³é¢‘ URLï¼Œå¦åˆ™ä½¿ç”¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„éŸ³é¢‘ URL
    const audioUrl = sessionAudioUrl || currentAudioUrl || mergedAudioUrl
    console.log('Applying to digital human, audioUrl:', audioUrl)

    if (!audioUrl) {
        showAlert(t('podcast.pleaseGenerateFirst'), 'warning')
        return
    }

    try {
        // å…ˆè®¾ç½®ä»»åŠ¡ç±»å‹ä¸º s2vï¼ˆè¯­éŸ³é©±åŠ¨ï¼‰
        selectedTaskId.value = 's2v'

        // è·å–å½“å‰è¡¨å•
        const currentForm = getCurrentForm()

        // ç«‹å³åˆ‡æ¢åˆ°åˆ›å»ºè§†å›¾å¹¶å±•å¼€åˆ›ä½œåŒºåŸŸï¼ˆå‚è€ƒ useTemplateï¼‰
        isCreationAreaExpanded.value = true
        switchToCreateView()

        // å¼‚æ­¥åŠ è½½éŸ³é¢‘æ–‡ä»¶
        try {
            // ä½¿ç”¨ apiCall è·å–éŸ³é¢‘ï¼ˆæ”¯æŒè®¤è¯ï¼‰
            const response = await apiCall(audioUrl)
            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`)
            }
            const blob = await response.blob()

            // æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šæ­£ç¡®çš„MIMEç±»å‹
            let mimeType = blob.type
            if (!mimeType || mimeType === 'application/octet-stream') {
                // ä» URL ä¸­æå–æ‰©å±•å
                const urlPath = audioUrl.split('?')[0]
                const ext = urlPath.toLowerCase().split('.').pop()
                const mimeTypes = {
                    'mp3': 'audio/mpeg',
                    'wav': 'audio/wav',
                    'mp4': 'audio/mp4',
                    'aac': 'audio/aac',
                    'ogg': 'audio/ogg',
                    'm4a': 'audio/mp4'
                }
                mimeType = mimeTypes[ext] || 'audio/mpeg'
            }

            const filename = `podcast_${Date.now()}.${mimeType.split('/')[1] || 'mp3'}`
            const file = new File([blob], filename, { type: mimeType })

            // è®¾ç½®éŸ³é¢‘æ–‡ä»¶åˆ°è¡¨å•
            currentForm.audioFile = file

            // ä½¿ç”¨ FileReader ç”Ÿæˆ data URL ä½œä¸ºé¢„è§ˆï¼ˆå‚è€ƒ useTemplateï¼‰
            const reader = new FileReader()
            reader.onload = (e) => {
                const audioDataUrl = e.target.result
                setCurrentAudioPreview(audioDataUrl)
                console.log('æ’­å®¢éŸ³é¢‘é¢„è§ˆå·²è®¾ç½®')

                // è§¦å‘éŸ³é¢‘ä¸Šä¼ å¤„ç†ï¼ˆç”¨äºéŸ³é¢‘åˆ†ç¦»ç­‰ï¼‰
                const fileList = new DataTransfer()
                fileList.items.add(file)
                const event = {
                    target: {
                        files: fileList.files
                    }
                }
                handleAudioUpload(event)
            }
            reader.readAsDataURL(file)

            showAlert(t('podcast.applySuccess'), 'success')
        } catch (error) {
            console.error('åŠ è½½æ’­å®¢éŸ³é¢‘å¤±è´¥:', error)
            showAlert(t('podcast.loadAudioFailed'), 'error')
        }
    } catch (error) {
        console.error('åº”ç”¨åˆ°æ•°å­—äººå¤±è´¥:', error)
        showAlert(t('podcast.applyFailed') + ': ' + error.message, 'error')
    }
}

// å­˜å‚¨å†å²ä¼šè¯çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå­—å¹•ã€æ—¶é—´æˆ³ç­‰ï¼‰
const historySessionData = new Map()

// åŠ è½½å†å²è®°å½•ï¼ˆåªè·å–å¹¶å­˜å‚¨å†å²æ•°æ®ï¼‰
async function loadHistory() {
    try {
        try {
            loadingHistory.value = true
        } catch (e) {
            console.warn('Error setting loadingHistory:', e)
            return
        }

        // ä½¿ç”¨ apiCall è‡ªåŠ¨æ·»åŠ è®¤è¯å¤´ï¼Œè°ƒç”¨ä»»åŠ¡æ¥å£è·å–å†å²åˆ—è¡¨
        const response = await apiCall('/api/v1/podcast/history')
        if (!response || !response.ok) {
            const errorText = response ? `HTTP error! status: ${response.status}` : 'Network error'
            throw new Error(errorText)
        }
        const data = await response.json()

        // æ¸…ç©ºå†å²æ•°æ®
        historySessionData.clear()

        // å­˜å‚¨æ¯ä¸ªä¼šè¯çš„å®Œæ•´æ•°æ®åˆ° Mapï¼ˆç”¨äºè¯¦æƒ…é¡µåŠ è½½ï¼‰
        // åŒæ—¶å‡†å¤‡ç”¨äº template æ¸²æŸ“çš„åˆ—è¡¨æ•°æ®
        const items = []
        if (data.sessions && Array.isArray(data.sessions)) {
            data.sessions.forEach((session, index) => {
                if (session.session_id) {
                    // å­˜å‚¨åˆ° Mapï¼ˆç”¨äºè¯¦æƒ…é¡µï¼‰
                    historySessionData.set(session.session_id, {
                        rounds: session.rounds || [],
                        subtitles: session.subtitles || [],
                        timestamps: session.timestamps || [],
                        user_input: session.user_input || '',
                        outputs: session.outputs || session.extra_info?.outputs || null,
                        has_audio: session.has_audio || false
                    })

                    // æ·»åŠ åˆ°åˆ—è¡¨ï¼ˆç”¨äº template æ¸²æŸ“ï¼‰
                    items.push({
                        session_id: session.session_id,
                        user_input: session.user_input || '',
                        has_audio: session.has_audio || false,
                        displayText: (session.user_input || `ä¼šè¯ ${index + 1}`).length > 40
                            ? (session.user_input || `ä¼šè¯ ${index + 1}`).substring(0, 40) + '...'
                            : (session.user_input || `ä¼šè¯ ${index + 1}`)
                    })
                }
            })
        }

        // æ›´æ–°å“åº”å¼å˜é‡ï¼Œtemplate ä¼šè‡ªåŠ¨æ¸²æŸ“
        try {
            historyItems.value = items
            loadingHistory.value = false
        } catch (e) {
            console.warn('Error setting historyItems:', e)
            try {
                loadingHistory.value = false
            } catch (e2) {
                console.warn('Error setting loadingHistory:', e2)
            }
        }
    } catch (error) {
        console.error('Error loading history:', error)
        try {
            historyItems.value = []
            loadingHistory.value = false
        } catch (e) {
            console.warn('Error setting historyItems:', e)
        }
    }
}

// åŠ è½½ç‰¹å®š session çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä»å†å²æ•°æ®ä¸­è·å–ï¼Œç„¶åé€šè¿‡ outputs è·å–éŸ³é¢‘ URLï¼‰
async function loadSessionDetail(sessionId) {
    try {
        try {
            loadingSessionDetail.value = true
        } catch (e) {
            console.warn('Error setting loadingSessionDetail:', e)
            return
        }

        // åœæ­¢å½“å‰æ’­æ”¾
        if (audio) {
            try {
            audio.pause()
            } catch (e) {
                console.warn('Error pausing audio:', e)
            }
        }

        // æ¸…ç©ºå’Œé‡ç½®çŠ¶æ€
        try {
            audioUrl.value = ''
            subtitles.value = []
            subtitleTimestamps.value = []
            activeSubtitleIndex.value = -1
        showPlayer.value = false
        isPlaying.value = false
        currentTime.value = 0
        duration.value = 0
        progress.value = 0
        audioUserInput.value = ''
        } catch (e) {
            console.warn('Error resetting state:', e)
        }

        sessionAudioUrl = null
        hasLoadedMetadata = false
        analyzerInitialized = false
        // é‡ç½®éŸ³é¢‘åˆ†æå™¨ç›¸å…³çŠ¶æ€
        if (mediaElementSource) {
            mediaElementSource = null
        }
        if (analyser) {
            analyser = null
        }
        if (audioContext && audioContext.state !== 'closed') {
            try {
                audioContext.close()
            } catch (e) {
                console.warn('Error closing audio context:', e)
            }
            audioContext = null
        }
        // æ¸…ç†è·¨åŸŸéŸ³é¢‘çš„é¢„åˆ†ææ•°æ®
        crossOriginWaveformData = null
        crossOriginWaveformDataLoaded = false
        crossOriginWaveformMin = 0
        crossOriginWaveformMax = 0
        lastAnalyzedAudioUrl = null

        // é‡ç½®æ³¢å½¢å›¾
        waveformBars.value = []

        await nextTick()

        // ä»å†å²æ•°æ®ä¸­è·å–ä¼šè¯ä¿¡æ¯
        const sessionData = historySessionData.get(sessionId)
        if (!sessionData) {
            // å¦‚æœå†å²æ•°æ®ä¸­æ²¡æœ‰ï¼Œæ˜¾ç¤ºé”™è¯¯
            try {
                showAlert(t('podcast.sessionDataNotFound'), 'error')
                loadingSessionDetail.value = false
            } catch (e) {
                console.warn('Error showing alert:', e)
            }
            return
        }

        // è®¾ç½®ç”¨æˆ·è¾“å…¥å’Œå­—å¹•æ•°æ®
        try {
            audioUserInput.value = sessionData.user_input || ''

            // ä½¿ç”¨ rounds æ•°æ®ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            if (sessionData.rounds && sessionData.rounds.length > 0) {
                subtitles.value = []
                subtitleTimestamps.value = []
                sessionData.rounds.forEach((round) => {
                    subtitles.value.push({
                        text: round.text || '',
                        speaker: round.speaker || ''
                    })
                    subtitleTimestamps.value.push({
                        start: round.start || 0.0,
                        end: round.end || 0.0,
                        text: round.text || '',
                        speaker: round.speaker || ''
                    })
                })
            } else if (sessionData.subtitles && sessionData.subtitles.length > 0) {
                subtitles.value = [...sessionData.subtitles]
            }

            if (sessionData.timestamps && sessionData.timestamps.length > 0) {
                subtitleTimestamps.value = [...sessionData.timestamps]
            }
        } catch (e) {
            console.warn('Error setting session data:', e)
            try {
                loadingSessionDetail.value = false
            } catch (e2) {
                console.warn('Error setting loadingSessionDetail:', e2)
            }
            return
        }

        // åœ¨è¯¦æƒ…æ¨¡å¼ä¸‹ï¼Œæ˜¾ç¤ºæ’­æ”¾å™¨åŒºåŸŸï¼ˆåªè¦æœ‰æ•°æ®å°±æ˜¾ç¤ºï¼‰
        if (isDetailMode.value) {
            try {
                console.log('Setting up player and subtitles:', {
                    isDetailMode: isDetailMode.value,
                    subtitlesCount: subtitles.value.length
                })

                // å¦‚æœæœ‰å­—å¹•æ•°æ®ï¼Œæ˜¾ç¤ºæ’­æ”¾å™¨å’Œå­—å¹•
                if (subtitles.value.length > 0) {
                    showPlayer.value = true
                    await nextTick()

                    showSubtitles.value = true
                    await nextTick()
                    console.log('Player and subtitles shown:', {
                        showPlayer: showPlayer.value,
                        showSubtitles: showSubtitles.value
                    })
                } else {
                    // å³ä½¿æ²¡æœ‰å­—å¹•ï¼Œä¹Ÿå…ˆæ˜¾ç¤ºæ’­æ”¾å™¨ï¼ˆéŸ³é¢‘ URL ä¼šåœ¨åé¢è®¾ç½®ï¼‰
                    showPlayer.value = true
                    await nextTick()
                    console.log('Player shown (no subtitles):', {
                        showPlayer: showPlayer.value
                    })
                }
            } catch (e) {
                console.warn('Error showing player/subtitles:', e)
            }
        } else {
            console.log('Not showing player:', {
                isDetailMode: isDetailMode.value
            })
        }

        try {
            // è°ƒç”¨ API è·å–éŸ³é¢‘ URLï¼ˆAPI ä¼šä» outputs æˆ–æ•°æ®åº“è·å–è·¯å¾„å¹¶è½¬æ¢ä¸º CDN URLï¼‰
            const audioUrlResponse = await apiCall(`/api/v1/podcast/session/${sessionId}/audio_url`)
            if (!audioUrlResponse || !audioUrlResponse.ok) {
                throw new Error(`Failed to get audio URL: ${audioUrlResponse ? audioUrlResponse.status : 'unknown'}`)
            }

            const audioUrlData = await audioUrlResponse.json()
            sessionAudioUrl = audioUrlData.audio_url

            if (!sessionAudioUrl) {
                throw new Error('Audio URL not found')
            }

            // è®¾ç½®éŸ³é¢‘ URL
            try {
                if (sessionAudioUrl.startsWith('http://') || sessionAudioUrl.startsWith('https://')) {
                    audioUrl.value = sessionAudioUrl
                } else {
                    audioUrl.value = addCacheBustingParam(sessionAudioUrl)
                }
            } catch (e) {
                console.warn('Error setting audioUrl:', e)
            }

            await nextTick()

            // ç¡®ä¿æ’­æ”¾å™¨å·²æ˜¾ç¤ºï¼ˆåœ¨è¯¦æƒ…æ¨¡å¼ä¸‹ï¼Œåªè¦æœ‰éŸ³é¢‘ URL å°±åº”è¯¥æ˜¾ç¤ºï¼‰
            if (isDetailMode.value && !showPlayer.value) {
                try {
                    showPlayer.value = true
                    await nextTick()
                } catch (e) {
                    console.warn('Error showing player:', e)
                }
            }

            // å¦‚æœæœ‰å­—å¹•ä½†å­—å¹•åŒºåŸŸæœªæ˜¾ç¤ºï¼Œæ˜¾ç¤ºå­—å¹•åŒºåŸŸ
            if (isDetailMode.value && subtitles.value.length > 0 && !showSubtitles.value) {
                try {
                    showSubtitles.value = true
                    await nextTick()
                } catch (e) {
                    console.warn('Error showing subtitles:', e)
                }
            }

            // åˆå§‹åŒ– audio å…ƒç´ å’Œäº‹ä»¶ç›‘å¬å™¨ï¼ˆè¯¦æƒ…é¡µéœ€è¦ï¼‰
            // ç­‰å¾… audioUrl è®¾ç½®å®Œæˆåå†åˆå§‹åŒ–
            await nextTick()

            // ç¡®ä¿ audioElement å·²ç»æ¸²æŸ“
            if (!audioElement.value) {
                console.warn('audioElement not available, waiting...')
                await nextTick()
            }

            if (audioElement.value) {
                // é‡æ–°ç»‘å®š audio å˜é‡ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°çš„å…ƒç´ ï¼‰
                audio = audioElement.value
                // ç¡®ä¿éŸ³é‡è®¾ç½®ä¸º 1.0ï¼ˆé‡è¦ï¼šé¿å…æ— å£°ï¼‰
                audio.volume = 1.0
                setupAudioEventListeners()

                // ç¡®ä¿éŸ³é¢‘å…ƒç´ å·²åŠ è½½
                // å¦‚æœ audioUrl å·²è®¾ç½®ä½†éŸ³é¢‘è¿˜æ²¡æœ‰å¼€å§‹åŠ è½½ï¼Œè§¦å‘åŠ è½½
                if (audioUrl.value) {
                    try {
                        // å¦‚æœ src å·²ç»è®¾ç½®ä½† readyState è¿˜æ˜¯ HAVE_NOTHINGï¼Œå¼ºåˆ¶é‡æ–°åŠ è½½
                        if (audio.src !== audioUrl.value) {
                            audio.src = audioUrl.value
                        }
                        if (audio.readyState === HTMLMediaElement.HAVE_NOTHING) {
                            audio.load()
                            console.log('Audio element load() called, src:', audioUrl.value.substring(0, 100))
                        } else {
                            console.log('Audio already loaded, readyState:', audio.readyState)
                            // å¦‚æœå·²ç»åŠ è½½ï¼Œæ‰‹åŠ¨è§¦å‘å…ƒæ•°æ®åŠ è½½äº‹ä»¶
                            if (audio.readyState >= HTMLMediaElement.HAVE_METADATA) {
                                onAudioLoadedMetadata()
                            }
                        }
                    } catch (e) {
                        console.warn('Error calling audio.load():', e)
                    }
                } else {
                    console.warn('audioUrl.value is empty')
                }
            } else {
                console.error('audioElement.value is still null after nextTick')
            }

            // åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡æ¢å¤ï¼ˆè¯¦æƒ…é¡µéœ€è¦ï¼Œé¿å…é‡å¤æ·»åŠ ï¼‰
            if (!window.__podcastResumeContextOnGesture) {
                window.__podcastResumeContextOnGesture = function resumeContextOnGesture() {
                    if (audioContext && audioContext.state === 'suspended') {
                        audioContext.resume().catch(() => {})
                    }
                    document.removeEventListener('touchend', window.__podcastResumeContextOnGesture)
                    document.removeEventListener('click', window.__podcastResumeContextOnGesture)
                }
                document.addEventListener('touchend', window.__podcastResumeContextOnGesture, { passive: true })
                document.addEventListener('click', window.__podcastResumeContextOnGesture)
            }

            // æ·»åŠ å…¨å±€é¼ æ ‡äº‹ä»¶ç›‘å¬å™¨ï¼ˆè¿›åº¦æ¡æ‹–æ‹½ï¼Œè¯¦æƒ…é¡µéœ€è¦ï¼Œé¿å…é‡å¤æ·»åŠ ï¼‰
            if (!window.__podcastProgressListenersAdded) {
                document.addEventListener('mousemove', onProgressMouseMove)
                document.addEventListener('mouseup', onProgressMouseUp)
                document.addEventListener('touchmove', onProgressTouchMove, { passive: true })
                document.addEventListener('touchend', onProgressTouchEnd, { passive: true })
                window.__podcastProgressListenersAdded = true
            }

            // åˆå§‹åŒ–æ³¢å½¢å›¾ï¼ˆç¡®ä¿åœ¨éŸ³é¢‘å…ƒç´ å‡†å¤‡å¥½ååˆå§‹åŒ–ï¼‰
            await nextTick()
            if (waveformBars.value.length === 0) {
                initWaveform()
                console.log('Waveform initialized, bars count:', waveformBars.value.length)
            }

            // å¦‚æœéŸ³é¢‘å·²ç»å¯ä»¥æ’­æ”¾ï¼Œç«‹å³åˆå§‹åŒ–åˆ†æå™¨
            if (audio && audio.readyState >= HTMLMediaElement.HAVE_METADATA && !analyzerInitialized) {
                try {
                    await initAudioAnalyzer()
                    analyzerInitialized = true
                    console.log('Audio analyzer initialized in loadSessionDetail')
                } catch (e) {
                    console.warn('Error initializing audio analyzer in loadSessionDetail:', e)
                }
            }
            } catch (error) {
            try {
                console.error('Error loading audio:', error)
                showAlert(t('podcast.loadAudioFailedDetail'), 'error')
            } catch (e) {
                console.warn('Error in error handler:', e)
            }
        }
        } catch (error) {
        try {
            console.error('Error loading session detail:', error)
            showAlert(t('podcast.loadSessionFailed'), 'error')
        } catch (e) {
            console.warn('Error in error handler:', e)
        }
        } finally {
        try {
            loadingSessionDetail.value = false
        } catch (e) {
            console.warn('Error setting loadingSessionDetail in finally:', e)
        }
        }
    }

// åˆ‡æ¢ä¾§è¾¹æ 
function toggleSidebar() {
    sidebarCollapsed.value = !sidebarCollapsed.value
}


// ç”¨æˆ·æ»šåŠ¨å­—å¹•
function handleUserScroll() {
    autoFollowSubtitles = false
    if (userScrollTimeout) {
        clearTimeout(userScrollTimeout)
    }
    userScrollTimeout = setTimeout(() => {
        autoFollowSubtitles = true
        userScrollTimeout = null
    }, 5000)
}

// å›è½¦é”®ç”Ÿæˆ
function onInputKeyPress(e) {
    if (e.key === 'Enter') {
        generatePodcast()
    }
}

// ç‚¹å‡»ç¤ºä¾‹è¾“å…¥
async function onExampleClick(example) {
    // å…ˆè®¾ç½®è¾“å…¥æ¡†çš„å€¼
    input.value = example
    // ç­‰å¾… Vue å“åº”å¼æ›´æ–°å®Œæˆ
    await nextTick()
    // ç„¶åå¼€å§‹ç”Ÿæˆ
    generatePodcast()
}

// ç›‘å¬è·¯ç”±å˜åŒ–
watch(() => route.params.session_id, async (newSessionId, oldSessionId) => {
    // å¦‚æœæ˜¯ immediate è°ƒç”¨ä¸”ç»„ä»¶è¿˜æœªå®Œå…¨æŒ‚è½½ï¼Œç­‰å¾…ä¸€ä¸‹
    if (!subtitleSection.value) {
        // ç­‰å¾… DOM æ›´æ–°
        await nextTick()
    }

    if (newSessionId) {
        // è¯¦æƒ…æ¨¡å¼
        try {
            currentSessionId.value = newSessionId
            isDetailMode.value = true
        } catch (e) {
            console.warn('Error setting detail mode:', e)
            return
        }

        // å¦‚æœå†å²æ•°æ®ä¸ºç©ºï¼Œå…ˆåŠ è½½å†å²æ•°æ®ï¼ˆåˆ·æ–°é¡µé¢æ—¶çš„æƒ…å†µï¼‰
        if (historySessionData.size === 0) {
            await loadHistory()
            // ç­‰å¾…å†å²æ•°æ®åŠ è½½å®Œæˆ
            await nextTick()
        }

        // åŠ è½½ä¼šè¯è¯¦æƒ…
        await loadSessionDetail(newSessionId)

        // é‡æ–°åŠ è½½å†å²è®°å½•ä»¥æ›´æ–°é«˜äº®çŠ¶æ€
        try {
            await loadHistory()
        } catch (e) {
            console.warn('Error loading history:', e)
        }
    } else {
        // åˆ—è¡¨æ¨¡å¼
        try {
        currentSessionId.value = null
        isDetailMode.value = false
        } catch (e) {
            console.warn('Error setting list mode:', e)
            return
        }

        // åœæ­¢æ’­æ”¾å¹¶é‡ç½®çŠ¶æ€
        if (audio) {
            try {
            audio.pause()
            } catch (e) {
                console.warn('Error pausing audio:', e)
            }
            audio = null
        }

        // ç§»é™¤éŸ³é¢‘ç›¸å…³çš„äº‹ä»¶ç›‘å¬å™¨ï¼ˆåˆ—è¡¨æ¨¡å¼ä¸éœ€è¦ï¼‰
        if (window.__podcastResumeContextOnGesture) {
            try {
                document.removeEventListener('touchend', window.__podcastResumeContextOnGesture)
                document.removeEventListener('click', window.__podcastResumeContextOnGesture)
            } catch (e) {
                console.warn('Error removing resume context listeners:', e)
            }
            window.__podcastResumeContextOnGesture = null
        }

        if (window.__podcastProgressListenersAdded) {
            try {
                document.removeEventListener('mousemove', onProgressMouseMove)
                document.removeEventListener('mouseup', onProgressMouseUp)
                document.removeEventListener('touchmove', onProgressTouchMove)
                document.removeEventListener('touchend', onProgressTouchEnd)
            } catch (e) {
                console.warn('Error removing progress listeners:', e)
            }
            window.__podcastProgressListenersAdded = false
        }

        // å®‰å…¨åœ°é‡ç½®æ‰€æœ‰å“åº”å¼çŠ¶æ€
        try {
        showPlayer.value = false
        isPlaying.value = false
        currentTime.value = 0
        duration.value = 0
        progress.value = 0
        audioUserInput.value = ''
                audioUrl.value = ''  // æ¸…ç©ºéŸ³é¢‘ URL
                subtitles.value = []  // æ¸…ç©ºå­—å¹•
                subtitleTimestamps.value = []  // æ¸…ç©ºæ—¶é—´æˆ³
                activeSubtitleIndex.value = -1  // é‡ç½®æ¿€æ´»å­—å¹•ç´¢å¼•
                showSubtitles.value = false  // éšè—å­—å¹•
        } catch (e) {
            console.warn('Error resetting state:', e)
        }

        sessionAudioUrl = null  // æ¸…ç©ºä¼šè¯éŸ³é¢‘ URL
    }
}, { immediate: true })  // æ”¹ä¸º trueï¼Œç¡®ä¿åœ¨ç»„ä»¶æŒ‚è½½æ—¶ä¹Ÿå¤„ç†è·¯ç”±å‚æ•°

// ç›‘å¬è·¯ç”±è·¯å¾„å˜åŒ–ï¼Œç®¡ç†å†å²è®°å½•åˆ·æ–°å®šæ—¶å™¨
watch(() => route.path, (newPath, oldPath) => {
    const isPodcastGenerateRoute = () => {
        return route.path.startsWith('/podcast_generate')
    }

    // å¦‚æœè¿›å…¥ podcast_generate è·¯ç”±ï¼Œå¯åŠ¨å®šæ—¶å™¨
    if (isPodcastGenerateRoute() && !window.__podcastHistoryInterval) {
        const historyInterval = setInterval(() => {
            // å†æ¬¡æ£€æŸ¥è·¯ç”±ï¼Œå¦‚æœä¸åœ¨ podcast_generate è·¯ç”±ä¸‹ï¼Œæ¸…é™¤å®šæ—¶å™¨
            if (isPodcastGenerateRoute()) {
                loadHistory()
            } else {
                if (window.__podcastHistoryInterval) {
                    clearInterval(window.__podcastHistoryInterval)
                    window.__podcastHistoryInterval = null
                }
            }
        }, 60000)

        window.__podcastHistoryInterval = historyInterval
    }
    // å¦‚æœç¦»å¼€ podcast_generate è·¯ç”±ï¼Œæ¸…é™¤å®šæ—¶å™¨
    else if (!isPodcastGenerateRoute() && window.__podcastHistoryInterval) {
        clearInterval(window.__podcastHistoryInterval)
        window.__podcastHistoryInterval = null
    }
}, { immediate: true })

onMounted(async () => {
    // ç­‰å¾… DOM å®Œå…¨æŒ‚è½½
    await nextTick()

    // å°å±å¹•é»˜è®¤æŠ˜å ä¾§è¾¹æ 
    if (window.matchMedia && window.matchMedia('(max-width: 768px)').matches) {
        sidebarCollapsed.value = true
    }

    // åŠ è½½å†å²è®°å½•ï¼ˆä¸»é¡µä¾§è¾¹æ éœ€è¦ï¼Œè¯¦æƒ…é¡µä¹Ÿéœ€è¦å†å²æ•°æ®ï¼‰
    await loadHistory()

    // å¦‚æœ URL ä¸­æœ‰ session_idï¼Œwatch å›è°ƒä¼šå¤„ç†ï¼ˆimmediate: trueï¼‰
    // ä½†ä¸ºäº†ç¡®ä¿åœ¨åˆ·æ–°æ—¶èƒ½æ­£ç¡®åŠ è½½ï¼Œè¿™é‡Œä¹Ÿæ£€æŸ¥ä¸€ä¸‹
    const sessionId = route.params.session_id
    if (sessionId && !isDetailMode.value) {
        // å¦‚æœ watch æ²¡æœ‰å¤„ç†ï¼ˆå¯èƒ½å› ä¸ºæ—¶æœºé—®é¢˜ï¼‰ï¼Œæ‰‹åŠ¨å¤„ç†
        await nextTick()
        if (route.params.session_id === sessionId && !isDetailMode.value) {
            currentSessionId.value = sessionId
            isDetailMode.value = true
            // å†å²æ•°æ®å·²ç»åŠ è½½ï¼Œç›´æ¥åŠ è½½è¯¦æƒ…
            await loadSessionDetail(sessionId)
            // é‡æ–°åŠ è½½å†å²è®°å½•ä»¥æ›´æ–°é«˜äº®çŠ¶æ€
            await loadHistory()
        }
    }

    // æ³¨æ„ï¼šå†å²è®°å½•åˆ·æ–°å®šæ—¶å™¨ç”±è·¯ç”±ç›‘å¬å™¨ç®¡ç†ï¼ˆwatch route.pathï¼‰
    // åªæœ‰åœ¨ podcast_generate è·¯ç”±ä¸‹æ—¶æ‰ä¼šå¯åŠ¨å®šæ—¶å™¨
})

// æ¸…ç†å‡½æ•° - å¿…é¡»åœ¨ onMounted å¤–éƒ¨å®šä¹‰
onBeforeUnmount(() => {
    // ç»„ä»¶å³å°†å¸è½½ï¼Œæ¸…ç†å·¥ä½œç”± onUnmounted å¤„ç†
})

    onUnmounted(() => {
    // æ¸…ç†å®šæ—¶å™¨
    if (window.__podcastHistoryInterval) {
        clearInterval(window.__podcastHistoryInterval)
        window.__podcastHistoryInterval = null
    }

    // æ¸…ç†æ»šåŠ¨èŠ‚æµå®šæ—¶å™¨
    if (scrollThrottleTimer) {
        clearTimeout(scrollThrottleTimer)
        scrollThrottleTimer = null
    }

        stopAudioUpdateChecker()

        // æ¸…ç†è¿›åº¦æ¡æ‹–æ‹½äº‹ä»¶ç›‘å¬å™¨
    try {
        document.removeEventListener('mousemove', onProgressMouseMove)
        document.removeEventListener('mouseup', onProgressMouseUp)
        document.removeEventListener('touchmove', onProgressTouchMove)
        document.removeEventListener('touchend', onProgressTouchEnd)
    } catch (e) {
        console.warn('Error removing progress event listeners:', e)
    }

    // å­—å¹•äº‹ä»¶ç›‘å¬å™¨ç°åœ¨é€šè¿‡ template ç»‘å®šï¼ŒVue ä¼šè‡ªåŠ¨æ¸…ç†

    // æ¸…ç†éŸ³é¢‘ç›¸å…³èµ„æº
        if (audio) {
        try {
            audio.pause()
            if (audio.src && audio.src.startsWith('blob:')) {
                URL.revokeObjectURL(audio.src)
            }
        } catch (e) {
            console.warn('Error cleaning up audio:', e)
        }
            audio = null
        }

    if (wsConnection && wsConnection.readyState !== WebSocket.CLOSED) {
        try {
            wsConnection.close()
        } catch (e) {
            console.warn('Error closing WebSocket:', e)
        }
    }

        if (animationFrameId) {
        try {
            cancelAnimationFrame(animationFrameId)
        } catch (e) {
            console.warn('Error canceling animation frame:', e)
        }
        animationFrameId = null
    }

        if (audioContext && audioContext.state !== 'closed') {
        try {
            audioContext.close()
        } catch (e) {
            console.warn('Error closing audio context:', e)
        }
    }

    // æ¸…ç† WebAudio ç›¸å…³èµ„æº
    if (webAudioContext && webAudioContext.state !== 'closed') {
        try {
            webAudioContext.close()
        } catch (e) {
            console.warn('Error closing webAudio context:', e)
        }
    }

    if (webAudioTimeUpdateFrame) {
        try {
            cancelAnimationFrame(webAudioTimeUpdateFrame)
        } catch (e) {
            console.warn('Error canceling webAudio time update frame:', e)
        }
        webAudioTimeUpdateFrame = null
    }
})
</script>

<template>
    <div class="bg-[#f5f5f7] dark:bg-[#000000] transition-colors duration-300 w-full h-full flex flex-col overflow-hidden">
        <!-- TopBar -->
        <topMenu />

        <div class="flex flex-col sm:flex-row flex-1 w-full overflow-hidden">
            <!-- ä¾§è¾¹æ å†å²è®°å½• -->
            <div
                class="w-full max-h-[300px] order-[-1] bg-white dark:bg-[#111] rounded-xl p-5 overflow-hidden flex flex-col transition-all duration-300 ease-in-out relative flex-shrink-0 sm:w-[300px] sm:max-h-none sm:order-none border border-black/6 dark:border-white/8"
                :class="{
                    'h-16 p-5 w-full sm:w-[50px] sm:p-5 sm:pl-2.5 sm:pr-2.5': sidebarCollapsed
                }"
                ref="sidebar">
                <!-- åŠ å·æŒ‰é’®ï¼ˆç”Ÿæˆæ’­å®¢ï¼‰ -->
                <button
                    class="absolute top-[15px] right-[50px] bg-black/6 dark:bg-white/10 border border-black/12 dark:border-white/20 rounded-md w-7 h-7 flex items-center justify-center cursor-pointer transition-all duration-200 text-[#1d1d1f] dark:text-white text-sm z-[3] hover:bg-black/10 dark:hover:bg-white/20 sm:top-[15px] sm:right-[50px]"
                    :class="{
                        'right-[50px] sm:right-[50px]': sidebarCollapsed
                    }"
                    @click="router.push('/podcast_generate')"
                    :title="t('podcast.generatePodcast')"
                    :aria-label="t('podcast.generatePodcast')">
                    <svg
                        class="w-4 h-4 fill-current"
                        viewBox="0 0 24 24"
                        aria-hidden="true">
                        <path d="M19 13h-6v6h-2v-6H5v-2h6V5h2v6h6v2z"/>
                    </svg>
                </button>
                <!-- æŠ˜å æŒ‰é’® -->
                <button
                    class="absolute top-[15px] right-[15px] bg-black/6 dark:bg-white/10 border border-black/12 dark:border-white/20 rounded-md w-7 h-7 flex items-center justify-center cursor-pointer transition-all duration-200 text-[#1d1d1f] dark:text-white text-sm z-[3] hover:bg-black/10 dark:hover:bg-white/20 sm:top-[15px] sm:right-[15px]"
                    :class="{
                        'right-2.5 sm:right-2.5': sidebarCollapsed
                    }"
                    @click="toggleSidebar"
                    :title="t('podcast.toggleSidebar')"
                    :aria-label="t('podcast.toggleSidebar')">
                    <svg
                        class="w-4 h-4 transition-transform duration-200 ease-in-out fill-current"
                        :class="{
                            'rotate-180': sidebarCollapsed
                        }"
                        viewBox="0 0 24 24"
                        aria-hidden="true">
                        <path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path>
                    </svg>
                </button>
                <h3
                    class="text-base font-semibold mb-4 text-[#1d1d1f] dark:text-white pr-20 sticky top-0 z-[2] block">{{ t('podcast.historyTitle') }}</h3>
                <div
                    class="overflow-y-auto flex-1 [-webkit-overflow-scrolling:touch] [scrollbar-width:thin] [scrollbar-color:#d1d1d6_#f5f5f7] dark:[scrollbar-color:#333_#0a0a0a] [&::-webkit-scrollbar]:w-1.5 [&::-webkit-scrollbar-track]:bg-[#f5f5f7] dark:[&::-webkit-scrollbar-track]:bg-[#0a0a0a] [&::-webkit-scrollbar-track]:rounded-sm [&::-webkit-scrollbar-thumb]:bg-[#d1d1d6] dark:[&::-webkit-scrollbar-thumb]:bg-[#333] [&::-webkit-scrollbar-thumb]:rounded-sm relative"
                    :class="{
                        'hidden sm:hidden': sidebarCollapsed
                    }">
                    <!-- Loading è¦†ç›–å±‚ï¼ˆåŠ è½½å†å²ä»»åŠ¡æ—¶ï¼‰- åœ¨ä¾§è¾¹æ å†… -->
                    <div
                        v-if="loadingHistory"
                        class="absolute inset-0 flex items-center justify-center z-50 bg-white/80 dark:bg-[#111]/80 backdrop-blur-sm">
                        <Loading />
                    </div>

                    <!-- å†å²è®°å½•åˆ—è¡¨ -->
                    <template v-if="!loadingHistory">
                        <div v-if="historyItems.length === 0" class="text-[#86868b] dark:text-[#666] text-[13px] text-center p-5">
                            {{ t('podcast.noHistory') }}
                        </div>
                        <div
                            v-for="(item, index) in historyItems"
                            :key="item.session_id || index"
                            @click="router.push(`/podcast_generate/${item.session_id}`)"
                            :class="[
                                'p-3 bg-white dark:bg-[#1a1a1a] rounded-lg mb-2 cursor-pointer transition-all duration-200 border',
                                currentSessionId === item.session_id
                                    ? 'border-[#1d1d1f] dark:border-white'
                                    : 'border-black/6 dark:border-transparent',
                                'hover:bg-[#f5f5f7] dark:hover:bg-[#222] hover:border-black/12 dark:hover:border-[#444]'
                            ]">
                            <div class="text-[13px] text-[#1d1d1f] dark:text-white mb-1 overflow-hidden text-ellipsis whitespace-nowrap">
                                {{ item.displayText }}
                            </div>
                            <div class="text-[11px] text-[#86868b] dark:text-[#666]">
                                {{ item.has_audio ? t('podcast.completedStatus') : t('podcast.generatingStatus') }}
                            </div>
                        </div>
                    </template>
                </div>
            </div>
            <!-- å†…å®¹åŒºåŸŸåŒ…è£…å™¨ -->
            <div class="flex-1 flex flex-col min-w-0 overflow-y-auto main-scrollbar w-full h-full">
                <!-- ä¸»å†…å®¹åŒº -->
                <div class="h-full w-full max-w-[1000px] mx-auto flex flex-col items-center justify-center py-10 px-4 relative" style="width: 100%; max-width: 1000px;">

                    <!-- è¿”å›ä¸»é¡µæŒ‰é’® - å³ä¸Šè§’ -->
                    <button
                        v-if="!isDetailMode"
                        @click="switchToCreateView()"
                        class="absolute top-4 right-4 px-4 py-2 bg-white dark:bg-[#111] border border-black/12 dark:border-white/20 rounded-full text-sm font-medium cursor-pointer transition-all duration-300 flex items-center gap-2 hover:opacity-90 hover:scale-105 [-webkit-appearance:none] [appearance:none] leading-none hover:bg-black/4 dark:hover:bg-white/8 backdrop-blur-sm z-10"
                        :title="t('goToHome')">
                        <svg viewBox="0 0 24 24" width="16" height="16" aria-hidden="true" style="fill: currentColor;">
                            <path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/>
                        </svg>
                        <span>{{ t('goToHome') }}</span>
                    </button>

                    <!-- åˆ—è¡¨æ¨¡å¼ï¼šæ˜¾ç¤ºè¾“å…¥æ¡†å’Œç¤ºä¾‹è¾“å…¥ -->
                    <template v-if="!isDetailMode">
                        <div class="text-center mb-10 w-full relative">
                        <h1 class="text-[32px] font-light mb-2 sm:text-[20px] md:text-[32px] lg:text-[32px]">{{ t('podcast.title') }}</h1>
                        <p class="text-[20px] text-[#888] font-light">{{ t('podcast.subtitle') }}</p>
                    </div>
                    <div
                        class="text-lg text-[#86868b] dark:text-[#888] mb-5 flex items-center justify-center gap-3 flex-nowrap"
                        ref="statusText">
                        <button
                            class="bg-black/6 dark:bg-white/20 rounded-full w-[40px] h-[40px] flex items-center justify-center cursor-pointer transition-all duration-300 text-base [-webkit-appearance:none] [appearance:none] leading-none border-none hover:scale-110 text-[#ff4444] dark:text-[#ff4444]"
                            v-show="showStopBtn"
                            @click="stopGeneration"
                            ref="stopBtn"
                            :title="t('podcast.stopGeneration')">
                            <svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" style="fill: currentColor;">
                                <path d="M6 6h12v12H6z"></path>
                            </svg>
                        </button>
                        <button
                            class="bg-black/6 dark:bg-white/20 rounded-full w-[40px] h-[40px] flex items-center justify-center cursor-pointer transition-all duration-300 text-base [-webkit-appearance:none] [appearance:none] leading-none border-none hover:scale-110 text-[#1d1d1f] dark:text-white"
                            v-show="showDownloadBtn"
                            @click="downloadAudio"
                            ref="downloadBtn"
                            :title="t('podcast.downloadAudio')">
                            <svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" style="fill: currentColor;">
                                <path d="M5 20h14v-2H5v2zm7-18v12l5-5 1.41 1.41L12 17.83 4.59 10.41 6 9l5 5V2h1z"/>
                            </svg>
                        </button>
                        <span ref="statusMessage" class="flex-1">{{ statusMsg }}</span>
                    </div>
                </template>

                                        <!-- è¯¦æƒ…æ¨¡å¼ï¼šæ˜¾ç¤ºè¿”å›æŒ‰é’®å’Œæ“ä½œæŒ‰é’® -->
                                        <template v-if="isDetailMode">
                            <div class="flex justify-between w-full">
                        <button
                                class="mb-3 px-4 py-2 text-black bg-white rounded-full text-sm font-medium cursor-pointer transition-all duration-300 flex items-center gap-2 hover:opacity-90 hover:scale-105 [-webkit-appearance:none] [appearance:none] leading-none border mr-auto backdrop-blur-sm"
                                @click="router.push('/podcast_generate')"
                                ref="backToGenerateBtn"
                                :title="t('podcast.generateMore')">
                                <svg viewBox="0 0 24 24" width="16" height="16" aria-hidden="true" style="fill: currentColor;">
                                    <path d="M15.41 7.41L14 6l-6 6 6 6 1.41-1.41L11.83 12z"/>
                                </svg>
                                <span>{{ t('podcast.generateMore') }}</span>
                            </button>
                                                     <div
                                class="text-lg text-[#86868b] dark:text-[#888] mb-5 flex items-center justify-center gap-3 flex-nowrap"
                                ref="statusText">
                                <button
                                    class="bg-black/6 dark:bg-white/20 rounded-full w-[40px] h-[40px] flex items-center justify-center cursor-pointer transition-all duration-300 text-base [-webkit-appearance:none] [appearance:none] leading-none border-none hover:scale-110 text-[#1d1d1f] dark:text-white"
                                    @click="downloadAudio"
                                    ref="downloadBtn"
                                    :title="t('podcast.downloadAudio')">
                                    <svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" style="fill: currentColor;">
                                        <path d="M5 20h14v-2H5v2zm7-18v12l5-5 1.41 1.41L12 17.83 4.59 10.41 6 9l5 5V2h1z"/>
                                    </svg>
                                </button>
                            </div>
                        <button
                                class="mb-5 px-4 py-2 text-black bg-white rounded-full text-sm font-medium cursor-pointer transition-all duration-300 flex items-center gap-2 hover:opacity-90 hover:scale-105 [-webkit-appearance:none] [appearance:none] leading-none border ml-auto backdrop-blur-sm"
                                @click="applyToDigitalHuman"
                                ref="applyBtn"
                                :title="t('podcast.applyToDigitalHuman')">
                                <span>{{ t('podcast.applyToDigitalHuman') }}</span>
                                <svg viewBox="0 0 24 24" width="16" height="16" aria-hidden="true" style="fill: currentColor;">
                                    <path d="M8.59 16.59L13.17 12 8.59 7.41 10 6l6 6-6 6z"/>
                                </svg>
                            </button>
                            </div>
                        </template>
                    <!-- æ’­æ”¾å™¨å’Œå­—å¹•ï¼ˆè¯¦æƒ…æ¨¡å¼æˆ–ç”Ÿæˆä¸­æ—¶æ˜¾ç¤ºï¼‰ -->
                    <template v-if="isDetailMode || showPlayer">

                    <div class="mb-5 w-full" v-show="showPlayer" ref="playerSection">
                        <div class="bg-white dark:bg-[#111] rounded-xl p-6 mb-6 w-full border border-black/6 dark:border-white/8 shadow-sm dark:shadow-none">
                            <div class="mb-1.5 text-s text-[#86868b] dark:text-[#888] opacity-90 flex items-center justify-center text-center whitespace-nowrap overflow-hidden text-ellipsis" ref="audioUserInputEl" :title="audioUserInput">{{ audioUserInput }}</div>
                            <div class="flex items-center gap-4 mb-4">
                                <button
                                    class="w-12 h-12 rounded-full bg-[#1d1d1f] dark:bg-white text-white dark:text-black border-none cursor-pointer flex items-center justify-center text-xl transition-all duration-300 hover:scale-105 [-webkit-appearance:none] [appearance:none] leading-none"
                                    :class="isPlaying ? 'playing' : 'paused'"
                                    @click="togglePlayback"
                                    ref="playBtn">
                                    <svg
                                        class="w-[22px] h-[22px] fill-current"
                                        :class="isPlaying ? 'hidden' : 'block'"
                                        viewBox="0 0 24 24"
                                        aria-hidden="true">
                                        <path d="M8 5v14l11-7z"></path>
                                    </svg>
                                    <svg
                                        class="w-[22px] h-[22px] fill-current"
                                        :class="isPlaying ? 'block' : 'hidden'"
                                        viewBox="0 0 24 24"
                                        aria-hidden="true">
                                        <path d="M6 5h4v14H6zM14 5h4v14h-4z"></path>
                                    </svg>
                                </button>
                                <div
                                    class="flex-1 relative h-2 bg-[#d1d1d6] dark:bg-[#333] rounded cursor-pointer group"
                                    ref="progressContainer"
                                    @mousedown="onProgressMouseDown"
                                    @touchstart="onProgressTouchStart">
                                    <div
                                        class="h-full bg-[#1d1d1f] dark:bg-white rounded transition-[width] duration-100 relative group-hover:bg-[#000] dark:group-hover:bg-[#ccc]"
                                        ref="progressBar"
                                        :style="{ width: progress + '%' }">
                                    </div>
                                    <div class="absolute top-1/2 left-0 -translate-x-1/2 -translate-y-1/2 w-3 h-3 bg-[#1d1d1f] dark:bg-white rounded-full opacity-0 transition-opacity duration-200 group-hover:opacity-100"></div>
                                </div>
                            </div>
                            <div
                                class="h-[80px] bg-[#f5f5f7] dark:bg-[#0a0a0a] rounded-lg mb-3 flex items-center justify-center gap-0.5 p-2.5 relative z-[1] overflow-hidden opacity-100"
                                ref="waveform">
                                <div
                                    v-for="bar in waveformBars"
                                    :key="bar.id"
                                    class="w-1 min-h-1 rounded-sm transition-[height] duration-3000 ease-out flex-shrink-0 relative z-[2] block visible opacity-100"
                                    :style="{
                                        height: bar.height + 'px',
                                        background: bar.isDark
                                            ? `linear-gradient(to top, #fff ${bar.intensity}%, #666 0%)`
                                            : `linear-gradient(to top, #1d1d1f ${bar.intensity}%, #d1d1d6 0%)`
                                    }">
                                </div>
                            </div>
                            <div class="flex justify-between text-xs text-[#86868b] dark:text-[#888]">
                                <span ref="currentTimeEl">{{ formatTime(currentTime) }}</span>
                                <span ref="durationEl">{{ formatTime(duration) }}</span>
                                </div>
                                <!-- éŸ³é¢‘å…ƒç´ ï¼ˆéšè—ï¼Œç”¨äºæ’­æ”¾æ§åˆ¶ï¼‰ -->
                                <audio
                                    ref="audioElement"
                                    :src="audioUrl"
                                    @loadedmetadata="onAudioLoadedMetadata"
                                    @canplay="onAudioCanPlay"
                                    @timeupdate="onAudioTimeUpdate"
                                    @ended="onAudioEnded"
                                    @play="onAudioPlay"
                                    @pause="onAudioPause"
                                    @error="onAudioError"
                                    preload="auto"
                                    class="hidden">
                                </audio>
                            </div>
                        </div>

                        <div class="flex justify-center">
                            <button
                                class="mb-5 px-4 py-2 bg-transparent text-[#1d1d1f] dark:text-white border border-black/12 dark:border-[#666] rounded-lg text-sm font-medium cursor-pointer transition-all duration-300 hover:bg-[#f5f5f7] dark:hover:bg-[#222] hover:border-black/20 dark:hover:border-[#444] hover:scale-105"
                                @click="toggleSubtitles"
                                ref="toggleSubtitlesBtn">
                                {{ showSubtitles ? t('podcast.hideSubtitles') : t('podcast.showSubtitles') }}
                            </button>
                        </div>

                        <div
                            class="w-full mb-5 bg-white dark:bg-[#111] rounded-xl p-6 max-h-[400px] sm:max-h-[400px] md:max-h-[500px] lg:max-h-[600px] border border-black/6 dark:border-white/8 shadow-sm dark:shadow-none overflow-y-auto [-webkit-overflow-scrolling:touch] [scrollbar-width:thin] [scrollbar-color:#d1d1d6_#f5f5f7] dark:[scrollbar-color:#333_#0a0a0a] [&::-webkit-scrollbar]:w-1.5 [&::-webkit-scrollbar-track]:bg-[#f5f5f7] dark:[&::-webkit-scrollbar-track]:bg-[#0a0a0a] [&::-webkit-scrollbar-track]:rounded-sm [&::-webkit-scrollbar-thumb]:bg-[#d1d1d6] dark:[&::-webkit-scrollbar-thumb]:bg-[#333] [&::-webkit-scrollbar-thumb]:rounded-sm"
                            v-show="showSubtitles"
                            ref="subtitleSection"
                            id="subtitleSection"
                            @wheel="handleUserScroll"
                            @touchstart="handleUserScroll"
                            @scroll="handleUserScroll"
                            >
                            <!-- å­—å¹•å†…å®¹ç”± template æ¸²æŸ“ -->
                            <div
                                v-for="(subtitle, index) in subtitles"
                                :key="index"
                                :id="`subtitle-${index}`"
                                :class="[
                                    'subtitle mb-3 cursor-pointer flex items-center',
                                    subtitle.speaker === 'zh_male_dayixiansheng_v2_saturn_bigtts' ? 'text-left' : 'text-right'
                                ]"
                                @click="onSubtitleClick(index)">
                                <span class="inline-block text-[11px] text-[#86868b] dark:text-[#888] opacity-90 align-middle flex-[0_0_48px] text-center mr-2">
                                    {{ subtitleTimestamps[index] ? formatTime(subtitleTimestamps[index].start) : '--:--' }}
                                </span>
                                <div :class="[
                                    'inline-block max-w-[70%] px-4 py-2.5 rounded-xl text-sm leading-normal',
                                    subtitle.speaker === 'zh_male_dayixiansheng_v2_saturn_bigtts'
                                        ? 'rounded-bl-sm text-left'
                                        : 'rounded-br-sm text-left ml-auto',
                                    activeSubtitleIndex === index
                                        ? 'bg-[#d1d1d6] dark:bg-white text-[#1d1d1f] dark:text-black shadow-[0_0_20px_rgba(0,0,0,0.1)] dark:shadow-[0_0_20px_rgba(255,255,255,0.4)] scale-105 font-medium transition-[background-color,color,box-shadow,transform] duration-75 ease-out'
                                        : 'bg-[#f5f5f7] dark:bg-[#2a2a2a] text-[#1d1d1f] dark:text-[#ccc] transition-[background-color,color,box-shadow,transform] duration-75 ease-out'
                                ]"
                                :style="activeSubtitleIndex === index ? { willChange: 'background-color, color, box-shadow, transform' } : {}">
                                    {{ subtitle.text }}
                                </div>
                        </div>
                    </div>

                    </template>


                    <template v-if="!isDetailMode && !showPlayer">
                        <!-- è¾“å…¥åŒºåŸŸ -->
                        <div class="mb-10 w-full">
                        <div class="flex gap-3 mb-4 flex-row w-full">
                            <input
                                type="text"
                                class="flex-1 px-5 py-4 bg-white dark:bg-[#111] border border-black/12 dark:border-[#333] rounded-lg text-[#1d1d1f] dark:text-white text-md transition-all duration-300 focus:outline-none focus:border-black/20 dark:focus:border-[#666] focus:bg-[#fafafa] dark:focus:bg-[#1a1a1a] placeholder:text-[#86868b] dark:placeholder:text-[#666]"
                                v-model="input"
                                @keypress="onInputKeyPress"
                                :placeholder="t('podcast.inputPlaceholder')"
                                ref="inputField">
                            <button
                                class="px-8 py-4 bg-white text-black border-none rounded-lg text-sm font-medium cursor-pointer transition-all duration-300 whitespace-nowrap hover:bg-[#e0e0e0] hover:-translate-y-0.5 disabled:opacity-50 disabled:cursor-not-allowed disabled:hover:translate-y-0 disabled:hover:bg-white flex-shrink-0"
                                @click="generatePodcast"
                                ref="generateBtn">{{ t('podcast.generatePodcast') }}</button>
                        </div>

                        <!-- ç¤ºä¾‹è¾“å…¥æ°”æ³¡ -->
                        <div class="flex flex-wrap items-center justify-center gap-3 max-w-2xl mx-auto">
                            <button
                                v-for="(example, index) in exampleInputs"
                                :key="index"
                                @click="onExampleClick(example)"
                                class="relative px-4 py-2.5 bg-white/90 dark:bg-[#2c2c2e]/90 backdrop-blur-[10px] border border-black/8 dark:border-white/8 rounded-2xl text-sm text-[#1d1d1f] dark:text-[#f5f5f7] hover:bg-white dark:hover:bg-[#3a3a3c] hover:border-black/12 dark:hover:border-white/12 hover:shadow-[0_4px_12px_rgba(0,0,0,0.1)] dark:hover:shadow-[0_4px_12px_rgba(0,0,0,0.3)] transition-all duration-200 cursor-pointer tracking-tight"
                                :class="{
                                    'rounded-br-sm': index % 2 === 0,
                                    'rounded-bl-sm': index % 2 === 1
                                }"
                            >
                                {{ example }}
                            </button>
                        </div>
                    </div>
                    </template>
                </div>
                <SiteFooter />
            </div>

        </div>

    </div>
    <Alert />
    <Confirm />
    <!-- å…¨å±€åŠ è½½è¦†ç›–å±‚ - Apple é£æ ¼ -->
    <div v-show="isLoading" class="fixed inset-0 bg-[#f5f5f7] dark:bg-[#000000] flex items-center justify-center z-[9999] transition-opacity duration-300">
      <Loading />
    </div>
</template>

<style scoped>
/* æ‰€æœ‰æ ·å¼å·²é€šè¿‡ Tailwind CSS åœ¨ template ä¸­å®šä¹‰ */
/* æ³¢å½¢å›¾çš„åŠ¨æ€æ ·å¼ï¼ˆé«˜åº¦å’Œæ¸å˜èƒŒæ™¯ï¼‰é€šè¿‡ JavaScript åŠ¨æ€è®¾ç½®ï¼Œä¿ç•™ style å±æ€§ */
</style>
