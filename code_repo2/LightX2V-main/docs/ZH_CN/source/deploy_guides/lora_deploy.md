# LoRA æ¨¡å‹éƒ¨ç½²ä¸ç›¸å…³å·¥å…·

LoRA (Low-Rank Adaptation) æ˜¯ä¸€ç§é«˜æ•ˆçš„æ¨¡å‹å¾®è°ƒæŠ€æœ¯ï¼Œé€šè¿‡ä½ç§©çŸ©é˜µåˆ†è§£æ˜¾è‘—å‡å°‘å¯è®­ç»ƒå‚æ•°æ•°é‡ã€‚LightX2V å…¨é¢æ”¯æŒ LoRA æŠ€æœ¯ï¼ŒåŒ…æ‹¬ LoRA æ¨ç†ã€LoRA æå–å’Œ LoRA åˆå¹¶ç­‰åŠŸèƒ½ã€‚

## ğŸ¯ LoRA æŠ€æœ¯ç‰¹æ€§

- **çµæ´»éƒ¨ç½²**ï¼šæ”¯æŒåŠ¨æ€åŠ è½½å’Œç§»é™¤ LoRA æƒé‡
- **å¤šç§æ ¼å¼**ï¼šæ”¯æŒå¤šç§ LoRA æƒé‡æ ¼å¼å’Œå‘½åçº¦å®š
- **å·¥å…·å®Œå–„**ï¼šæä¾›å®Œæ•´çš„ LoRA æå–ã€åˆå¹¶å·¥å…·é“¾

## ğŸ“œ LoRA æ¨ç†éƒ¨ç½²

### é…ç½®æ–‡ä»¶æ–¹å¼

åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š LoRA è·¯å¾„ï¼š

```json
{
  "lora_configs": [
    {
      "path": "/path/to/your/lora.safetensors",
      "strength": 1.0
    }
  ]
}
```

**é…ç½®å‚æ•°è¯´æ˜ï¼š**

- `lora_path`: LoRA æƒé‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ª LoRA åŒæ—¶åŠ è½½
- `strength_model`: LoRA å¼ºåº¦ç³»æ•° (alpha)ï¼Œæ§åˆ¶ LoRA å¯¹åŸæ¨¡å‹çš„å½±å“ç¨‹åº¦

### å‘½ä»¤è¡Œæ–¹å¼

ç›´æ¥åœ¨å‘½ä»¤è¡Œä¸­æŒ‡å®š LoRA è·¯å¾„ï¼ˆä»…æ”¯æŒåŠ è½½å•ä¸ª LoRAï¼‰ï¼š

```bash
python -m lightx2v.infer \
  --model_cls wan2.1 \
  --task t2v \
  --model_path /path/to/model \
  --config_json /path/to/config.json \
  --lora_path /path/to/your/lora.safetensors \
  --lora_strength 0.8 \
  --prompt "Your prompt here"
```

### å¤šLoRAé…ç½®

è¦ä½¿ç”¨å¤šä¸ªå…·æœ‰ä¸åŒå¼ºåº¦çš„LoRAï¼Œè¯·åœ¨é…ç½®JSONæ–‡ä»¶ä¸­æŒ‡å®šï¼š

```json
{
  "lora_configs": [
    {
      "path": "/path/to/first_lora.safetensors",
      "strength": 0.8
    },
    {
      "path": "/path/to/second_lora.safetensors",
      "strength": 0.5
    }
  ]
}
```

### æ”¯æŒçš„ LoRA æ ¼å¼

LightX2V æ”¯æŒå¤šç§ LoRA æƒé‡å‘½åçº¦å®šï¼š

| æ ¼å¼ç±»å‹ | æƒé‡å‘½å | è¯´æ˜ |
|----------|----------|------|
| **æ ‡å‡† LoRA** | `lora_A.weight`, `lora_B.weight` | æ ‡å‡†çš„ LoRA çŸ©é˜µåˆ†è§£æ ¼å¼ |
| **Down/Up æ ¼å¼** | `lora_down.weight`, `lora_up.weight` | å¦ä¸€ç§å¸¸è§çš„å‘½åçº¦å®š |
| **å·®å€¼æ ¼å¼** | `diff` | `weight` æƒé‡å·®å€¼ |
| **åç½®å·®å€¼** | `diff_b` | `bias` æƒé‡å·®å€¼ |
| **è°ƒåˆ¶å·®å€¼** | `diff_m` | `modulation` æƒé‡å·®å€¼ |

### æ¨ç†è„šæœ¬ç¤ºä¾‹

**æ­¥æ•°è’¸é¦ LoRA æ¨ç†ï¼š**

```bash
# T2V LoRA æ¨ç†
bash scripts/wan/run_wan_t2v_distill_4step_cfg_lora.sh

# I2V LoRA æ¨ç†
bash scripts/wan/run_wan_i2v_distill_4step_cfg_lora.sh
```

**éŸ³é¢‘é©±åŠ¨ LoRA æ¨ç†ï¼š**

```bash
bash scripts/wan/run_wan_i2v_audio.sh
```

### API æœåŠ¡ä¸­ä½¿ç”¨ LoRA

åœ¨ API æœåŠ¡ä¸­é€šè¿‡ [config æ–‡ä»¶](wan_t2v_distill_4step_cfg_lora.json) æŒ‡å®šï¼Œå¯¹ [scripts/server/start_server.sh](https://github.com/ModelTC/lightx2v/blob/main/scripts/server/start_server.sh) ä¸­çš„å¯åŠ¨å‘½ä»¤è¿›è¡Œä¿®æ”¹ï¼š

```bash
python -m lightx2v.api_server \
  --model_cls wan2.1_distill \
  --task t2v \
  --model_path $model_path \
  --config_json ${lightx2v_path}/configs/distill/wan_t2v_distill_4step_cfg_lora.json \
  --port 8000 \
  --nproc_per_node 1
```

## ğŸ”§ LoRA æå–å·¥å…·

ä½¿ç”¨ `tools/extract/lora_extractor.py` ä»ä¸¤ä¸ªæ¨¡å‹çš„å·®å¼‚ä¸­æå– LoRA æƒé‡ã€‚

### åŸºæœ¬ç”¨æ³•

```bash
python tools/extract/lora_extractor.py \
  --source-model /path/to/base/model \
  --target-model /path/to/finetuned/model \
  --output /path/to/extracted/lora.safetensors \
  --rank 32
```

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | å¿…éœ€ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| `--source-model` | str | âœ… | - | åŸºç¡€æ¨¡å‹è·¯å¾„ |
| `--target-model` | str | âœ… | - | å¾®è°ƒåæ¨¡å‹è·¯å¾„ |
| `--output` | str | âœ… | - | è¾“å‡º LoRA æ–‡ä»¶è·¯å¾„ |
| `--source-type` | str | âŒ | `safetensors` | åŸºç¡€æ¨¡å‹æ ¼å¼ (`safetensors`/`pytorch`) |
| `--target-type` | str | âŒ | `safetensors` | å¾®è°ƒæ¨¡å‹æ ¼å¼ (`safetensors`/`pytorch`) |
| `--output-format` | str | âŒ | `safetensors` | è¾“å‡ºæ ¼å¼ (`safetensors`/`pytorch`) |
| `--rank` | int | âŒ | `32` | LoRA ç§©å€¼ |
| `--output-dtype` | str | âŒ | `bf16` | è¾“å‡ºæ•°æ®ç±»å‹ |
| `--diff-only` | bool | âŒ | `False` | ä»…ä¿å­˜æƒé‡å·®å€¼ï¼Œä¸è¿›è¡Œ LoRA åˆ†è§£ |

### é«˜çº§ç”¨æ³•ç¤ºä¾‹

**æå–é«˜ç§© LoRAï¼š**

```bash
python tools/extract/lora_extractor.py \
  --source-model /path/to/base/model \
  --target-model /path/to/finetuned/model \
  --output /path/to/high_rank_lora.safetensors \
  --rank 64 \
  --output-dtype fp16
```

**ä»…ä¿å­˜æƒé‡å·®å€¼ï¼š**

```bash
python tools/extract/lora_extractor.py \
  --source-model /path/to/base/model \
  --target-model /path/to/finetuned/model \
  --output /path/to/weight_diff.safetensors \
  --diff-only
```

## ğŸ”€ LoRA åˆå¹¶å·¥å…·

ä½¿ç”¨ `tools/extract/lora_merger.py` å°† LoRA æƒé‡åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹ä¸­ï¼Œä»¥è¿›è¡Œåç»­é‡åŒ–ç­‰æ“ä½œã€‚

### åŸºæœ¬ç”¨æ³•

```bash
python tools/extract/lora_merger.py \
  --source-model /path/to/base/model \
  --lora-model /path/to/lora.safetensors \
  --output /path/to/merged/model.safetensors \
  --alpha 1.0
```

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | å¿…éœ€ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| `--source-model` | str | âœ… | æ—  | åŸºç¡€æ¨¡å‹è·¯å¾„ |
| `--lora-model` | str | âœ… | æ—  | LoRA æƒé‡è·¯å¾„ |
| `--output` | str | âœ… | æ—  | è¾“å‡ºåˆå¹¶æ¨¡å‹è·¯å¾„ |
| `--source-type` | str | âŒ | `safetensors` | åŸºç¡€æ¨¡å‹æ ¼å¼ |
| `--lora-type` | str | âŒ | `safetensors` | LoRA æƒé‡æ ¼å¼ |
| `--output-format` | str | âŒ | `safetensors` | è¾“å‡ºæ ¼å¼ |
| `--alpha` | float | âŒ | `1.0` | LoRA åˆå¹¶å¼ºåº¦ |
| `--output-dtype` | str | âŒ | `bf16` | è¾“å‡ºæ•°æ®ç±»å‹ |

### é«˜çº§ç”¨æ³•ç¤ºä¾‹

**éƒ¨åˆ†å¼ºåº¦åˆå¹¶ï¼š**

```bash
python tools/extract/lora_merger.py \
  --source-model /path/to/base/model \
  --lora-model /path/to/lora.safetensors \
  --output /path/to/merged_model.safetensors \
  --alpha 0.7 \
  --output-dtype fp32
```

**å¤šæ ¼å¼æ”¯æŒï¼š**

```bash
python tools/extract/lora_merger.py \
  --source-model /path/to/base/model.pt \
  --source-type pytorch \
  --lora-model /path/to/lora.safetensors \
  --lora-type safetensors \
  --output /path/to/merged_model.safetensors \
  --output-format safetensors \
  --alpha 1.0
```
