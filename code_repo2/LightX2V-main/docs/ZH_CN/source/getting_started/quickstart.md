# LightX2V å¿«é€Ÿå…¥é—¨æŒ‡å—

æ¬¢è¿ä½¿ç”¨ LightX2Vï¼æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨å¿«é€Ÿæ­å»ºç¯å¢ƒå¹¶å¼€å§‹ä½¿ç”¨ LightX2V è¿›è¡Œè§†é¢‘ç”Ÿæˆã€‚

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [Linux ç³»ç»Ÿç¯å¢ƒæ­å»º](#linux-ç³»ç»Ÿç¯å¢ƒæ­å»º)
  - [Docker ç¯å¢ƒï¼ˆæ¨èï¼‰](#docker-ç¯å¢ƒæ¨è)
  - [Conda ç¯å¢ƒæ­å»º](#conda-ç¯å¢ƒæ­å»º)
- [Windows ç³»ç»Ÿç¯å¢ƒæ­å»º](#windows-ç³»ç»Ÿç¯å¢ƒæ­å»º)
- [æ¨ç†ä½¿ç”¨](#æ¨ç†ä½¿ç”¨)

## ğŸš€ ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 18.04+) æˆ– Windows 10/11
- **Python**: 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬
- **GPU**: NVIDIA GPUï¼Œæ”¯æŒ CUDAï¼Œè‡³å°‘ 8GB æ˜¾å­˜
- **å†…å­˜**: å»ºè®® 16GB æˆ–æ›´å¤š
- **å­˜å‚¨**: è‡³å°‘ 50GB å¯ç”¨ç©ºé—´

## ğŸ§ Linux ç³»ç»Ÿç¯å¢ƒæ­å»º

### ğŸ³ Docker ç¯å¢ƒï¼ˆæ¨èï¼‰

æˆ‘ä»¬å¼ºçƒˆæ¨èä½¿ç”¨ Docker ç¯å¢ƒï¼Œè¿™æ˜¯æœ€ç®€å•å¿«æ·çš„å®‰è£…æ–¹å¼ã€‚

#### 1. æ‹‰å–é•œåƒ

è®¿é—® LightX2V çš„ [Docker Hub](https://hub.docker.com/r/lightx2v/lightx2v/tags)ï¼Œé€‰æ‹©ä¸€ä¸ªæœ€æ–°æ—¥æœŸçš„ tagï¼Œæ¯”å¦‚ `25111101-cu128`ï¼š

```bash
docker pull lightx2v/lightx2v:25111101-cu128
```

æˆ‘ä»¬æ¨èä½¿ç”¨`cuda128`ç¯å¢ƒï¼Œä»¥è·å¾—æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œè‹¥éœ€è¦ä½¿ç”¨`cuda124`ç¯å¢ƒï¼Œå¯ä»¥ä½¿ç”¨å¸¦`-cu124`åç¼€çš„é•œåƒç‰ˆæœ¬ï¼š

```bash
docker pull lightx2v/lightx2v:25101501-cu124
```

#### 2. è¿è¡Œå®¹å™¨

```bash
docker run --gpus all -itd --ipc=host --name [å®¹å™¨å] -v [æŒ‚è½½è®¾ç½®] --entrypoint /bin/bash [é•œåƒid]
```

#### 3. ä¸­å›½é•œåƒæºï¼ˆå¯é€‰ï¼‰

å¯¹äºä¸­å›½å¤§é™†åœ°åŒºï¼Œå¦‚æœæ‹‰å–é•œåƒæ—¶ç½‘ç»œä¸ç¨³å®šï¼Œå¯ä»¥ä»é˜¿é‡Œäº‘ä¸Šæ‹‰å–ï¼š

```bash
# cuda128
docker pull registry.cn-hangzhou.aliyuncs.com/yongyang/lightx2v:25111101-cu128

# cuda124
docker pull registry.cn-hangzhou.aliyuncs.com/yongyang/lightx2v:25101501-cu124
```

### ğŸ Conda ç¯å¢ƒæ­å»º

å¦‚æœæ‚¨å¸Œæœ›ä½¿ç”¨ Conda è‡ªè¡Œæ­å»ºç¯å¢ƒï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

#### æ­¥éª¤ 1: å…‹éš†é¡¹ç›®

```bash
# ä¸‹è½½é¡¹ç›®ä»£ç 
git clone https://github.com/ModelTC/LightX2V.git
cd LightX2V
```

#### æ­¥éª¤ 2: åˆ›å»º conda è™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»ºå¹¶æ¿€æ´» conda ç¯å¢ƒ
conda create -n lightx2v python=3.11 -y
conda activate lightx2v
```

#### æ­¥éª¤ 3: å®‰è£…ä¾èµ–åŠä»£ç 

```bash
pip install -v -e .
```

#### æ­¥éª¤ 4: å®‰è£…æ³¨æ„åŠ›æœºåˆ¶ç®—å­

**é€‰é¡¹ A: Flash Attention 2**
```bash
git clone https://github.com/Dao-AILab/flash-attention.git --recursive
cd flash-attention && python setup.py install
```

**é€‰é¡¹ B: Flash Attention 3ï¼ˆç”¨äº Hopper æ¶æ„æ˜¾å¡ï¼‰**
```bash
cd flash-attention/hopper && python setup.py install
```

**é€‰é¡¹ C: SageAttention 2ï¼ˆæ¨èï¼‰**
```bash
git clone https://github.com/thu-ml/SageAttention.git
cd SageAttention && CUDA_ARCHITECTURES="8.0,8.6,8.9,9.0,12.0" EXT_PARALLEL=4 NVCC_APPEND_FLAGS="--threads 8" MAX_JOBS=32 pip install -v -e .
```

#### æ­¥éª¤ 4: å®‰è£…é‡åŒ–ç®—å­ï¼ˆå¯é€‰ï¼‰

é‡åŒ–ç®—å­ç”¨äºæ”¯æŒæ¨¡å‹é‡åŒ–åŠŸèƒ½ï¼Œå¯ä»¥æ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨å¹¶åŠ é€Ÿæ¨ç†ã€‚æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„é‡åŒ–ç®—å­ï¼š

**é€‰é¡¹ A: VLLM Kernelsï¼ˆæ¨èï¼‰**
é€‚ç”¨äºå¤šç§é‡åŒ–æ–¹æ¡ˆï¼Œæ”¯æŒ FP8 ç­‰é‡åŒ–æ ¼å¼ã€‚

```bash
pip install vllm
```

æˆ–è€…ä»æºç å®‰è£…ä»¥è·å¾—æœ€æ–°åŠŸèƒ½ï¼š

```bash
git clone https://github.com/vllm-project/vllm.git
cd vllm
uv pip install -e .
```

**é€‰é¡¹ B: SGL Kernels**
é€‚ç”¨äº SGL é‡åŒ–æ–¹æ¡ˆï¼Œéœ€è¦ torch == 2.8.0ã€‚

```bash
pip install sgl-kernel --upgrade
```

**é€‰é¡¹ C: Q8 Kernels**
é€‚ç”¨äº Ada æ¶æ„æ˜¾å¡ï¼ˆå¦‚ RTX 4090ã€L40S ç­‰ï¼‰ã€‚

```bash
git clone https://github.com/KONAKONA666/q8_kernels.git
cd q8_kernels && git submodule init && git submodule update
python setup.py install
```

> ğŸ’¡ **æç¤º**:
> - å¦‚æœä¸éœ€è¦ä½¿ç”¨é‡åŒ–åŠŸèƒ½ï¼Œå¯ä»¥è·³è¿‡æ­¤æ­¥éª¤
> - é‡åŒ–æ¨¡å‹å¯ä»¥ä» [LightX2V HuggingFace](https://huggingface.co/lightx2v) ä¸‹è½½
> - æ›´å¤šé‡åŒ–ç›¸å…³ä¿¡æ¯è¯·å‚è€ƒ [é‡åŒ–æ–‡æ¡£](method_tutorials/quantization.html)

#### æ­¥éª¤ 5: éªŒè¯å®‰è£…
```python
import lightx2v
print(f"LightX2V ç‰ˆæœ¬: {lightx2v.__version__}")
```

## ğŸªŸ Windows ç³»ç»Ÿç¯å¢ƒæ­å»º

Windows ç³»ç»Ÿä»…æ”¯æŒ Conda ç¯å¢ƒæ­å»ºæ–¹å¼ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

### ğŸ Conda ç¯å¢ƒæ­å»º

#### æ­¥éª¤ 1: æ£€æŸ¥ CUDA ç‰ˆæœ¬

é¦–å…ˆç¡®è®¤æ‚¨çš„ GPU é©±åŠ¨å’Œ CUDA ç‰ˆæœ¬ï¼š

```cmd
nvidia-smi
```

è®°å½•è¾“å‡ºä¸­çš„ **CUDA Version** ä¿¡æ¯ï¼Œåç»­å®‰è£…æ—¶éœ€è¦ä¿æŒç‰ˆæœ¬ä¸€è‡´ã€‚

#### æ­¥éª¤ 2: åˆ›å»º Python ç¯å¢ƒ

```cmd
# åˆ›å»ºæ–°ç¯å¢ƒï¼ˆæ¨è Python 3.12ï¼‰
conda create -n lightx2v python=3.12 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate lightx2v
```

> ğŸ’¡ **æç¤º**: å»ºè®®ä½¿ç”¨ Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬ä»¥è·å¾—æœ€ä½³å…¼å®¹æ€§ã€‚

#### æ­¥éª¤ 3: å®‰è£… PyTorch æ¡†æ¶

**æ–¹æ³•ä¸€ï¼šä¸‹è½½å®˜æ–¹ wheel åŒ…ï¼ˆæ¨èï¼‰**

1. è®¿é—® [PyTorch å®˜æ–¹ä¸‹è½½é¡µé¢](https://download.pytorch.org/whl/torch/)
2. é€‰æ‹©å¯¹åº”ç‰ˆæœ¬çš„ wheel åŒ…ï¼Œæ³¨æ„åŒ¹é…ä»¥ä¸‹å‚æ•°ï¼š
   - **Python ç‰ˆæœ¬**: ä¸æ‚¨çš„ç¯å¢ƒä¸€è‡´
   - **CUDA ç‰ˆæœ¬**: ä¸æ‚¨çš„ GPU é©±åŠ¨åŒ¹é…
   - **å¹³å°**: é€‰æ‹© Windows ç‰ˆæœ¬

**ç¤ºä¾‹ï¼ˆPython 3.12 + PyTorch 2.6 + CUDA 12.4ï¼‰ï¼š**

```cmd
# ä¸‹è½½å¹¶å®‰è£… PyTorch
pip install torch-2.6.0+cu124-cp312-cp312-win_amd64.whl

# å®‰è£…é…å¥—åŒ…
pip install torchvision==0.21.0 torchaudio==2.6.0
```

**æ–¹æ³•äºŒï¼šä½¿ç”¨ pip ç›´æ¥å®‰è£…**

```cmd
# CUDA 12.4 ç‰ˆæœ¬ç¤ºä¾‹
pip install torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124
```

#### æ­¥éª¤ 4: å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–

```cmd
# å…‹éš†é¡¹ç›®ä»£ç 
git clone https://github.com/ModelTC/LightX2V.git
cd LightX2V

# å®‰è£… Windows ä¸“ç”¨ä¾èµ–
pip install -r requirements_win.txt
pip install -v -e .
```

#### æ­¥éª¤ 5: å®‰è£…æ³¨æ„åŠ›æœºåˆ¶ç®—å­

**é€‰é¡¹ A: Flash Attention 2**

```cmd
pip install flash-attn==2.7.2.post1
```

**é€‰é¡¹ B: SageAttention 2ï¼ˆå¼ºçƒˆæ¨èï¼‰**

**ä¸‹è½½æºï¼š**
- [Windows ä¸“ç”¨ç‰ˆæœ¬ 1](https://github.com/woct0rdho/SageAttention/releases)
- [Windows ä¸“ç”¨ç‰ˆæœ¬ 2](https://github.com/sdbds/SageAttention-for-windows/releases)

```cmd
# å®‰è£… SageAttentionï¼ˆè¯·æ ¹æ®å®é™…æ–‡ä»¶åè°ƒæ•´ï¼‰
pip install sageattention-2.1.1+cu126torch2.6.0-cp312-cp312-win_amd64.whl
```

> âš ï¸ **æ³¨æ„**: SageAttention çš„ CUDA ç‰ˆæœ¬å¯ä»¥ä¸ä¸¥æ ¼å¯¹é½ï¼Œä½† Python å’Œ PyTorch ç‰ˆæœ¬å¿…é¡»åŒ¹é…ã€‚

#### æ­¥éª¤ 6 (å¯é€‰): å®‰è£…é‡åŒ–ç®—å­

é»˜è®¤ä½¿ç”¨ Triton kernel è¿›è¡Œé‡åŒ–æ¨ç†ï¼Œå®ç°é«˜æ•ˆä¸”æ— éœ€å®‰è£…é¢å¤–ä¾èµ–ï¼Œåªéœ€ç¡®ä¿å·²å®‰è£… `triton-windows` å³å¯ã€‚

å¦‚éœ€ä½¿ç”¨å…¶ä»–é‡åŒ–ç®—å­ï¼Œå¯å®‰è£…ä»¥ä¸‹é€‰é¡¹ï¼š

**1. å®‰è£… Windows ç‰ˆ vLLM**

ä» [vllm-windows releases](https://github.com/SystemPanic/vllm-windows/releases) ä¸‹è½½å¯¹åº”çš„ wheel åŒ…ã€‚

**ç‰ˆæœ¬åŒ¹é…è¦æ±‚ï¼š**
- Python ç‰ˆæœ¬åŒ¹é…
- PyTorch ç‰ˆæœ¬åŒ¹é…
- CUDA ç‰ˆæœ¬åŒ¹é…

```cmd
# å®‰è£… vLLMï¼ˆè¯·æ ¹æ®å®é™…æ–‡ä»¶åè°ƒæ•´ï¼‰
pip install vllm-0.9.1+cu124-cp312-cp312-win_amd64.whl
```

**2. å®‰è£… q8-kernels**

å¯¹äº RTX 40 ç³»æ˜¾å¡ï¼Œæ¨èå®‰è£… `q8_kernel==0.1.0`ï¼š

```bash
git clone https://github.com/KONAKONA666/q8_kernels.git
cd q8_kernels && git submodule init && git submodule update
python setup.py install
```

å¯¹äºå…¶ä»–æ˜¾å¡ï¼Œæ¨èå®‰è£… `q8_kernel==0.5.0`ï¼Œè¯·å‚è€ƒ [LTX-Video-Q8-Kernels](https://github.com/Lightricks/LTX-Video-Q8-Kernels)ã€‚

> ğŸ’¡ **æç¤º**:
> - å»ºè®®ä½¿ç”¨é»˜è®¤çš„ Triton kernel è¿›è¡Œæ¨ç†
> - é‡åŒ–æ¨¡å‹å¯ä»¥ä» [LightX2V HuggingFace](https://huggingface.co/lightx2v) ä¸‹è½½
> - æ›´å¤šé‡åŒ–ç›¸å…³ä¿¡æ¯è¯·å‚è€ƒ [é‡åŒ–æ–‡æ¡£](method_tutorials/quantization.html)

#### æ­¥éª¤ 8: éªŒè¯å®‰è£…
```python
import lightx2v
print(f"LightX2V ç‰ˆæœ¬: {lightx2v.__version__}")
```

## ğŸ¯ æ¨ç†ä½¿ç”¨

### ğŸ“¥ æ¨¡å‹å‡†å¤‡

åœ¨å¼€å§‹æ¨ç†ä¹‹å‰ï¼Œæ‚¨éœ€è¦æå‰ä¸‹è½½å¥½æ¨¡å‹æ–‡ä»¶ã€‚æˆ‘ä»¬æ¨èï¼š

- **ä¸‹è½½æº**: ä» [LightX2V å®˜æ–¹ Hugging Face](https://huggingface.co/lightx2v/)æˆ–è€…å…¶ä»–å¼€æºæ¨¡å‹åº“ä¸‹è½½æ¨¡å‹
- **å­˜å‚¨ä½ç½®**: å»ºè®®å°†æ¨¡å‹å­˜å‚¨åœ¨ SSD ç£ç›˜ä¸Šä»¥è·å¾—æ›´å¥½çš„è¯»å–æ€§èƒ½
- **å¯ç”¨æ¨¡å‹**: åŒ…æ‹¬ Wan2.1-I2Vã€Wan2.1-T2V ç­‰å¤šç§æ¨¡å‹ï¼Œæ”¯æŒä¸åŒåˆ†è¾¨ç‡å’ŒåŠŸèƒ½

### ğŸ“ é…ç½®æ–‡ä»¶ä¸è„šæœ¬

æ¨ç†ä¼šç”¨åˆ°çš„é…ç½®æ–‡ä»¶éƒ½åœ¨[è¿™é‡Œ](https://github.com/ModelTC/LightX2V/tree/main/configs)ï¼Œè„šæœ¬éƒ½åœ¨[è¿™é‡Œ](https://github.com/ModelTC/LightX2V/tree/main/scripts)ã€‚

éœ€è¦å°†ä¸‹è½½çš„æ¨¡å‹è·¯å¾„é…ç½®åˆ°è¿è¡Œè„šæœ¬ä¸­ã€‚é™¤äº†è„šæœ¬ä¸­çš„è¾“å…¥å‚æ•°ï¼Œ`--config_json` æŒ‡å‘çš„é…ç½®æ–‡ä»¶ä¸­ä¹Ÿä¼šåŒ…å«ä¸€äº›å¿…è¦å‚æ•°ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦è‡ªè¡Œä¿®æ”¹ã€‚

### ğŸš€ å¼€å§‹æ¨ç†

#### Linux ç¯å¢ƒ

```bash
# ä¿®æ”¹è„šæœ¬ä¸­çš„è·¯å¾„åè¿è¡Œ
bash scripts/wan/run_wan_t2v.sh
```

#### Windows ç¯å¢ƒ

```cmd
# ä½¿ç”¨ Windows æ‰¹å¤„ç†è„šæœ¬
scripts\win\run_wan_t2v.bat
```
#### Pythonè„šæœ¬å¯åŠ¨

```python
from lightx2v import LightX2VPipeline

pipe = LightX2VPipeline(
    model_path="/path/to/Wan2.1-T2V-14B",
    model_cls="wan2.1",
    task="t2v",
)

pipe.create_generator(
    attn_mode="sage_attn2",
    infer_steps=50,
    height=480, # 720
    width=832, # 1280
    num_frames=81,
    guidance_scale=5.0,
    sample_shift=5.0,
)

seed = 42
prompt = "Two anthropomorphic cats in comfy boxing gear and bright gloves fight intensely on a spotlighted stage."
negative_prompt = "é•œå¤´æ™ƒåŠ¨ï¼Œè‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°"
save_result_path="/path/to/save_results/output.mp4"

pipe.generate(
    seed=seed,
    prompt=prompt,
    negative_prompt=negative_prompt,
    save_result_path=save_result_path,
)
```


## ğŸ“ è·å–å¸®åŠ©

å¦‚æœæ‚¨åœ¨å®‰è£…æˆ–ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. åœ¨ [GitHub Issues](https://github.com/ModelTC/LightX2V/issues) ä¸­æœç´¢ç›¸å…³é—®é¢˜
2. æäº¤æ–°çš„ Issue æè¿°æ‚¨çš„é—®é¢˜

---

ğŸ‰ **æ­å–œï¼** ç°åœ¨æ‚¨å·²ç»æˆåŠŸæ­å»ºäº† LightX2V ç¯å¢ƒï¼Œå¯ä»¥å¼€å§‹äº«å—è§†é¢‘ç”Ÿæˆçš„ä¹è¶£äº†ï¼
